{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "669cd6bb",
   "metadata": {},
   "source": [
    "# Task 2: Use SageMaker Debugger\n",
    "\n",
    "In this lab, you use Amazon SageMaker Debugger to analyze, detect, and get alerted on bottlenecks, resource utilization rates, and various training issues during training jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-booking",
   "metadata": {
    "papermill": {
     "duration": 0.018947,
     "end_time": "2021-06-01T00:12:50.309809",
     "exception": false,
     "start_time": "2021-06-01T00:12:50.290862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Task 2.1: Environment setup\n",
    "\n",
    "Install packages and dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516a23c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#install a compiler\n",
    "%conda install -c conda-forge gcc -y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c83fa35",
   "metadata": {},
   "source": [
    "**Note:** GCC can take as long as 5 minutes to install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa03393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install-dependencies\n",
    "\n",
    "%pip install pytest-cov\n",
    "%pip install pytest-filter-subpackage\n",
    "%pip install -U sagemaker\n",
    "%pip install -U smdebug\n",
    "%pip install -U shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44983b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries and set variable values\n",
    "\n",
    "import sys\n",
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import sagemaker_datawrangler \n",
    "import shap\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "\n",
    "from sagemaker.debugger import (\n",
    "    CollectionConfig,\n",
    "    DebuggerHookConfig,\n",
    "    FrameworkProfile,\n",
    "    ProfilerConfig,\n",
    "    ProfilerRule,\n",
    "    Rule,\n",
    "    rule_configs,\n",
    "    TensorBoardOutputConfig\n",
    ")\n",
    "\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from smdebug.core import modes\n",
    "from smdebug.trials import create_trial\n",
    "\n",
    "base_job_name = \"lab-7-smdebugger-job\"\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "bucket_path = \"s3://{}\".format(bucket)\n",
    "prefix = \"lab-7-smdebugger\"\n",
    "region = boto3.Session().region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "save_interval = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f5b470",
   "metadata": {},
   "source": [
    "Next, import the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57128928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import-dataset\n",
    "lab_test_data = pd.read_csv('adult_data_processed.csv')\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "lab_test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26e3138",
   "metadata": {},
   "source": [
    "Split the dataset into training (70 percent), validation (20 percent), and test (10 percent) datasets. The training and validation datasets are used to create the model in this lab. You will not use the test dataset in this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95c48c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split-dataset\n",
    "train_data, validation_data, test_data = np.split(\n",
    "    lab_test_data.sample(frac=1, random_state=1729),\n",
    "    [int(0.7 * len(lab_test_data)), int(0.9 * len(lab_test_data))],\n",
    ")\n",
    "\n",
    "train_data.to_csv('train_data.csv', index=False, header=False)\n",
    "validation_data.to_csv('validation_data.csv', index=False, header=False)\n",
    "\n",
    "feature_names = list(train_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42977436",
   "metadata": {},
   "source": [
    "Now, upload the dataset to Amazon Simple Storage Service (Amazon S3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be44e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload-dataset\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "train_path = S3Uploader.upload('train_data.csv', 's3://{}/{}'.format(bucket, prefix))\n",
    "validation_path = S3Uploader.upload('validation_data.csv', 's3://{}/{}'.format(bucket, prefix))\n",
    "\n",
    "train_input = TrainingInput(train_path, content_type='text/csv')\n",
    "validation_input = TrainingInput(validation_path, content_type='text/csv')\n",
    "\n",
    "data_inputs = {\n",
    "    'train': train_input,\n",
    "    'validation': validation_input\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "wrong-terror",
   "metadata": {
    "papermill": {
     "duration": 0.022031,
     "end_time": "2021-06-01T00:12:54.187737",
     "exception": false,
     "start_time": "2021-06-01T00:12:54.165706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Task 2.2: Modify the training script to enable SageMaker Debugger\n",
    "\n",
    "You must modify the training script that you used in the previous lab to save tensors to a specified output S3 bucket, specify which tensors to save, and register debug hooks.\n",
    "\n",
    "To train the model, you will need to configure the following:\n",
    "- **Debugger Hook Parameters** to adjust save intervals of the output tensors in the training phases\n",
    "- **Debugger Rule Object** to save output tensors for evaluation\n",
    "\n",
    "For **Debugger Hook Parameters**, you configure the **metrics**, **feature_importance**, **full_shap**, and **average_shap** built-in tensor collections to be captured during training. These are configured in the **collection_configs** for the **debugger_hook_config**. The **full_shap**, and **average_shap** built-in tensor collections use Shapley Values (SHAP). SHAP explains a machine learning (ML) prediction by assuming that each feature value of a training data instance is a player in a game where the prediction is the payout. It then indicates how to distribute the payout fairly among the features. Refer to [SHAP Baselines for Explainability](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-feature-attribute-shap-baselines.html) for more information about SHAP.\n",
    "\n",
    "For **Debugger Rule Object**, you configure the following **rule_configs** in **rules**:\n",
    "- [Profiler Report](https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-report.html#debugger-profiling-report): Runs rules for system bottleneck detections and autogenerates a profiling report.\n",
    "- [XGBoost Training Report](https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-report-xgboost.html): Runs a comprehensive XGBoost Report.\n",
    "- [Overfit](https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-built-in-rules.html#overfit): Detects if your model is being overfit to the training data by comparing the validation and training losses.\n",
    "- [Overtraining](https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-built-in-rules.html#overtraining): Detects if a model is being overtrained. After several training iterations on a well-behaved model (both training and validation loss decrease), the model approaches to a minimum of the loss function and does not improve anymore. If the model continues training, validation loss might start increasing because the model starts overfitting.\n",
    "- [Loss Not Decreasing](https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-built-in-rules.html#loss-not-decreasing): Detects when the loss is not decreasing in value at an adequate rate. These losses must be scalars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4253b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enable-debugger\n",
    "# Retrieve the container image\n",
    "container = sagemaker.image_uris.retrieve(\n",
    "    region=boto3.Session().region_name, \n",
    "    framework='xgboost', \n",
    "    version='1.5-1'\n",
    ")\n",
    "# Set up the estimator\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role, \n",
    "    base_job_name=base_job_name,\n",
    "    instance_count=1, \n",
    "    instance_type='ml.m5.4xlarge',\n",
    "    #Set the hyperparameters\n",
    "    hyperparameters= {\n",
    "        \"max_depth\": \"5\",\n",
    "        \"eta\": \"0.2\",\n",
    "        \"gamma\": \"4\",\n",
    "        \"min_child_weight\": \"6\",\n",
    "        \"subsample\": \"0.7\",\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"num_round\": \"300\",\n",
    "    },\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    max_run=1800,\n",
    "    #Set the Debugger Hook Config\n",
    "    debugger_hook_config=DebuggerHookConfig(\n",
    "        s3_output_path=bucket_path,  # Required\n",
    "        collection_configs=[  # For each of these, a new processing job will be run later in the lab\n",
    "            CollectionConfig(name=\"metrics\", parameters={\"save_interval\": str(save_interval)}),\n",
    "            CollectionConfig(name=\"feature_importance\", parameters={\"save_interval\": str(save_interval)},),\n",
    "            CollectionConfig(name=\"full_shap\", parameters={\"save_interval\": str(save_interval)}),\n",
    "            CollectionConfig(name=\"average_shap\", parameters={\"save_interval\": str(save_interval)}),\n",
    "        ],\n",
    "    ),\n",
    "    #Set the Debugger Profiler Configuration\n",
    "    profiler_config = ProfilerConfig(\n",
    "        system_monitor_interval_millis=500,\n",
    "        framework_profile_params=FrameworkProfile()\n",
    "\n",
    "    ),\n",
    "    #Configure the Debugger Rule Object\n",
    "    rules = [\n",
    "        ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "        Rule.sagemaker(rule_configs.create_xgboost_report()),  \n",
    "        Rule.sagemaker(rule_configs.overfit()),\n",
    "        Rule.sagemaker(rule_configs.overtraining()),\n",
    "        Rule.sagemaker(rule_configs.loss_not_decreasing(),\n",
    "            rule_parameters={\n",
    "                \"collection_names\": \"metrics\",\n",
    "                \"num_steps\": str(save_interval * 2),\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6a6c2d",
   "metadata": {},
   "source": [
    "## Task 2.3: Run the Debugger-enabled training job\n",
    "\n",
    "Now, train the XGBoost model using the Debugger-enabled script. Training will take approximately 5–10 minutes to run. You can continue with the next task while the training job is running and monitor the job progress using SageMaker Debugger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cd5dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-model\n",
    "xgb.fit(\n",
    "    inputs = data_inputs\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "verified-draft",
   "metadata": {
    "papermill": {
     "duration": 0.022325,
     "end_time": "2021-06-01T00:12:55.995017",
     "exception": false,
     "start_time": "2021-06-01T00:12:55.972692",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Task 2.4: Monitor the training job status\n",
    "\n",
    "In SageMaker Studio, you can review the trial components, including all the SageMaker Debugger jobs that you started. In this lab, you created an **XGBoost Report** job, an **Overfit** job, an **Overtraining** job, and a **Loss Not Decreasing** job. Explore these in SageMaker Studio.\n",
    "\n",
    "The next step will bring you to a new tab in SageMaker Studio. To follow these directions, use one of the following options:\n",
    "- **Option 1:** View the tabs side by side. To create a split screen view from the main SageMaker Studio window, either drag the **lab_7.ipynb** tab to the side or choose (right-click) the **lab_7.ipynb** tab and choose **New View for Notebook**. You can now have the directions visible as you explore the feature group.\n",
    "- **Option 2:** Switch between the SageMaker Studio tabs to follow these instructions.\n",
    "\n",
    "1. Choose the **SageMaker Home** icon.\n",
    "2. Choose **Experiments**.\n",
    "\n",
    "SageMaker studio opens the **Experiments** tab.\n",
    "\n",
    "3. Choose **Unassigned runs**.\n",
    "4. From the list, select the **Name** of the job, which has the Type **SageMakerTrainingJob**.\n",
    "\n",
    "Details of the Training job are displayed.\n",
    "\n",
    "5. On the left side, select the **Debugger** tab.\n",
    "\n",
    "SageMaker Debugger provides the status of your training job, which you can monitor while the model training is running. When complete, you will see the status of any specified training issues.\n",
    "\n",
    "The analysis is complete when all the **Status** lines display **No Issues Found** or **Issues Found**. The Debugger rules can take as long as 9 minutes to complete.\n",
    "\n",
    "If issues are found, it means that there are problems you might want to fix in your model. Are there any issues found for the jobs? \n",
    "\n",
    "In this lab, you do not resolve any issues found. However, if you want to resolve issues found, you can address them with a combination of processing the dataset and retraining the model with adjusted hyperparameters.\n",
    "\n",
    "6. When the analysis is complete, return to the notebook tab labeled **lab_7.ipynb**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-galaxy",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Task 2.5: Perform post-training analysis\n",
    "\n",
    "With SageMaker Debugger, you can create processing job logs in Amazon CloudWatch that you can use to configure custom alarms. Here, you print the location of where the logs are stored for each metric evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-command",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print-urls\n",
    "def _get_rule_job_name(training_job_name, rule_configuration_name, rule_job_arn):\n",
    "    \"\"\"Helper function to get the rule job name with correct casing\"\"\"\n",
    "    return \"{}-{}-{}\".format(\n",
    "        training_job_name[:26], rule_configuration_name[:26], rule_job_arn[-8:]\n",
    "    )\n",
    "\n",
    "\n",
    "def _get_cw_url_for_rule_job(rule_job_name, region):\n",
    "    return \"https://{}.console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/ProcessingJobs;prefix={};streamFilter=typeLogStreamPrefix\".format(\n",
    "        region, region, rule_job_name\n",
    "    )\n",
    "\n",
    "\n",
    "def get_rule_jobs_cw_urls(xgb):\n",
    "    region = boto3.Session().region_name\n",
    "    training_job = xgb.latest_training_job\n",
    "    training_job_name = training_job.describe()[\"TrainingJobName\"]\n",
    "    rule_eval_statuses = training_job.describe()[\"DebugRuleEvaluationStatuses\"]\n",
    "\n",
    "    result = {}\n",
    "    for status in rule_eval_statuses:\n",
    "        if status.get(\"RuleEvaluationJobArn\", None) is not None:\n",
    "            rule_job_name = _get_rule_job_name(\n",
    "                training_job_name, status[\"RuleConfigurationName\"], status[\"RuleEvaluationJobArn\"]\n",
    "            )\n",
    "            result[status[\"RuleConfigurationName\"]] = _get_cw_url_for_rule_job(\n",
    "                rule_job_name, region\n",
    "            )\n",
    "    return result\n",
    "\n",
    "\n",
    "get_rule_jobs_cw_urls(xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0280e9a7",
   "metadata": {},
   "source": [
    "Tensors can be retrieved by default collections such as weights, gradients, biases, and losses that SageMaker Debugger creates from your training job in addition to custom collections from tensors. Generate a list of names and values for the saved tensors to determine which tensors to plot for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-liquid",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#retrieve-names\n",
    "trial = create_trial(xgb.latest_job_debugger_artifacts_path())\n",
    "trial.tensor_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ef14b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve-values\n",
    "trial.tensor(\"average_shap/f1\").values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fba8e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot-tensors\n",
    "shap_values = trial.tensor(\"full_shap/f10\").value(trial.last_complete_step)\n",
    "shap_no_base = shap_values[:, :-1]\n",
    "shap_base_value = shap_values[0, -1]\n",
    "shap.summary_plot(shap_no_base, plot_type=\"bar\", feature_names=feature_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6e546ff",
   "metadata": {},
   "source": [
    "## Task 2.6: Access the SageMaker Debugger insights dashboard\n",
    "\n",
    "1. Return to the **Experiments** tab.\n",
    "2. On the left, select **Debugger**.\n",
    "3. In the **Debugger insights** section, select the available **lab-7-smdebugger-job** from the **Training job name** list.\n",
    "\n",
    "SageMaker Studio opens a new **Debugger insights tab** for the job and begins loading data.\n",
    "\n",
    "SageMaker Debugger provides an overview of your model training performance on Amazon Elastic Compute Cloud (Amazon EC2) instances. Explore SageMaker Debugger in SageMaker Studio and examine details contained in the reports.\n",
    "\n",
    "The **Systems Metrics** tab includes the following sections:\n",
    "\n",
    "- **Resource utilization summary**\n",
    "- **CPU utilization summary**\n",
    "- **GPU Utilization summary**\n",
    "\n",
    "The **Rules** tab includes the following **Insights**: \n",
    "\n",
    "- **BatchSize**\n",
    "- **LowGPUUtiliztion**\n",
    "- **CPUBottleneck**\n",
    "- **GPUMemoryIncrease**\n",
    "- **StepOutlier**\n",
    "- **MaxInitializationTime**\n",
    "- **IOBottleneck**\n",
    "- **LoadBalancing**\n",
    "\n",
    "Data will populate in the charts and tables if any issues were found.\n",
    "\n",
    "4. You can download a Debugger report by choosing the <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">Download report</span> near the top of the **Debugger insights** tab.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Congratulations! You have used SageMaker Debugger to analyze, detect, and create alerts for potential issues in model training. You can now use the information generated from your reports and alerts to provide insight into efficiently training and creating a more effective model. The next lab focuses on using SageMaker Clarify to detect bias and provide explainability for model predictions.\n",
    "\n",
    "### Cleanup\n",
    "\n",
    "You have completed this notebook. To move to the next part of the lab, do the following:\n",
    "\n",
    "- Close this notebook file.\n",
    "- Return to the lab session and continue with the **Conclusion**."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 239.460793,
   "end_time": "2021-06-01T00:16:48.734820",
   "environment_variables": {},
   "exception": true,
   "input_path": "pytorch_script_change_smdebug.ipynb",
   "output_path": "/opt/ml/processing/output/pytorch_script_change_smdebug-2021-06-01-00-08-41.ipynb",
   "parameters": {
    "kms_key": "arn:aws:kms:us-west-2:521695447989:key/6e9984db-50cf-4c7e-926c-877ec47a8b25"
   },
   "start_time": "2021-06-01T00:12:49.274027",
   "version": "2.3.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "2e45558c452cedcb26631315a9b3b77e80a9c32d662ed25df58964b99bc5b9b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
