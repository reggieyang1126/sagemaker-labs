{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10: Using SageMaker Pipelines and the SageMaker Model Registry with SageMaker Studio\n",
    "\n",
    "In this lab you create and run an Amazon Sagemaker Pipeline and monitor the pipeline's progress. You also locate and explore some of the artifacts that the machine learning (ML) process uses or generates.\n",
    "\n",
    "If time permits, you can also review the lineage details for the model that the pipeline generated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1 Environment setup\n",
    "\n",
    "Before you create your SageMaker pipeline, you must prepare the environment by installing necessary packages, importing modules, and staging supporting files. This pipeline was designed to use a feature group, so you also create a feature group in Amazon SageMaker Feature Store and run a Data Wrangler flow to prepare your environment. \n",
    "\n",
    "Run the cells in this task to do the following:\n",
    "- Install dependencies.\n",
    "- Import required modules.\n",
    "- Copy data and code to Amazon Simple Storage Service (Amazon S3).\n",
    "- Create a feature group.\n",
    "- Ingest features into the feature group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1.1 Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install dependencies\n",
    "%pip install --upgrade pip \n",
    "%pip install pytest-astropy ==  0.7.0\n",
    "%pip install rsa == 4.7.2\n",
    "%pip install PyYAML\n",
    "!apt update && apt install -y git\n",
    "%pip install git+https://github.com/aws-samples/ml-lineage-helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1.2 Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import-modules\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker_datawrangler\n",
    "import sagemaker.session\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import uuid\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.model_metrics import (\n",
    "    MetricsSource,\n",
    "    ModelMetrics,\n",
    ")\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    "    ScriptProcessor,\n",
    ")\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThan\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep,\n",
    "    TrainingStep,\n",
    ")\n",
    "from sagemaker.workflow.condition_step import (\n",
    "    ConditionStep,\n",
    "    JsonGet,\n",
    ")\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "from ml_lineage_helper import *\n",
    "from sagemaker.feature_store.feature_definition import FeatureDefinition\n",
    "from sagemaker.feature_store.feature_definition import FeatureTypeEnum\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import FeatureStoreOutput\n",
    "from sagemaker.processing import Processor\n",
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.dataset_definition.inputs import AthenaDatasetDefinition, DatasetDefinition, RedshiftDatasetDefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sessions\n",
    "boto_session  =  boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create clients\n",
    "s3_client = boto3.client('s3')\n",
    "featurestore_runtime = boto3.client('sagemaker-featurestore-runtime')\n",
    "sagemaker_client = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature store session\n",
    "feature_store_session = Session(\n",
    "    boto_session = boto_session,\n",
    "    sagemaker_client = sagemaker_client,\n",
    "    sagemaker_featurestore_runtime_client = featurestore_runtime\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set global variables\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "region = boto_session.region_name\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1.3 Copy lab files to Amazon S3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload files to default bucket\n",
    "s3_client.put_object(Bucket = default_bucket, Key = 'data/')\n",
    "s3_client.put_object(Bucket = default_bucket, Key = 'input/code/')\n",
    "s3_client.upload_file('pipelines/data/storedata_total.csv', default_bucket, 'data/storedata_total.csv')\n",
    "s3_client.upload_file('pipelines/input/code/evaluate.py', default_bucket, 'input/code/evaluate.py')\n",
    "s3_client.upload_file('pipelines/input/code/generate_config.py', default_bucket, 'input/code/generate_config.py')\n",
    "s3_client.upload_file('pipelines/input/code/processfeaturestore.py', default_bucket, 'input/code/processfeaturestore.py')\n",
    "\n",
    "# Preview the dataset\n",
    "print('Dataset preview:')\n",
    "customer_data = pd.read_csv('pipelines/data/storedata_total.csv')\n",
    "customer_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1.4 Create the feature group"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you create a feature group for the data. First, create a schema of the data. For this lab, the schema should be by the columns **name**, and then by **type** of variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set-up-feature-store-variables\n",
    "record_identifier_feature_name = 'FS_ID'\n",
    "event_time_feature_name = 'FS_time'\n",
    "\n",
    "column_schemas = [\n",
    "    {\n",
    "        \"name\": \"retained\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"esent\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"eopenrate\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"eclickrate\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"avgorder\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ordfreq\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"paperless\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"refill\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"doorstep\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"first_last_days_diff\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"created_first_days_diff\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Friday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Monday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Saturday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Sunday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Thursday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Tuesday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Wednesday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"city_BLR\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"city_BOM\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"city_DEL\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"city_MAA\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"FS_ID\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"FS_time\",\n",
    "        \"type\": \"float\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create the feature group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow name and a unique ID for this export (used later as the processing job name for the export)\n",
    "flow_name = 'featureengineer'\n",
    "flow_export_id = f\"{strftime('%d-%H-%M-%S', gmtime())}-{str(uuid.uuid4())[:8]}\"\n",
    "flow_export_name = f\"flow-{flow_export_id}\"\n",
    "\n",
    "# Feature group name, with flow_name and a unique id. You can give it a customized name\n",
    "feature_group_name = f\"FG-{flow_name}-{str(uuid.uuid4())[:8]}\"\n",
    "\n",
    "# SageMaker Feature Store writes the data in the offline store of a Feature Group to a \n",
    "# Amazon S3 location owned by you.\n",
    "feature_store_offline_s3_uri = 's3://' + default_bucket\n",
    "\n",
    "# Controls if online store is enabled. Enabling the online store allows quick access to \n",
    "# the latest value for a record by using the GetRecord API.\n",
    "enable_online_store = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create-feature-group\n",
    "default_feature_type = FeatureTypeEnum.STRING\n",
    "column_to_feature_type_mapping = {\n",
    "    \"float\": FeatureTypeEnum.FRACTIONAL,\n",
    "    \"long\": FeatureTypeEnum.INTEGRAL\n",
    "}\n",
    "\n",
    "feature_definitions = [\n",
    "    FeatureDefinition(\n",
    "        feature_name = column_schema['name'], \n",
    "        feature_type = column_to_feature_type_mapping.get(column_schema['type'], default_feature_type)\n",
    "    ) for column_schema in column_schemas\n",
    "]\n",
    "\n",
    "\n",
    "print(f\"Feature Group Name: {feature_group_name}\")\n",
    "\n",
    "# Confirm the Athena settings are configured\n",
    "try:\n",
    "    boto3.client('athena').update_work_group(\n",
    "        WorkGroup = 'primary',\n",
    "        ConfigurationUpdates = {\n",
    "            'EnforceWorkGroupConfiguration':False\n",
    "        }\n",
    "    )\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "feature_group = FeatureGroup(\n",
    "    name = feature_group_name, sagemaker_session = feature_store_session, feature_definitions = feature_definitions)\n",
    "\n",
    "feature_group.create(\n",
    "    s3_uri = feature_store_offline_s3_uri,\n",
    "    record_identifier_name = record_identifier_feature_name,\n",
    "    event_time_feature_name = event_time_feature_name,\n",
    "    role_arn = role,\n",
    "    enable_online_store = enable_online_store\n",
    ")\n",
    "\n",
    "def wait_for_feature_group_creation_complete(feature_group):\n",
    "    \"\"\"Helper function to wait for the completions of creating a feature group\"\"\"\n",
    "    response = feature_group.describe()\n",
    "    status = response.get(\"FeatureGroupStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for feature group creation\")\n",
    "        time.sleep(5)\n",
    "        response = feature_group.describe()\n",
    "        status = response.get(\"FeatureGroupStatus\")\n",
    "\n",
    "    if status != \"Created\":\n",
    "        print(f\"Failed to create feature group, response: {response}\")\n",
    "        failureReason = response.get(\"FailureReason\", \"\")\n",
    "        raise SystemExit(\n",
    "            f\"Failed to create feature group {feature_group.name}, status: {status}, reason: {failureReason}\"\n",
    "        )\n",
    "    print(f\"Feature Group {feature_group.name} successfully created.\")\n",
    "\n",
    "wait_for_feature_group_creation_complete(feature_group = feature_group)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1.5 Ingest features\n",
    "\n",
    "This process takes approximately 8 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate-feature-store\n",
    "column_list = ['retained','esent','eopenrate','eclickrate','avgorder','ordfreq','paperless','refill','doorstep','first_last_days_diff','created_first_days_diff','favday_Friday','favday_Monday', 'favday_Saturday','favday_Sunday','favday_Thursday','favday_Tuesday','favday_Wednesday','city_BLR','city_BOM','city_DEL','city_MAA','FS_ID','FS_time']\n",
    "lab_test_data = pd.read_csv('featureengineer_data/store_data_processed.csv', names = (column_list), header = 1)\n",
    "feature_group.ingest(data_frame = lab_test_data, wait = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2 Create and run a SageMaker pipeline\n",
    "\n",
    "Now that your environment is set up, you configure, create, and start a SageMaker pipeline. \n",
    "\n",
    "A SageMaker pipeline is a workflow that runs a set of dependent steps. Steps can accept inputs and send outputs, so data and other assets can be passed between them. \n",
    "\n",
    "Run the following cells to:\n",
    "- Define variables that are needed to configure the pipeline.\n",
    "- Configure a SageMaker session.\n",
    "- Define the pipeline steps.\n",
    "- Configure the pipeline.\n",
    "- Create the pipeline.\n",
    "- Start the pipeline.\n",
    "- Describe the pipeline.\n",
    "- Create a wait event so that the notebook does not proceed until the pipeline has finished running."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2.1 Set up the variables that the pipeline uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pipeline-variables\n",
    "feature_group_name = feature_group.name\n",
    "model_name = \"Churn-model\"\n",
    "\n",
    "sklearn_processor_version = \"0.23-1\"\n",
    "model_package_group_name = \"ChurnModelPackageGroup\"\n",
    "pipeline_name = \"ChurnModelSMPipeline\"\n",
    "\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name = \"ProcessingInstanceCount\",\n",
    "    default_value = 1\n",
    "    )\n",
    "\n",
    "processing_instance_type = ParameterString(\n",
    "        name = \"ProcessingInstanceType\",\n",
    "        default_value = \"ml.m5.xlarge\"\n",
    "    )\n",
    "\n",
    "training_instance_type = ParameterString(\n",
    "        name = \"TrainingInstanceType\",\n",
    "        default_value = \"ml.m5.xlarge\"\n",
    "    )\n",
    "\n",
    "input_data = ParameterString(\n",
    "        name = \"InputData\",\n",
    "        default_value = \"s3://{}/data/storedata_total.csv\".format(default_bucket), \n",
    "    )\n",
    "\n",
    "batch_data = ParameterString(\n",
    "        name = \"BatchData\",\n",
    "        default_value = \"s3://{}/data/batch/batch.csv\".format(default_bucket),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2.2 Configure the pipeline\n",
    "\n",
    "You define a pipeline named **ChurnModelPipeline** to produce a model that evaluates the likelihood of retaining or losing customers. This pipeline has nine steps. \n",
    "\n",
    "Each step in a pipeline runs a specific job type. The required inputs for a job vary based on the job type. Refer to [Step Types](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#build-and-manage-steps-types) for more information about SageMaker pipeline step types.\n",
    "\n",
    "Review the code in the following cells to understand how each step was defined:\n",
    "\n",
    "The **ChurnModelProcess** step is defined in the variable named **step_process**. \n",
    "\n",
    "Step configuration includes the following:\n",
    "- **Type:** Processing – Processing jobs are defined using the class ProcessingStep().\n",
    "- **Processor:** SKLearnProcessor.\n",
    "- **Destination:** Output will be sent to folders under your default S3 bucket.\n",
    "- **Job Arguments:** This step will use the Feature Store to process the dataset.\n",
    "- **Code:** **processfeaturestore.py**, which resides in your default S3 bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-processing-step\n",
    "# Run a scikit-learn script to do data processing on SageMaker \n",
    "# using the SKLearnProcessor class\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "        framework_version = sklearn_processor_version,\n",
    "        instance_type = processing_instance_type.default_value, \n",
    "        instance_count = processing_instance_count,\n",
    "        sagemaker_session = sagemaker_session,\n",
    "        role = role,\n",
    "    )\n",
    "\n",
    "# Inputs, outputs, and code are parameters to the processor\n",
    "# step_* will become the pipeline steps toward the end of the cell\n",
    "# in this case, use the feature store as input, so there is no externalinput\n",
    "step_process = ProcessingStep(\n",
    "        name = \"ChurnModelProcess\",\n",
    "        processor = sklearn_processor,\n",
    "        outputs = [\n",
    "            ProcessingOutput(output_name = \"train\", source = \"/opt/ml/processing/train\",\\\n",
    "                             destination = f\"s3://{default_bucket}/output/train\" ),\n",
    "            ProcessingOutput(output_name = \"validation\", source = \"/opt/ml/processing/validation\",\\\n",
    "                            destination = f\"s3://{default_bucket}/output/validation\"),\n",
    "            ProcessingOutput(output_name = \"test\", source = \"/opt/ml/processing/test\",\\\n",
    "                            destination = f\"s3://{default_bucket}/output/test\"),\n",
    "            ProcessingOutput(output_name = \"batch\", source = \"/opt/ml/processing/batch\",\\\n",
    "                            destination = f\"s3://{default_bucket}/data/batch\"),\n",
    "            ProcessingOutput(output_name = \"baseline\", source = \"/opt/ml/processing/baseline\",\\\n",
    "                            destination = f\"s3://{default_bucket}/input/baseline\")\n",
    "        ],\n",
    "        job_arguments = [\"--featuregroupname\",feature_group_name,\"--default-bucket\",default_bucket,\"--region\",region],\n",
    "        code = f\"s3://{default_bucket}/input/code/processfeaturestore.py\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **ChurnHyperParameterTuning** step is defined in the variable named **step_tuning**. \n",
    "\n",
    "Step configuration includes the following:\n",
    "- **Type:** Tuning – Tuning jobs are defined using the class TuningStep().\n",
    "- **Tuner:** This job uses the XGBoost framework.\n",
    "- **Inputs:** Notice that this job uses the training and validation data that was produced by the ChurnModelProcess step, **step_process**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-churn-hyperparameter-tuning\n",
    "# Training/tuning step for generating model artifacts\n",
    "model_path = f\"s3://{default_bucket}/output\"\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework = \"xgboost\",\n",
    "    region = region,\n",
    "    version = \"1.5-1\",\n",
    "    py_version = \"py3\",\n",
    "    instance_type = training_instance_type.default_value,\n",
    ")\n",
    "\n",
    "fixed_hyperparameters = {\n",
    "    \"eval_metric\":\"auc\",\n",
    "    \"objective\":\"binary:logistic\",\n",
    "    \"num_round\":\"100\",\n",
    "    \"rate_drop\":\"0.3\",\n",
    "    \"tweedie_variance_power\":\"1.4\"\n",
    "    }\n",
    "\n",
    "xgb_train = Estimator(\n",
    "    image_uri = image_uri,\n",
    "    instance_type = training_instance_type,\n",
    "    instance_count = 1,\n",
    "    hyperparameters = fixed_hyperparameters,\n",
    "    output_path = model_path,\n",
    "    base_job_name = f\"churn-train\",\n",
    "    sagemaker_session = sagemaker_session,\n",
    "    role = role\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning steps\n",
    "hyperparameter_ranges = {\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "    \"min_child_weight\": ContinuousParameter(1, 10),\n",
    "    \"alpha\": ContinuousParameter(0, 2),\n",
    "    \"max_depth\": IntegerParameter(1, 10),\n",
    "    }\n",
    "objective_metric_name = \"validation:auc\"\n",
    "\n",
    "step_tuning = TuningStep(\n",
    "    name = \"ChurnHyperParameterTuning\",\n",
    "    tuner = HyperparameterTuner(xgb_train, objective_metric_name, hyperparameter_ranges, max_jobs = 2, max_parallel_jobs = 2),\n",
    "    inputs = {\n",
    "            \"train\": TrainingInput(\n",
    "                s3_data = step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"train\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type = \"text/csv\",\n",
    "            ),\n",
    "            \"validation\": TrainingInput(\n",
    "                s3_data = step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"validation\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type = \"text/csv\",\n",
    "            ),\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **ChurnEvalBestModel** step is defined in the variable named **step_eval**. \n",
    "\n",
    "Step configuration includes the following:\n",
    "- **Type:** Processing.\n",
    "- **Processor:** ScriptProcessor.\n",
    "- **Inputs:** Notice that this job uses the top model from ChurnHyperParameterTuning (**step_tuning**) and the test output from ChurnModelProcess (**step_process**).\n",
    "- **Outputs:** Output is written to the default S3 bucket.\n",
    "- **Code:** A script named **evaluate.py**, which resides in Amazon S3, is used for the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-churn-best-model\n",
    "evaluation_report = PropertyFile(\n",
    "    name = \"ChurnEvaluationReport\",\n",
    "    output_name = \"evaluation\",\n",
    "    path = \"evaluation.json\",\n",
    ")\n",
    "\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri = image_uri,\n",
    "    command = [\"python3\"],\n",
    "    instance_type = processing_instance_type,\n",
    "    instance_count = 1,\n",
    "    base_job_name = \"script-churn-eval\",\n",
    "    role = role,\n",
    "    sagemaker_session = sagemaker_session,\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name = \"ChurnEvalBestModel\",\n",
    "    processor = script_eval,\n",
    "    inputs = [\n",
    "        ProcessingInput(\n",
    "            source = step_tuning.get_top_model_s3_uri(top_k = 0, s3_bucket = default_bucket, prefix = \"output\"),\n",
    "            destination = \"/opt/ml/processing/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source = step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri,\n",
    "            destination = \"/opt/ml/processing/test\"\n",
    "        )\n",
    "    ],\n",
    "    outputs = [\n",
    "        ProcessingOutput(output_name = \"evaluation\", source = \"/opt/ml/processing/evaluation\",\\\n",
    "                            destination = f\"s3://{default_bucket}/output/evaluation\"),\n",
    "    ],\n",
    "    code = f\"s3://{default_bucket}/input/code/evaluate.py\",\n",
    "    property_files = [evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **ChurnCreateModel** step is defined in the variable named **step_create_model**. \n",
    "\n",
    "Step configuration includes the following:\n",
    "- **Type:** Model – Model jobs are defined using the class Model().\n",
    "- **Model:** The model used by the step is defined in the previously defined variable named **model**. Notice that the **model** variable uses the top model that was created by ChurnHyperParameterTuning (**step_tuning**).\n",
    "- **Inputs:** The inputs include an instance type and an accelerator type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-model-creation\n",
    "model = Model(\n",
    "    image_uri = image_uri,        \n",
    "    model_data = step_tuning.get_top_model_s3_uri(top_k = 0,s3_bucket = default_bucket,prefix = \"output\"),\n",
    "    name = model_name,\n",
    "    sagemaker_session = sagemaker_session,\n",
    "    role = role,\n",
    ")\n",
    "\n",
    "inputs = CreateModelInput(\n",
    "    instance_type = \"ml.m5.large\",\n",
    "    accelerator_type = \"ml.inf1.xlarge\",\n",
    ")\n",
    "\n",
    "step_create_model = CreateModelStep(\n",
    "    name = \"ChurnCreateModel\",\n",
    "    model = model,\n",
    "    inputs = inputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **ChurnModelConfigFile** step is defined in the variable named **step_config_file**. \n",
    "\n",
    "Step configuration includes the following:\n",
    "- **Type:** Processing.\n",
    "- **Processor:** ScriptProcessor.\n",
    "- **Code:** **generate_config.py**, which resides in your default S3 bucket.\n",
    "- **Job Arguments:** Job arguments include the model that was generated by **ChurnCreateModel**, the path to the bias report, the default bucket, the number of samples, and the number of instances used for processing.\n",
    "- **Depends On:** Notice that this job cannot run until the model creation has completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#configure-script-processing\n",
    "bias_report_output_path = f\"s3://{default_bucket}/clarify-output/bias\"\n",
    "clarify_instance_type = 'ml.m5.xlarge'\n",
    "analysis_config_path = f\"s3://{default_bucket}/clarify-output/bias/analysis_config.json\"\n",
    "clarify_image = sagemaker.image_uris.retrieve(framework = 'sklearn', version = sklearn_processor_version, region = region)\n",
    "\n",
    "#custom_image_uri = None\n",
    "script_processor = ScriptProcessor(\n",
    "    command = ['python3'],\n",
    "    image_uri = clarify_image,\n",
    "    role = role,\n",
    "    instance_count = 1,\n",
    "    instance_type = processing_instance_type,\n",
    "    sagemaker_session = sagemaker_session,\n",
    ")\n",
    "\n",
    "step_config_file = ProcessingStep(\n",
    "    name = \"ChurnModelConfigFile\",\n",
    "    processor = script_processor,\n",
    "    code = f\"s3://{default_bucket}/input/code/generate_config.py\",\n",
    "    job_arguments = [\"--modelname\", step_create_model.properties.ModelName, \"--bias-report-output-path\", bias_report_output_path, \"--clarify-instance-type\", clarify_instance_type,\\\n",
    "                  \"--default-bucket\", default_bucket, \"--num-baseline-samples\", \"50\", \"--instance-count\", \"1\"],\n",
    "    depends_on = [step_create_model.name]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **ChurnTransform** step is defined in the variable named **step_transform**. \n",
    "\n",
    "Step configuration includes the following:\n",
    "- **Type:** Transform – Transform jobs are defined using the class TransformStep().\n",
    "- **Transformer:** The transformer details are set in the previously defined variable named **transformer**. Notice that this variable is using the model that was created in ChurnCreateModel (**step_create_model**).\n",
    "- **Inputs:** The data that will be transformed, batch.csv, which was defined earlier in the notebook. The input also includes the file type and how it should be split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-inference\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type = \"ml.m5.xlarge\",\n",
    "    instance_count = 1,\n",
    "    assemble_with = \"Line\",\n",
    "    accept = \"text/csv\",    \n",
    "    output_path = f\"s3://{default_bucket}/ChurnTransform\"\n",
    "    )\n",
    "\n",
    "step_transform = TransformStep(\n",
    "    name = \"ChurnTransform\",\n",
    "    transformer = transformer,\n",
    "    inputs = TransformInput(data = batch_data, content_type = \"text/csv\", join_source = \"Input\", split_type = \"Line\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **ClarifyProcessingStep** step is defined in the variable named **step_clarify**. \n",
    "\n",
    "Step configuration includes the following:\n",
    "- **Type:** Processing.\n",
    "- **Processor:** This job uses SageMakerClarifyProcessor. You can review the processor configuration in the variable named **clarify_processor**.\n",
    "- **Inputs:** The inputs are defined in the **data_input** and **congif_input** variables.\n",
    "- **Outputs:** The output is written to a folder under the default bucket. \n",
    "- **Depends On:**  Notice that this job cannot run until the configuration file required by Amazon SageMaker Clarify has been created by the **ChurnModelConfigFile**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-clarify-processing\n",
    "data_config = sagemaker.clarify.DataConfig(\n",
    "s3_data_input_path = f's3://{default_bucket}/output/train/train.csv',\n",
    "s3_output_path = bias_report_output_path,\n",
    "    label = 0,\n",
    "    headers = ['target','esent','eopenrate','eclickrate','avgorder','ordfreq','paperless','refill','doorstep','first_last_days_diff','created_first_days_diff','favday_Friday','favday_Monday','favday_Saturday','favday_Sunday','favday_Thursday','favday_Tuesday','favday_Wednesday','city_BLR','city_BOM','city_DEL','city_MAA'],\n",
    "    dataset_type = \"text/csv\",\n",
    ")\n",
    "\n",
    "clarify_processor = sagemaker.clarify.SageMakerClarifyProcessor(\n",
    "    role = role,\n",
    "    instance_count = 1,\n",
    "    instance_type = clarify_instance_type,\n",
    "    sagemaker_session = sagemaker_session,\n",
    ")\n",
    "\n",
    "config_input = ProcessingInput(\n",
    "    input_name = \"analysis_config\",\n",
    "    source=analysis_config_path,\n",
    "    destination = \"/opt/ml/processing/input/analysis_config\",\n",
    "    s3_data_type = \"S3Prefix\",\n",
    "    s3_input_mode = \"File\",\n",
    "    s3_compression_type = \"None\",\n",
    "    )\n",
    "\n",
    "data_input = ProcessingInput(\n",
    "    input_name = \"dataset\",\n",
    "    source = data_config.s3_data_input_path,\n",
    "    destination = \"/opt/ml/processing/input/data\",\n",
    "    s3_data_type = \"S3Prefix\",\n",
    "    s3_input_mode = \"File\",\n",
    "    s3_data_distribution_type = data_config.s3_data_distribution_type,\n",
    "    s3_compression_type = data_config.s3_compression_type,\n",
    ")\n",
    "\n",
    "result_output = ProcessingOutput( \n",
    "    source = \"/opt/ml/processing/output\",\n",
    "    destination = data_config.s3_output_path,\n",
    "    output_name = \"analysis_result\",\n",
    "    s3_upload_mode = \"EndOfJob\",\n",
    ")\n",
    "\n",
    "step_clarify = ProcessingStep(\n",
    "    name = \"ClarifyProcessingStep\",\n",
    "    processor = clarify_processor,\n",
    "    inputs = [data_input, config_input],\n",
    "    outputs = [result_output],\n",
    "    depends_on = [step_config_file.name]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **RegisterChurnModel** step is defined in the variable named **step_register**. \n",
    "\n",
    "Step configuration includes the following:\n",
    "- **Type:** Register Model – Register jobs are defined using the class RegisterMode().\n",
    "- **Estimator:** The estimator is defined in the **xgbtrain** variable earlier in the cell.\n",
    "- **Model Data:** This is the model URI that is returned by **ChurnHyperParameterTuning**.\n",
    "- **Content Types:** text/csv\n",
    "- **Response Types** text/csv\n",
    "- **Inference Instance:** This is the instance type that will be used for inference processing.\n",
    "- **Transform Instance:** This is the instance type that will be used to process transformations.\n",
    "- **Model Package Group Name:** This is the name of the group that will store the group of model versions.\n",
    "- **Model Metrics:** This defines the location of the model metrics. Files included are the SageMaker Clarify bias report, SageMaker Clarify explainability report, and the model evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-model-registry\n",
    "model_statistics = MetricsSource(\n",
    "    s3_uri = \"s3://{}/output/evaluation/evaluation.json\".format(default_bucket),\n",
    "    content_type = \"application/json\"\n",
    "    )\n",
    "explainability = MetricsSource(\n",
    "    s3_uri = \"s3://{}/clarify-output/bias/analysis.json\".format(default_bucket),\n",
    "    content_type = \"application/json\"\n",
    "    )\n",
    "\n",
    "bias = MetricsSource(\n",
    "    s3_uri = \"s3://{}/clarify-output/bias/analysis.json\".format(default_bucket),\n",
    "    content_type = \"application/json\"\n",
    "    ) \n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics = model_statistics,\n",
    "    explainability = explainability,\n",
    "    bias = bias\n",
    ")\n",
    "\n",
    "step_register = RegisterModel(\n",
    "    name = \"RegisterChurnModel\",\n",
    "    estimator = xgb_train,\n",
    "    model_data = step_tuning.get_top_model_s3_uri(top_k = 0, s3_bucket = default_bucket, prefix = \"output\"),\n",
    "    content_types = [\"text/csv\"],\n",
    "    response_types = [\"text/csv\"],\n",
    "    inference_instances = [\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "    transform_instances = [\"ml.m5.large\"],\n",
    "    model_package_group_name = model_package_group_name,\n",
    "    model_metrics = model_metrics,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **CheckAUCScoreChurnEvaluation** step is defined in the variable named **step_cond**. \n",
    "\n",
    "Step configuration includes the following:\n",
    "- **Type:** Condition – Condition jobs are defined using the class ConditionStep().\n",
    "- **Conditions:** This condition evaluates to True if the output from **ChurnEvalBestModel** is greater than 0.75.\n",
    "- **If Steps:** This is the list of steps that runs if the condition evaluates to True.\n",
    "- **Else Steps:** This is the list of steps that run if the condition evaluates to False. Notice that this list is empty, which means the pipeline stops processing if the condition is not met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "cond_lte = ConditionGreaterThan(\n",
    "    left = JsonGet(\n",
    "        step = step_eval,\n",
    "        property_file = evaluation_report,\n",
    "        json_path = \"binary_classification_metrics.auc.value\"\n",
    "    ),\n",
    "    right = 0.75,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name = \"CheckAUCScoreChurnEvaluation\",\n",
    "    conditions = [cond_lte],\n",
    "    if_steps = [step_create_model, step_config_file, step_transform, step_clarify, step_register],\n",
    "    else_steps = [],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2.3 Define the pipeline\n",
    "\n",
    "After you define the steps, you configure the pipeline in the variable named **pipeline**. Notice how steps that were previously defined are passed into the pipeline definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #define pipeline function\n",
    "def get_pipeline(\n",
    "    region,\n",
    "    role = None,\n",
    "    default_bucket = None,\n",
    "    model_package_group_name = \"ChurnModelPackageGroup\",\n",
    "    pipeline_name = \"ChurnModelPipeline\",\n",
    "    base_prefix = None,\n",
    "    custom_image_uri = None,\n",
    "    sklearn_processor_version = None\n",
    "    ):\n",
    "\n",
    "    #configure pipeline instance\n",
    "    pipeline = Pipeline(\n",
    "        name = pipeline_name,\n",
    "        parameters = [\n",
    "            processing_instance_type,\n",
    "            processing_instance_count,\n",
    "            training_instance_type,\n",
    "            input_data,\n",
    "            batch_data,\n",
    "        ],\n",
    "        steps = [step_process, step_tuning, step_eval, step_cond],\n",
    "        sagemaker_session = sagemaker_session\n",
    "    )\n",
    "    return pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2.4 Create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #create pipeline using function\n",
    "pipeline = get_pipeline(\n",
    "  region = region,\n",
    "    role = role,\n",
    "    default_bucket = default_bucket,\n",
    "    model_package_group_name = model_package_group_name,\n",
    "    pipeline_name = pipeline_name,\n",
    "    custom_image_uri = clarify_image,\n",
    "    sklearn_processor_version = sklearn_processor_version\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2.5 Update the pipeline to use the correct IAM role. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set-iam-role\n",
    "pipeline.upsert(role_arn = role)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you find the following warning after running the cell, you can safely ignore it.\n",
    "\n",
    "\"No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2.6 Start the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start-pipeline\n",
    "RunPipeline = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2.7 Describe the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe-pipeline\n",
    "RunPipeline.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pipeline takes about 35 minutes to run.\n",
    "\n",
    "While the pipeline is running, continue to the next task to explore the pipeline in the Amazon SageMaker Studio console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.3 Monitor and approve the pipeline\n",
    "\n",
    "In this task, you explore the pipeline using the  Amazon SageMaker Studio console.\n",
    "\n",
    "### Task 2.3.1 Monitor the pipeline in SageMaker Studio\n",
    "\n",
    "The next task opens new tab in SageMaker Studio. To follow these directions, use one of the following options:\n",
    "- **Option 1:** View the tabs side by side. To create a split screen view from the main SageMaker Studio window, either drag the **lab_10.ipynb** tab to the side or choose (right-click) the **lab_10.ipynb** tab and select **New View for Notebook**. You can now have the directions displayed as you explore the pipeline steps.\n",
    "- **Option 2:** Switch between the SageMaker Studio tabs to follow these instructions. When you are finished exploring the pipeline steps, return to the notebook by selecting the **lab_10.ipynb** tab.\n",
    "\n",
    "1. In SageMaker Studio, choose the **SageMaker Home** icon.\n",
    "1. Choose **Pipelines**.\n",
    "\n",
    "SageMaker Studio opens the **Pipelines** tab.\n",
    "\n",
    "1. Select the pipeline named **ChurnModelSMPipeline**. \n",
    "\n",
    "SageMaker Studio opens the **ChurnModelSMPipeline** tab.\n",
    "\n",
    "1. In the **ChurnModelSMPipeline** tab, under **Executions**, open (right-click) the pipeline status, and then choose **Open execution details**. \n",
    "\n",
    "SageMaker Studio opens the **Directed Acyclic Graph** (DAG) page.\n",
    "\n",
    "The Directed Acyclic Graph (DAG) shows the pipeline's workflow and progress. Colors are used to indicate the status of a step. The step color indicators are:\n",
    "- **gray:** waiting to run.\n",
    "- **blue:** running.\n",
    "- **green:** completed successfully.\n",
    "- **red:** error.\n",
    "\n",
    "Each step that you explore has the same four tabs in the step's details pane. Although the tab titles are the same, the contents of each tab varies depending on the job type, and the job's configuration:\n",
    "\n",
    "- **Input:** This tab contains inputs that were passed to the job. Examples of inputs are parameters that specify instance types, AWS Identity and Access Management (IAM) roles, or arguments needed to run the job. Other input examples include files such as code, data sets, and Docker images.\n",
    "- **Output:** This tab shows the output that the job created. Some examples of outputs are metrics, charts, files, and evaluation outcomes.\n",
    "- **Logs:** This tab provides a list of logs associated with the job. If the user has sufficient privileges to Amazon CloudWatch logs, users can choose the logs link and view detailed log messages in CloudWatch. Some job types do not generate logs.\n",
    "- **Information:** This tab provides basic information about a job such as the job type, job name, and when the job ran.\n",
    "\n",
    "1. Choose the step named **ChurnModelProcess**. A new pane named **ChurnModelProcess** is displayed.\n",
    "1. In the **ChurnModelProcess** pane, review the tabs associated with this pipeline step: \n",
    "    - Choose the **Input** tab. This tab contains helpful information about the parameters and files that the processing step uses. In the parameters list, there are details including the instance type and image that the job uses, dataset location, code location, and destinations for the different outputs that are generated. Scroll to the bottom of the pane to find the file inputs that were passed to the job.\n",
    "    - Choose the **Output** tab. This tab shows the different files that the pipeline step generates and where they are placed. This pipeline places all outputs in the SageMaker Studio default bucket.\n",
    "    - Choose the **Logs** tab. This tab shows the logs that the job generates. Having the logging available inside SageMaker Studio speeds up investigation and troubleshooting when a pipeline step fails to run successfully.\n",
    "    - Choose the **Information** tab. This tab provides a high-level overview of the pipeline step. It includes information such as the step type, step name, and a link to the job log. It also provides details about when the job ran and how long it took to run.\n",
    "        - Notice that the **Step Type** is **Processing**.\n",
    "\n",
    "### Task 2.3.2 Discover pipeline step details\n",
    "\n",
    "In the following steps, you choose the appropriate node from the directed acyclic graph (DAG) to find information about a given pipeline step. If you need help finding the answers, correct responses or hints are included at the end of this python notebook.\n",
    "\n",
    "1. For the step named **ChurnHyperParameterTuning**, locate the following details:\n",
    "    - What is the **Step Type** for this step?\n",
    "    - What was the **Overall Best Training Job** generated by this step?\n",
    "1. For the step named **ChurnEvalBestModel**, locate the following details:\n",
    "    - What is the **Step Type** for this step?\n",
    "    - What is the name of the Python script that is used to evaluate the top model that was identified in the previous step?\n",
    "    - Where is this file located?\n",
    "    - Where were the results from this step written?\n",
    "1. For the step named **CheckAUCScoreChurnEvaluation**, locate the following details:\n",
    "    - What is the **Step Type** for this step?\n",
    "    - What was the **Evaluation outcome**?\n",
    "1. For the step named **ChurnCreateModel**, locate the following details:\n",
    "    - What is the **Step Type** for this step?\n",
    "    - Did this job generate any logs?\n",
    "1. For the step named **RegisterChurnModel**, locate the following details:\n",
    "    - What is the **Step Type** for this step?\n",
    "    - What is value for the area under the curve (AUC) metric?\n",
    "1. For the step named **ChurnTransform**, locate the following details:\n",
    "    - What is the **Step Type** for this step?\n",
    "    - Did this job generate logs?\n",
    "    - Which files were inputs for this step?\n",
    "1. For the step named **ChurnModelConfigFile**, locate the following details: \n",
    "    - Which ProcessingInstanceType was used to run this job?\n",
    "    - What is the **Step Type** for this step?\n",
    "1. For the step named **ClarifyProcessingStep**, locate the following details:\n",
    "    - What was the file output from this step?\n",
    "    - Where was the output written?\n",
    "\n",
    "### 2.3.3 Approve the model in the pipeline\n",
    "\n",
    "1. After the pipeline has finished running, view the model that the pipeline created in the **Model registry**:\n",
    "    - In SageMaker Studio, choose the **SageMaker Home** icon.\n",
    "    - Expand the **Models** list.\n",
    "    - Choose **Model registry**.\n",
    "    - Open the Model group named **ChurnModelPackageGroup**.\n",
    "    - In the **ChurnModelPackageGroup** tab, open (right-click) the row in the **Versions** table and choose **Open model version**. Notice that the model status is **Pending**. Also, notice that the **Execution** value is the name of the pipeline run that just completed.\n",
    "\n",
    "    Additional details about the pipeline are found in each tab:\n",
    "    - **Activity:** This tab shows activity for the model. It contains event information and how long it has been since the model was modified.\n",
    "    - **Model quality:** This tab shows model accuracy metrics.\n",
    "    - **Explainability:** This tab shows the importance of the model's features in terms of Shapley Values (SHAP).\n",
    "    - **Bias report:** This tab shows potential model bias.\n",
    "    - **Inference recommender:** This tab provides recommendations to improve the price performance of a model. This tab does not contain data because this feature is not supported for this model package.\n",
    "    - **Load test:** From this tab you can launch load tests to try different instance types and evaluate them for required throughput and latency metrics that are required for a production deployment.\n",
    "    - **Settings:** This tab shows information such as when the model was created, which pipeline generated the model, where the model is located, and the trial component associated with the model.\n",
    "\n",
    "1. Approve the model. This process is designed for manual review before approving the model. However, it is possible to automate the model approval within the pipeline:\n",
    "    - Choose <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">**Update status**</span>.\n",
    "    - Open the dropdown list and choose <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">**Approved**</span>.\n",
    "    - Choose <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">**Update status**</span>.\n",
    "1. Close the **ChurnModelPackageGroup** tab.\n",
    "\n",
    "### Task 2.3.4 View the pipeline steps using the AWS SDK\n",
    "\n",
    "In addition to using the SageMaker Studio UI to view pipeline details, you can also use AWS SDK commands. For example, the following command returns a list of the pipeline steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list-steps\n",
    "RunPipeline.list_steps()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.4 Review the artifacts\n",
    "\n",
    "The next task opens a new tab in SageMaker Studio. To follow these directions, use one of the following options:\n",
    "- **Option 1:** View the tabs side by side. To create a split screen view from the main SageMaker Studio window, either drag the **lab_10.ipynb** tab to the side or choose (right-click) the **lab_10.ipynb** tab and choose **New View for Notebook**. You can now have the directions displayed as you explore the artifacts.\n",
    "- **Option 2:** Switch between the SageMaker Studio tabs to follow these instructions. When you are finished exploring the artifacts, return to the notebook by choosing the **lab_10.ipynb** tab.\n",
    "\n",
    "### Task 2.4.1 Review the artifacts in SageMaker Studio\n",
    "\n",
    "As the pipeline ran, each step generated artifacts such as files, trained parameters, and models. You can identify artifacts that the pipeline in SageMaker Studio created.\n",
    "1. Return to the tab named **ChurnModelSMPipeline**.\n",
    "1. Select the **Executions** tab.\n",
    "1. Open (right-click) the listed execution and choose **View trial components generated by execution**. \n",
    "\n",
    "SageMaker Studio opens a new tab named **Trial Component List**. \n",
    "\n",
    "A list of all the jobs that the pipeline ran is displayed.\n",
    "\n",
    "Notice that each trial component, has a **Trial Component Type**. Information available under the various tabs in the associated trial detail depend on the trial component type. Not all tabs under trial detail are populated with data for all component types.\n",
    "\n",
    "1. Open (right-click) the top row in the list of jobs and choose **Open in trial details**. \n",
    "\n",
    "SageMaker Studio opens a new tab named **Describe Trial Component**. \n",
    "\n",
    "Under **Trial Components**, multiple tabs are available. Depending on what a pipeline step was doing, some tabs might be empty. \n",
    "\n",
    "1. Choose the **Artifacts** tab. The details of both the input and the output used in the step.\n",
    "1. Choose the **Explainability** tab. This tab shows the explainability report that SageMaker Clarify generated.\n",
    "1. Choose the **Bias Report** tab. This tab shows the bias report that SageMaker Clarify generated.\n",
    "\n",
    "### Task 2.4.2 Locate the artifacts in the default S3 bucket\n",
    "**Note:** You use the AWS Management Console for this task. After you have explored the S3 bucket, return to the browser tab where SageMaker Studio is open and choose the **lab_10.ipynb** tab.\n",
    "\n",
    "1. On the browser tab where the console is open, navigate to Amazon S3.\n",
    "1. Choose the bucket name that begins with **sagemaker-** and the AWS Region; for example **sagemaker-us-west-2-123456789**.\n",
    "1. Explore the folders and files under this bucket. This bucket contains the dataset, processing inputs and outputs, the SageMaker Clarify results, and other files that contributed to the resulting model.\n",
    "1. Return to the browser tab where SageMaker Studio is open and choose the **lab_10.ipynb** tab."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.5 (Optional) Build and review the lineage for the pipeline\n",
    "\n",
    "You learned how to use SageMaker Clarify to help explain how a model makes predictions and understand the potential bias of a model. You can also use SageMaker Clarify to discover the steps that are used to generate the model, which are often needed for model auditing. In this task you take advantage of the MLLineageHelper module to build the lineage of the current pipeline run. Refer to [MLLineageHelper](https://github.com/aws-samples/ml-lineage-helper) for more information about ML Lineage Helper.\n",
    "\n",
    "Amazon SageMaker ML Lineage Tracking creates and stores information about the steps of an ML workflow from data preparation to model deployment. With the tracking information, you can reproduce the workflow steps, track model and dataset lineage, and establish model governance and audit standards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.5.1 Setting up the session and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set-variables\n",
    "fs_query = feature_group.athena_query()\n",
    "fs_table = fs_query.table_name\n",
    "query_string = 'SELECT * FROM \"'+fs_table+'\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.5.2 Show values that will be used to build the model's lineage\n",
    "\n",
    "Configurations include the following:\n",
    "- **query_string:** This is the SageMaker Feature Store query that will be passed to the MLLineageHelper module.\n",
    "- **model_ref:** This is the name of the model that is being evaluated.\n",
    "- **processing_job:** This is the name of the processing job that generated the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print-values\n",
    "print ('query_string:',query_string)\n",
    "\n",
    "model_ref = sagemaker_client.list_models(SortBy = 'CreationTime', SortOrder = 'Descending')['Models'][0]['ModelName']\n",
    "print ('model_ref:',model_ref)\n",
    "\n",
    "processing_job = sagemaker_client.list_processing_jobs(SortBy = 'CreationTime', SortOrder = 'Descending', NameContains = 'ChurnModelProcess')['ProcessingJobSummaries'][0]['ProcessingJobName']\n",
    "print ('processing_job:',processing_job)\n",
    "\n",
    "processing_job_description = sagemaker_client.describe_processing_job(\n",
    "    ProcessingJobName = processing_job\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.5.3 Describe the processing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe-processing-job\n",
    "processing_job_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.5.4 Show the name of the training job used to create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print-training-job\n",
    "training_job_name  =  sagemaker_client.list_training_jobs(SortBy = 'CreationTime', SortOrder = 'Descending')['TrainingJobSummaries'][0]['TrainingJobName']\n",
    "print (training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.5.5 Build the lineage for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you receive the following error, run the cell again.\n",
    "- **ClientError: An error occurred (ThrottlingException) when calling the UpdateArtifact operation (reached max retries: 4): Rate exceeded**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build-lineage\n",
    "ml_lineage = MLLineageHelper()\n",
    "lineage = ml_lineage.create_ml_lineage(training_job_name, model_name = model_ref,\n",
    "                                       query = query_string, sagemaker_processing_job_description = processing_job_description,\n",
    "                                       feature_group_names = [feature_group_name])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.5.6 Limit the lineage to include only the current trial and feature group\n",
    "\n",
    "A pipeline can run multiple times. To ensure that you are retrieving details from the most recent training job run, filter the lineage call using the name of the current trial and the feature group that the trial uses. \n",
    "\n",
    "After you run this cell, the steps used to create the model, the order in which the steps ran, and which jobs contributed to other jobs in the pipeline are displayed as a table. This same information is also written to a file named **lineage_FS.csv**. You can download this file to save the output and share it with other team members, such as auditors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit-lineage\n",
    "trial_name = RunPipeline.describe()['PipelineExperimentConfig']['TrialName']\n",
    "pat = str(trial_name)+'|'+'fg-FG'\n",
    "df1 = lineage[lineage.apply(lambda x: any(x.str.contains(pat)),axis = 1)]\n",
    "pd.set_option('display.max_colwidth', 120)\n",
    "df1.to_csv('lineage_FS.csv') \n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.5.7 Generate a visualization of the model's lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize-lineage\n",
    "plt.figure(3, figsize = (20, 14))\n",
    "graph = nx.DiGraph()\n",
    "graph.add_edges_from([(each[0], each[2]) for each in df1.values])\n",
    "fig, ax = plt.subplots()\n",
    "nx.draw_networkx(\n",
    "    graph,\n",
    "    node_size = 300,\n",
    "    node_color = \"orange\",\n",
    "    alpha = 0.65,\n",
    "    font_size = 8,\n",
    "    pos = nx.spring_layout(graph)\n",
    ")\n",
    "ax.set_facecolor('deepskyblue')\n",
    "ax.axis('off')\n",
    "fig.set_facecolor('deepskyblue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.6 Remove the pipeline\n",
    "\n",
    "To delete the pipeline, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete-pipeline\n",
    "response = sagemaker_client.delete_pipeline(PipelineName = 'ChurnModelSMPipeline')\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion \n",
    "\n",
    "Congratulations! You have used SageMaker Pipelines to automate the creation and registry of a model. You learned how to drill down into each pipeline step to identify associated parameters, files, and logs. You know how to identify the assets that the pipeline used to generate the model, how to find the model in the model registry, and how to find and view the explainability and bias reports that a pipeline can generate.\n",
    "\n",
    "### Cleanup\n",
    "\n",
    "You have completed this notebook. To move to the next part of the lab, do the following:\n",
    "\n",
    "- Close this notebook file.\n",
    "- Return to the lab session and continue with the **Conclusion**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints and answers for Task 2.3.1.1\n",
    "General hint: **Step type** is found on the **Information** tab.\n",
    "\n",
    "1. For the step named **ChurnHyperParameterTuning**, locate the following details:\n",
    "    - What is the **Step Type** for this step?</br>\n",
    "    **Answer:** Tuning</br>\n",
    "    - What was the **Overall Best Training Job** generated by this step? </br>\n",
    "    **Hint:** This information is found on the **Output** tab.</br>\n",
    "    **Answer:** The model name is generated and will be different for each student. The name should be similar to this example: 056vhzs2vkxc-ChurnHy-TCAtUr16oV-001-17d5bd01\n",
    "1. For the **ChurnEvalBestModel** step, locate the following details:\n",
    "    - What is the **Step Type** for this step?\n",
    "    **Answer:** Processing</br>\n",
    "    - What is the name of the Python script that is used to evaluate the top model that was identified in the previous step?</br>\n",
    "    **Hint:** This information is found on the **Input** tab.</br>\n",
    "    **Answer:** evaluate.py</br>\n",
    "    - Where is this file located?</br>\n",
    "    **Hint:** This information is found on the **Input** tab.</br>\n",
    "    **Answer:** The file resides in an S3 Bucket. The path is similar to this example: s3://sagemaker-us-west-2-1234567890/input/code/evaluate.py</br>\n",
    "    - Where were the results from this step written?</br>\n",
    "    **Hint:** This information is found on the **Output** tab.</br>\n",
    "    **Answer:** The results of the evaluation were written to an S3 bucket. The path to the file should be similar to the following example: s3://sagemaker-us-west-2-1234567890/output/evaluation</br>\n",
    "1. For the **CheckAUCScoreChurnEvaluation** step, locate the following details:\n",
    "    - What is the **Step Type** for this step?</br>\n",
    "    **Answer:** Condition</br>\n",
    "    - What was the **Evaluation outcome**?</br>\n",
    "    **Hint:** This information is found on the **Output** tab.</br>\n",
    "    **Answer:** True\n",
    "1. For the **ChurnCreateModel** step, locate the following details:\n",
    "    - What is the **Step Type** for this step?</br>\n",
    "    **Answer:** Model</br>\n",
    "    - Did this job generate any logs?</br>\n",
    "    **Answer:** No\n",
    "1. For the **RegisterChurnModel** step, locate the following details:\n",
    "    - What is the **Step Type** for this step?</br>\n",
    "    **Answer:** RegisterModel</br>\n",
    "    - What is value for the AUC metric?</br>\n",
    "    **Hint:** This information is found on the **Output** tab.</br>\n",
    "    **Answer:** The value will vary, but should be close to 0.98.\n",
    "1. For the **ChurnTransform** step, locate the following details:\n",
    "    - What is the **Step Type** for this step?</br>\n",
    "    **Answer:** Transform</br>\n",
    "    - Did this job generate logs?</br>\n",
    "    **Answer:** Yes</br>\n",
    "    - Which files were inputs for this step?</br>\n",
    "    **Hint:** This information is found on the **Input** tab. You might need to scroll to the bottom of the pane to find the file names.</br>\n",
    "    **Answer:** model.tar.gz, sagemaker-xgboost:1.5-1-cpu-py3, batch.csv\n",
    "1. For the **ChurnModelConfigFile** step, locate the following details: \n",
    "    - Which ProcessingInstanceType was used to run this job?</br>\n",
    "    **Hint:** This information is found on the **Input** tab.</br>\n",
    "    **Answer:** ml.m5.xlarge\n",
    "    - What is the **Step Type** for this step?</br>\n",
    "    **Answer:** Processing\n",
    "1. For the **ClarifyProcessingStep**, locate the following details:\n",
    "    - What was the file output from this step?\n",
    "    **Hint:** This information is found on the **Output** tab.</br>\n",
    "    **Answer:** The output was bias data.\n",
    "    - Where was the output written?\n",
    "    **Answer:** The output was written to an S3 Bucket. The path should be similar to this example: s3://sagemaker-us-west-2-1234567890/clarify-output/bias"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "741de909edea0d5644898c592544ed98bede62b404d20772e5c4abc3c2f12566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
