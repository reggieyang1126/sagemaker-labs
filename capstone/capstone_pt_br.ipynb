{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto final: criar um projeto de ML de dados tabulares de ponta a ponta usando o SageMaker Studio e o SDK Python do Amazon SageMaker Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuração do ambiente\n",
    "\n",
    "Este código de configuração básico foi incluído para ajudar você a começar. Leia e execute essas células primeiro para instalar os pacotes e criar as variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U shap\n",
    "%pip install -U smdebug\n",
    "%pip install imbalanced-learn\n",
    "%pip install pytest-cov\n",
    "%pip install pytest-filter-subpackage\n",
    "%pip install sagemaker\n",
    "%pip install -U seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required-libraries\n",
    "\n",
    "import boto3\n",
    "import datetime as datetime\n",
    "import io\n",
    "import IPython\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt  # visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import re\n",
    "import sagemaker\n",
    "import seaborn as sns  # visualization\n",
    "import statistics\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sagemaker import clarify\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from sagemaker.dataset_definition.inputs import AthenaDatasetDefinition, DatasetDefinition, RedshiftDatasetDefinition\n",
    "from sagemaker.debugger import CollectionConfig, DebuggerHookConfig, FrameworkProfile, ProfilerConfig, ProfilerRule, Rule, rule_configs\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.experiments.run import Run, load_run\n",
    "from sagemaker.feature_store.feature_definition import FeatureDefinition\n",
    "from sagemaker.feature_store.feature_definition import FeatureTypeEnum\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.processing import FeatureStoreOutput\n",
    "from sagemaker.processing import Processor, ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.workflow.condition_step import ConditionStep, JsonGet\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThan\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterFloat, ParameterString\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic-variable-code-and-settings\n",
    "\n",
    "%matplotlib inline\n",
    "base_job_name = \"capstone-smdebugger-job\"\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "bucket_path = \"s3://{}\".format(bucket)\n",
    "prefix = \"sagemaker/capstone\"\n",
    "region = boto3.Session().region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sagemaker_session = sagemaker.Session()\n",
    "save_interval = 5\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descrição do conjunto de dados\n",
    "\n",
    "Cinco tabelas são armazenados em um bucket do Amazon Simple Storage Service (Amazon S3):\n",
    "- **claims.csv**: uma tabela contendo dados brutos de sinistros.\n",
    "- **customers.csv**: um tabela contendo dados brutos de clientes.\n",
    "- **claims_preprocessed.csv**: uma tabela contendo dados processados de sinistros.\n",
    "- **customers_preprocessed.csv**: uma tabela contendo dados processados de clientes.\n",
    "- **claims_customer.csv**: uma tabela unificada no **policy_id** com os dados processados de sinistros e clientes.\n",
    "\n",
    "Neste laboratório, comece com as tabelas **claims.csv** e **customers.csv**. Você vai processá-las no **Desafio 1** usando o Amazon SageMaker Data Wrangler. Se você tiver dúvidas ou quiser uma referência de como o conjunto de dados deve ser, examine as tabelas pré-processadas.\n",
    "\n",
    "Para este conjunto de dados, o destino é **fraud**, uma coluna na tabela de sinistros.\n",
    "\n",
    "A tabela de sinistros inclui os seguintes campos: \n",
    "\n",
    "- **policy_id**: o ID exclusivo da política.\n",
    "- **driver_relationship**: uma lista de relacionamentos (Spouse, Self, Child, Other, N/A).\n",
    "- **incident_type**: o tipo de incidente relatado (Break-In, Collision, Theft).\n",
    "- **collision_type**: o local da colisão (Front, Rear, Side, N/A).\n",
    "- **incident_severity**: a severidade do incidente (Minor, Major, Totaled).\n",
    "- **authorities_contacted**: o tipo de autoridade do primeiro contato (None, Police, Ambulance, Fire).\n",
    "- **num_vehicles_involved**: o número de veículos envolvidos no incidente (um intervalo de 1 a 6).\n",
    "- **num_injuries**: o número de ferimentos envolvidos no incidente (um intervalo de 1 a 4).\n",
    "- **num_witnesses**: o número de testemunhas do incidente (um intervalo de 1 a 5).\n",
    "- **police_report_available**: se há um relatório policial envolvido (yes ou no).\n",
    "- **injury_claim**: o valor reivindicado, relativo a ferimentos, em dólares americanos (300 a 576300 USD).\n",
    "- **injury_claim**: o valor reivindicado, relativo a danos no veículo, em dólares americanos (1000 a 51051 USD).\n",
    "- **total_claim_amount**: o valor total reivindicado para ferimentos e danos (2100 a 588868 USD).\n",
    "- **incident_month**: o mês do incidente (um intervalo de 1 a 12).\n",
    "- **incident_day**: o dia do incidente (um intervalo de 1 a 31).\n",
    "- **incident_dow**: o dia da semana do incidente (um intervalo de 0 a 6 representando de sábado a domingo).\n",
    "- **incident_hour**: o horário do incidente (um intervalo de 0 a 23)\n",
    "- **fraud**: se a apólice era fraudulenta (0 ou 1).\n",
    "\n",
    "A tabela de clientes inclui os seguintes campos:\n",
    "\n",
    "- **policy_id**: o ID exclusivo da política.\n",
    "- **customer_age**: a idade do cliente (um intervalo de 18 a 70).\n",
    "- **months_as_customer**: o número de meses em que esse cliente já pagou o seguro (um intervalo de 1 a 495).\n",
    "- **num_claims_past_year**: o número de sinistros registrados pelo cliente no ano passado.\n",
    "- **num_insurers_past_5_years**: o número de seguradoras que o cliente teve nos últimos cinco anos.\n",
    "- **policy_state**: o estado dos EUA em que o cliente vive (AZ, CA, ID, NV, OR, WA).\n",
    "- **policy_deductable**: o valor deduzível da apólice em dólares americanos (um intervalo de 750 a 1100 USD).\n",
    "- **policy_annual_premium**: o prêmio anual da apólice em dólares americanos (um intervalo de 2200 a 3000 USD).\n",
    "- **policy_liability**: o máximo de responsabilização por ferimentos corporais, dividido em ferimentos individuais ou no corpo todo (15/30, 25/50, 60/90, 100/200).\n",
    "- **customer_zip**: o CEP do cliente (um intervalo de 83201 a 99362).\n",
    "- **customer_gender**: o gênero do cliente (Male, Female, Other, Unknown).\n",
    "- **customer_education**: o nível educacional do cliente (Below High School, High School, Associate, Bachelor, Advanced Degree).\n",
    "- **auto_year**: o ano em que o automóvel foi fabricado (um intervalo de 2001 a 2020).\n",
    "\n",
    "É possível unificar as tabelas com uma unificação interna na coluna **policy_id**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navegação no laboratório de desafio\n",
    "\n",
    "Este laboratório está configurado com links que navegam entre as tarefas de desafio e o apêndice no final do notebook. Se você quiser examinar um item no apêndice, escolha o hiperlink associado. Para retornar ao desafio em que você está trabalhando no momento, escolha o hiperlink da tarefa correspondente no apêndice.\n",
    "\n",
    "O laboratório é organizado desta forma:\n",
    "\n",
    "- Desafio 1: Analisar e preparar o conjunto de dados com o SageMaker Data Wrangler\n",
    "- Desafio 2: Criar grupos de recursos no SageMaker Feature Store\n",
    "- Desafio 3: Treinar o modelo\n",
    "- Desafio 4: Avaliar o viés do modelo\n",
    "- Desafio 5: Transformação em lote\n",
    "- Desafio 6: Criar um pipeline automatizado\n",
    "- Apêndice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafio 1: Analisar e preparar o conjunto de dados com o SageMaker Data Wrangler\n",
    "\n",
    "A AnyCompany Consulting recebeu uma solicitação para analisar conjuntos de dados de fraude em seguro de automóvel e criar um modelo para ajudar a prever a probabilidade de que as novos sinistros sejam fraudulentos ou não. Há 5 mil registros de cliente. Cada sinistro está rotulado como fraudulento ou não. Você pode usar esses dados para treinar, testar e validar o modelo antes de executar a inferência em uma nova coleção de registros em lote.\n",
    "\n",
    "Use os recursos de análise do Amazon SageMaker Data Wrangler para visualizar as distribuições dos dados em colunas importantes, verificar a correlação entre as colunas e conferir o vazamento de dados de destino. Em seguida, crie um modelo de linha de base rápido. Depois, use os recursos de processamento do SageMaker Data Wrangler a fim de transformar as colunas adequando-as para treinar um modelo com melhor desempenho. \n",
    "\n",
    "Para concluir essa tarefa, realize estas subtarefas:\n",
    "\n",
    "- Examinar os dados.\n",
    "- Concluir uma análise exploratória de dados no Amazon SageMaker Studio.\n",
    "- Usar um trabalho de processador do Amazon SageMaker Clarify para gerar um relatório de viés.\n",
    "- Preparar os dados.\n",
    "\n",
    "Este desafio exige cerca de *100* minutos para ser concluído."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 1.1: Examinar os dados\n",
    "\n",
    "<a id=\"task1-1-continue\"></a>\n",
    "\n",
    "Acesse o conjunto de dados de seguro de automóvel tabular armazenado no repositório e examine uma amostra do conjunto de dados. O repositório contém duas tabelas não processadas. Uma contém dados de clientes, chamada **customers.csv**, e a outra contém dados de sinistros, chamada **claims.csv**.\n",
    "\n",
    "**Dica 1**: as tabelas não processadas estão localizadas na pasta **./data/**.\n",
    "\n",
    "**Dica 2**: as tabelas **claims.csv** e **customers.csv** são as tabelas não processadas.\n",
    "\n",
    "Reserve um momento para explorar as tabelas. Há campos que se destacam? Há campos que exigem um pré-processamento cuidadoso?\n",
    "\n",
    "Para obter etapas detalhadas que mostram como examinar os dados, consulte <a href=\"#task1-1\" target=\"_self\">**Examinar os dados (Tarefa 1.1)**</a> na seção *Apêndice*.\n",
    "\n",
    "Depois de acessar a tabela de fraudes em seguro de automóvel e examinar uma amostra do conjunto de dados, você terá concluído esta tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_1_1_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 1.2: Realizar uma análise exploratória de dados no SageMaker Studio \n",
    "\n",
    "<a id=\"task1-2-continue\"></a>\n",
    "\n",
    "Faça uma análise exploratória de dados examinando os dados, identificando possíveis problemas no conjunto de dados e verificando se há correlações fortes entre as colunas e o destino. Você pode explorar os dados no SageMaker Data Wrangler e no notebook.\n",
    "\n",
    "Especificamente, dedique um tempo para examinar os seguintes itens:\n",
    "- **Histogramas de coluna**: examine as colunas em um formato visual e verifique quais tipos de valores estão no conjunto de dados.\n",
    "- **Modelo rápido**: examine o conjunto de dados e pense qual seria o resultado esperado do modelo.\n",
    "- **Correlação de recursos**: verifique se existe uma correlação forte entre as colunas e o destino.\n",
    "- **Vazamento de dados de destino**: verifique se há dados que dependem do valor de destino.\n",
    "\n",
    "Ao ser aberto, o SageMaker Data Wrangler abre uma nova aba no SageMaker Studio. Para seguir essas orientações, escolha uma das seguintes opções:\n",
    "- **Opção 1:** visualizar as abas lado a lado. Para criar uma visualização de tela dividida por meio da janela principal do SageMaker Studio, arraste a aba **capstone.ipynb** para a lateral ou selecione (clique com o botão direito) a aba **capstone.ipynb** e escolha **New View for Notebook** (Nova visualização do notebook). Agora, as orientações ficam visíveis durante o trabalho no fluxo do SageMaker Data Wrangler.\n",
    "- **Opção 2:** alternar entre as abas do SageMaker Studio para seguir essas instruções. Quando terminar de explorar as etapas do SageMaker Data Wrangler, retorne ao notebook selecionando a aba **capstone.ipynb**.\n",
    "\n",
    "Se aparecer o erro **\"O seguinte tipo de instância não está disponível: ml.m5.4xlarge. Tente selecionar uma instância diferente abaixo.\"** durante a criação de um arquivo de fluxo, escolha outro tipo de instância. Tente o **ml.m5.8xlarge** em seguida.\n",
    "\n",
    "Se a mensagem **Ocorreu um erro ao carregar esta visualização** for exibida, feche a aba **untitled.flow** e reabra o arquivo de fluxo usando o navegador de arquivo.\n",
    "\n",
    "**Dica 1**: há muitas maneiras de explorar o conjunto de dados. Abra um fluxo do SageMaker Data Wrangler para começar. É necessário importar o **claims.csv** e o **customers.csv** no SageMaker Data Wrangler por meio do bucket do S3 que contém **databucket-** no nome.\n",
    "\n",
    "**Dica 2**: para importar uma segunda tabela, retorne ao **Fuxo de dados**, selecione a aba **Import** (Importar) para importar outro conjunto de dados.\n",
    "\n",
    "**Dica 3**: **Obter informações de dados** e **Adicionar análise** são duas maneiras de explorar os dados no SageMaker Data Wrangler. Depois de examinar alguns gráficos de amostra dos dados, você poderá usar outras ferramentas de criação de gráficos no notebook para analisar os dados, se desejar. As bibliotecas **plt** e **sns** foram instaladas. Fique à vontade para usar qualquer ferramenta de análise que você já conheça para explorar o conjunto de dados.  \n",
    "\n",
    "**Dica 4**: tente unificar as duas tabelas usando **Join** (Unificar) em **policy_id**. Depois, gere outro relatório de informações. Você pode usar uma unificação **Interna** para essas tabelas.\n",
    "\n",
    "Você obteve resultados mais significativos com um conjunto de dados unificado?\n",
    "\n",
    "Para obter etapas detalhadas que mostram como explorar um conjunto de dados no SageMaker Studio, consulte <a href=\"#task1-2-1\" target=\"_self\">**Explorar um conjunto de dados no SageMaker Studio (Tarefa 1.2)**</a> na seção *Apêndice*.\n",
    "\n",
    "Para obter etapas detalhadas que mostram como explorar um conjunto de dados no notebook, consulte <a href=\"#task1-2-2\" target=\"_self\">**Explorar um conjunto de dados no notebook (Tarefa 1.2)**</a> na seção *Apêndice*.\n",
    "\n",
    "Depois de processar os dados usando o SageMaker Data Wrangler, explorar o conjunto de dados e identificar as etapas de processamento que deseja realizar, você terá concluído esta tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_1_2_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 1.3: Usar um trabalho de processador do SageMaker Clarify para gerar um relatório de viés\n",
    "\n",
    "<a id=\"task1-3-continue\"></a>\n",
    "\n",
    "Use o SageMaker Clarify para gerar um relatório de viés de pré-treinamento para capturar o desequilíbrio de classes nos dados. Use um fluxo do SageMaker Data Wrangler para gerar o relatório de viés no SageMaker Studio.\n",
    "1. Comece unificando as duas tabelas.\n",
    "\n",
    "- Unificar: unificação **interna** de **claims.csv** com **customers.csv** em **policy_id**.\n",
    "\n",
    "**Dica 1**: para criar um relatório de viés de pré-treinamento, adicione uma nova análise ao fluxo do SageMaker Data Wrangler e escolha **Bias Report** (Relatório de viés) em **Analysis type** (Tipo de análise).\n",
    "\n",
    "**Dica 2**: é possível gerar o relatório de viés várias vezes escolhendo recursos diferentes para analisar a cada vez.\n",
    "\n",
    "Para obter etapas detalhadas que mostram como unificar tabelas com o SageMaker Data Wrangler, consulte <a href=\"#task1-3-1\" target=\"_self\">**Unificar tabelas no SageMaker Studio (Tarefa 1.3)**</a> na seção *Apêndice*.\n",
    "\n",
    "Para obter etapas detalhadas que mostram como gerar um relatório de viés de pré-treinamento, consulte <a href=\"#task1-3-2\" target=\"_self\">**Gerar um relatório de viés de pré-treinamento (Tarefa 1.3)**</a> na seção *Apêndice*.\n",
    "\n",
    "Depois de gerar o relatório de viés de pré-treinamento e visualizar o relatório, você terá concluído esta tarefa."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 1.4: Preparar os dados\n",
    "\n",
    "<a id=\"task1-4-continue\"></a>\n",
    "\n",
    "Prepare o conjunto de dados usando o SageMaker Data Wrangler. Concentre-se nas seguintes transformações, mas fique à vontade para incluir outras:\n",
    "\n",
    "- Codificar de maneira categórica (codificação one-hot): **authorities_contacted**, **collision_type**, **customer_gender**, **driver_relationship**, **incident_type** e **policy_state**.\n",
    "- Codificar de maneira ordinal: **customer_education**, **policy_liability**, **incident_severity** e **police_report_available**.\n",
    "- Analisar coluna como tipo: **vehicle_claim** e **total_claim_amount** de **Float** para **Long**.\n",
    "- Gerenciar colunas (Remover coluna): **customer_zip**.\n",
    "- Gerenciar colunas (Mover coluna): **fraud** (usando **Mover para início**).\n",
    "- Gerenciar colunas (Renomear coluna): remova o símbolo **/** de **collision_type_N/A** e **driver_relationship_N/A** com **_**.\n",
    "- Gerenciar colunas (Renomear coluna): renomeie **policy_id_0** como **policy_id**.\n",
    "\n",
    "**Dica 1**: unifique a tabela **claims** às tabelas **customers** usando uma unificação no SageMaker Data Wrangler. \n",
    "\n",
    "**Dica 2**: unifique as duas tabelas na coluna **policy_id**.\n",
    "\n",
    "**Dica 3**: adicione transformações usando a opção **Add transform** (Adicionar transformação).\n",
    "\n",
    "Quais transformações você acha que mais afetam o treinamento do modelo?\n",
    "\n",
    "Para obter etapas detalhadas que mostram como preparar dados usando o SageMaker Data Wrangler, consulte <a href=\"#task1-4-1\" target=\"_self\">**Preparar dados usando o SageMaker Data Wrangler (Tarefa 1.4)**</a> na seção *Apêndice*.\n",
    "\n",
    "Se você quiser importar um conjunto de exemplo de dados processados, consulte <a href=\"#task1-4-2\" target=\"_self\">**Importar um conjunto de exemplo de dados processados (Tarefa 1.4)**</a> na seção *Apêndice*. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafio 2: criar grupos de recursos no SageMaker Feature Store\n",
    "\n",
    "Agora que você processou o conjunto de dados, crie recursos e grupos de recursos que serão usados em análises futuras. Use o SageMaker Feature Store para armazenar esses itens em um grupo de recursos e consultá-los durante o treinamento do modelo.\n",
    "\n",
    "Para realizar essa tarefa, conclua todas estas subtarefas:\n",
    "\n",
    "1. Exportar recursos para o SageMaker Feature Store.\n",
    "2. Consultar o grupo de recursos em um armazenamento off-line com o Amazon Athena.\n",
    "\n",
    "Este desafio exige cerca de *30* minutos para ser concluído."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.1: Exportar recursos para o SageMaker Feature Store\n",
    "\n",
    "<a id=\"task2-1-continue\"></a>\n",
    "\n",
    "Use o recurso **Export to** (Exportar para) do SageMaker Data Wrangler para criar um caderno Jupyter personalizado. O notebook cria uma definição de recurso e um grupo de recursos. O notebook ingere os registros no grupo de recursos. No notebook, faça as seguintes etapas:\n",
    "\n",
    "- Defina os valores de registro e de event_time.\n",
    "- Execute as células do notebook para criar o grupo de recursos.\n",
    "- Execute as células do notebook para confirmar o grupo de recursos criado.\n",
    "- Execute as células do notebook para fazer a ingestão dos registros no grupo de recursos.\n",
    "\n",
    "**Dica 1**: todas essas etapas podem ser realizadas no SageMaker Studio. Ao concluir a criação do grupo de recursos, retorne a este notebook para continuar a Tarefa 2.2.\n",
    "\n",
    "**Dica 2**: adicione uma transformação personalizada para criar a coluna **event_time**. \n",
    "\n",
    "**Dica 3**: o código para adicionar a transformação personalizada é o seguinte:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import lit\n",
    "date_time = datetime.date.today()\n",
    "\n",
    "df = df.withColumn(\"event_time\", lit(time.mktime(date_time.timetuple())))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Dica 4**: no final do fluxo do SageMaker Data Wrangler, selecione o ícone **+**, escolha a opção **Export to** (Exportar para) e escolha **SageMaker Feature Store (via JupyterNotebook)** (SageMaker Feature Store (por meio do caderno Jupyter)).\n",
    "\n",
    "**Dica 5**: é possível desativar o armazenamento on-line alterando o valor de **enable_online_store** de **True** para **False**.\n",
    "\n",
    "Como você usaria o SageMaker Feature Store para armazenar e consultar registros para treinamento, não para inferência?\n",
    "\n",
    "Para obter etapas detalhadas que mostram como criar um grupo de recursos usando a opção **Export to** (Exportar para), consulte <a href=\"#task2-1\" target=\"_self\">**Criar um grupo de recursos usando a opção Exportar para (Tarefa 2.1)**</a> na seção *Apêndice*. \n",
    "\n",
    "Depois de criar um grupo de recursos e fazer a ingestão de dados nele, você terá concluído esta tarefa."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.2: Consultar o grupo de recursos em um armazenamento off-line com o Athena\n",
    "\n",
    "<a id=\"task2-2-continue\"></a>\n",
    "\n",
    "Use o Athena para extrair registros de um armazenamento de dados off-line. No próximo desafio, você vai dividir esses registros em conjuntos de treinamento, teste e validação.\n",
    "\n",
    "Use a célula de código fornecida abaixo para fazer as chamadas de API do Amazon Athena. Você também poderia usar o console do Amazon Athena para fazer a consulta, mas isso não faz parte do escopo deste laboratório.\n",
    "\n",
    "**Dica 1**: é possível criar uma consulta do Athena com **feature_group.athena_query()** e obter o nome da tabela com **query.table_name**.\n",
    "\n",
    "**Dica 2**: é possível executar uma consulta com **query.run(query_string=query_string, output_location=output_location)** e ler o valor retornado como um dataframe com **query.as_dataframe()**.\n",
    "\n",
    "Como você poderia usar **event_time** para acompanhar recursos que ocorrem em diferentes pontos na linha do tempo do conjunto de dados?\n",
    "\n",
    "Para obter as etapas detalhadas que mostram como extrair registros de um armazenamento de dados off-line com o Athena, consulte <a href=\"#task2-2\" target=\"_self\">**Extrair registros de um armazenamento off-line com o Athena (Tarefa 2.2)**</a> na seção *Apêndice*.\n",
    "\n",
    "Depois de salvar a consulta do Athena retornada como uma variáveis do dataframe, você terá concluído esta tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_2_2_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafio 3: Treinar o modelo\n",
    "\n",
    "O modelo está pronto para ser treinado. Divida os dados em conjuntos de dados de treinamento, teste e validação e treine o modelo. \n",
    "\n",
    "O SageMaker Autopilot já foi executado nesses dados e obteve **F1** igual a **0,616**, **accuracy** igual a **0,978**, **AUC** igual a **0,918** e **Recall** igual a **0,539**. Para saber mais sobre as métricas que o SageMaker Autopilot produz, consulte o documento *autopilot-metrics-validation* na seção *Recursos adicionais* e obtenha mais informações.\n",
    "\n",
    "Durante o treinamento e o ajuste, trabalhe para atingir ou exceder as pontuações do SageMaker Autopilot e confirme se o Amazon SageMaker Debugger não está relatando erros.\n",
    "\n",
    "Para concluir essa tarefa, realize estas subtarefas:\n",
    "\n",
    "- Criar um experimento e uma execução.\n",
    "- Dividir os dados em conjuntos de dados de treinamento, teste e validação.\n",
    "- Configurar e executar um trabalho de treinamento.\n",
    "    - Executar um trabalho de treinamento básico.\n",
    "    - Executar um trabalho de treinamento com o SageMaker Debugger habilitado e analisar os relatórios (opcional).\n",
    "- Realizar ajuste de hiperparâmetros.\n",
    "\n",
    "Este desafio exige cerca de *110* minutos para ser concluído.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 3.1: Nomear um experimento e uma execução\n",
    "\n",
    "<a id=\"task3-1-continue\"></a>\n",
    "\n",
    "Defina variáveis para nomear o experimento e as execuções. \n",
    "Um experimento exige **experiment_name**, **run_name** e **description**. \n",
    "\n",
    "Para obter etapas detalhadas de como criar as variáveis, consulte <a href=\"#task3-1\" target=\"_self\">**Nomear um experimento e uma execução (Tarefa 3.1)**</a> na seção *Apêndice*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_3_1_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 3.2: Dividir os dados em conjuntos de dados de treinamento, teste e validação\n",
    "\n",
    "<a id=\"task3-2-continue\"></a>\n",
    "\n",
    "Use os recursos consultados do SageMaker Feature Store e divida os dados em conjuntos de dados de treinamento, teste e validação.\n",
    "\n",
    "**Dica 1**: use **np.split** para dividir os conjuntos de dados em três partições.\n",
    "\n",
    "**Dica 2**: use **to_csv** para criar os arquivos CSV e use **S3Uploader.upload** para adicioná-los ao Amazon S3.\n",
    "\n",
    "**Dica 3**: o produto final da divisão deve ser uma variável **data_inputs** com valores para **train** e **validation**.\n",
    "\n",
    "Para obter as etapas detalhadas que mostram como dividir os dados em conjuntos de dados de treinamento, teste e validação, consulte <a href=\"#task3-2\" target=\"_self\">**Dividir dados em conjuntos de dados de treinamento, teste e validação (Tarefa 3.2)**</a> na seção *Apêndice*. \n",
    "\n",
    "Depois de dividir os dados em conjuntos de dados de treinamento, teste e validação, você terá concluído esta tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_3_2_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 3.3: Configurar e executar um trabalho de treinamento\n",
    "\n",
    "<a id=\"task3-3-continue\"></a>\n",
    "\n",
    "Comece seu primeiro trabalho de treinamento configurando o contêiner, um estimador e os hiperparâmetros. Depois, treine o modelo com **fit()**. Se você quiser examinar relatórios mais detalhados, habilite o SageMaker Debugger com **DebuggerHookConfig**.\n",
    "\n",
    "**Dica 1**: use o contêiner **XGBoost** com a versão **1.5-1**.\n",
    "\n",
    "**Dica 2**: para começar, defina os hiperparâmetros para **eta**, **gamma**, **max_depth**, **min_child_weight**, **num_round**, **objective** e **subsample**.\n",
    "\n",
    "**Dica 3**: use a variável **data_inputs** que você já criou no Desafio 1 como o valor de **inputs** do trabalho de treinamento.\n",
    "\n",
    "**Dica 4**: é possível configurar um trabalho de treinamento definindo as entradas e experiment_config. O experiment_config deve conter uma **sagemaker_session**, um **run_name** e um **experiment_name**.\n",
    "\n",
    "**Dica 5**: se você quiser usar o SageMaker Debugger, configure **DebuggerHookConfig**, **ProfilerConfig** e o objeto **rule** do Debugger.\n",
    "\n",
    "Quais hiperparâmetros têm a maior probabilidade de causar um grande impacto no desempenho e na precisão do modelo? Quais hiperparâmetros você planeja ajustar primeiro?\n",
    "\n",
    "Para obter etapas detalhadas que mostram como configurar e executar um trabalho de treinamento básico, veja <a href=\"#task3-3-1\" target=\"_self\">**Configurar e executar um trabalho de treinamento básico (Tarefa 3.3)**</a> na seção *Apêndice*.\n",
    "\n",
    "Para obter etapas detalhadas que mostram como configurar e executar um trabalho de treinamento com o Debugger habilitado e analisar relatórios, veja <a href=\"#task3-3-2\" target=\"_self\">**Configurar e executar um trabalho de treinamento com o SageMaker Debugger habilitado e analisar relatórios (Tarefa 3.3)**</a> na seção *Apêndice*.\n",
    "\n",
    "Depois de terminar um ou mais trabalhos de treinamento, você terá concluído esta tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_3_3_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 3.4: Ajustar os hiperparâmetros\n",
    "\n",
    "<a id=\"task3-4-continue\"></a>\n",
    "\n",
    "Agora que você concluiu um trabalho de treinamento e fez a análise, ajuste os intervalos de hiperparâmetros considerando o que você já descobriu e execute mais trabalhos de treinamentos para melhorar o modelo.\n",
    "\n",
    "**Dica 1**: para começar, defina os intervalos de hiperparâmetro para **alpha**, **eta**, **max_depth**, **min_child_weight** e **num_round**.\n",
    "\n",
    "**Dica 2**: ao executar o **HyperparameterTuner**, defina **objective_metric_name** e **objective_type** considerando o que você já descobriu.\n",
    "\n",
    "**Dica 3**: para verificar se houve melhora nos resultados do SageMaker Autopilot, abra o menu **Experiments and runs** (Experimentos e execuções) em **SageMaker resources** (Recursos do SageMaker). Na execução, veja as **Métricas**. **ObjectiveMetric** deve ser superior à pontuação de **F1**, que é igual a **0,616**, e **validation:auc** deve ter um **Valor final** superior à pontuação do SageMaker Autopilot, que é igual a **0,918**.\n",
    "\n",
    "Quando você ajustou os hiperparâmetros, qual deles melhorou mais o desempenho do modelo?\n",
    "\n",
    "Para obter etapas detalhadas que mostram como configurar intervalos de hiperparâmetros, veja <a href=\"#task3-4\" target=\"_self\">**Configurar intervalos de hiperparâmetros (Tarefa 3.4)**</a> na seção *Apêndice*.\n",
    "\n",
    "Depois de configurar os intervalos de hiperparâmetros de treinamento e iniciar mais trabalhos de treinamento, você terá concluído esta tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_3_4_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafio 4: Avaliar o viés do modelo\n",
    "\n",
    "Agora que o modelo está treinado, avalie-o usando o Amazon SageMaker Clarify. Se você encontrar problemas, remova o desequilíbrio detectado e retreine o modelo.\n",
    "\n",
    "Para concluir essa tarefa, realize estas subtarefas:\n",
    "\n",
    "- Criar um modelo usando o trabalho de treinamento.\n",
    "- Criar uma configuração de modelo do SageMaker Clarify.\n",
    "- Criar uma configuração de viés do SageMaker Clarify.\n",
    "- Usar um trabalho de processador do SageMaker Clarify para gerar relatórios de viés, dados e modelo.\n",
    "- Remover o desequilíbrio detectado com o SageMaker Clarify (opcional).\n",
    "- Retreinar o modelo (opcional).\n",
    "\n",
    "Este desafio exige cerca de *80* minutos para ser concluído."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 4.1: Criar um modelo usando o trabalho de treinamento\n",
    "\n",
    "<a id=\"task4-1-continue\"></a>\n",
    "\n",
    "Crie um modelo do XGBoost chamando **create_model** com **model_name**, **role** e **container_def** definidos por você.\n",
    "\n",
    "**Dica 1**: chame **xgb.create_model()** e escolha um nome para o modelo.\n",
    "\n",
    "**Dica 2**: use sua sessão e chame **create_model**, passando **model_name**, **role** e **container_def**.\n",
    "\n",
    "Para obter etapas detalhadas que mostram como criar um modelo, veja <a href=\"#task4-1\" target=\"_self\">**Criar um modelo (Tarefa 4.1)**</a> na seção *Apêndice*.\n",
    "\n",
    "Depois de criar um modelo, você terá concluído esta tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_4_1_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 4.2: Criar uma configuração de modelo do SageMaker Clarify\n",
    "\n",
    "<a id=\"task4-2-continue\"></a>\n",
    "\n",
    "Crie uma configuração de modelo do SageMaker Clarify usando **SageMakerClarifyProcessor**.\n",
    "\n",
    "**Dica 1**: defina **instance_count** e **instance_type**.\n",
    "\n",
    "**Dica 2**: use **role** e **session** criados no início do laboratório de projeto final.\n",
    "\n",
    "Para obter etapas detalhadas que mostram como criar uma configuração de modelo do SageMaker Clarify, consulte <a href=\"#task4-2\" target=\"_self\">**Criar uma configuração de modelo do SageMaker Clarify (Tarefa 4.2)**</a> na seção *Apêndice*.\n",
    "\n",
    "Depois de criar uma configuração de modelo do SageMaker Clarify, você terá concluído esta tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_4_2_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 4.3: Criar uma configuração de viés do SageMaker Clarify\n",
    "\n",
    "<a id=\"task4-3-continue\"></a>\n",
    "\n",
    "Crie uma configuração de dados, uma configuração de modelo, uma configuração de rótulo e uma configuração de viés.\n",
    "\n",
    "**Dica 1**: comece com uma **DataConfig**, configurando o caminho de entrada, o caminho de saída, os cabeçalhos e o tipo de conjunto de dados.\n",
    "\n",
    "**Dica 2**: depois, crie um **ModelConfig**, escolhendo o conteúdo e o tipo de aceitação, o nome do modelo, o tipo de instância e a contagem de instâncias.\n",
    "\n",
    "**Dica 3**: em seguida, crie uma configuração **ModelPredictedLabelConfig**, definindo o limite de probabilidade.\n",
    "\n",
    "**Dica 4**: por último, crie uma **BiasConfig**, definindo os valores ou o limite de rótulo, o nome da faceta e os valores ou o limite de faceta.\n",
    "\n",
    "Quais facetas você quer explorar primeiro no relatório de viés? Há recursos que são mais suscetíveis a viés?\n",
    "\n",
    "Para obter etapas detalhadas que mostram como criar uma configuração de viés do SageMaker Clarify, consulte <a href=\"#task4-3\" target=\"_self\">**Criar uma configuração de viés do SageMaker Clarify (Tarefa 4.3)**</a> na seção *Apêndice*.\n",
    "\n",
    "Depois de criar uma configuração de viés do SageMaker Clarify, você terá concluído esta tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_4_3_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 4.4: Usar um trabalho de processador do SageMaker Clarify para gerar relatórios de viés, dados e modelo\n",
    "\n",
    "<a id=\"task4-4-continue\"></a>\n",
    "\n",
    "Você já pode escolher todas as configurações para os relatórios de viés, dados e modelo. Agora, gere os relatórios.\n",
    "\n",
    "**Dica 1**: passe os valores de **data_config**, **bias_config**, **model_predicted_label_config** e **model_config** para **run_bias**.\n",
    "\n",
    "**Dica 2**: é necessário definir **pre_training_methods** e **post_training_methods**.\n",
    "\n",
    "Para obter etapas detalhadas que mostram como gerar relatórios de viés, dados e modelo usando o SageMaker Clarify, consulte <a href=\"#task4-4\" target=\"_self\">**Gerar relatórios de viés, dados e modelo usando o SageMaker Clarify (Tarefa 4.4)**</a> na seção *Apêndice*.\n",
    "\n",
    "Depois de usar um trabalho de processador do SageMaker Clarify para gerar relatórios de viés, dados e modelo, você terá concluído esta tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_4_4_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 4.5: Remover o desequilíbrio detectado com o SageMaker Clarify (opcional)\n",
    "\n",
    "<a id=\"task4-5-continue\"></a>\n",
    "\n",
    "Há várias maneiras de remover o desequilíbrio detectado com o SageMaker Clarify. Use qualquer método que você já conheça. Neste laboratório, é demonstrado um exemplo de técnica de sobreamostragem minoritária sintética (SMOTE) que remove o viés de uma das colunas.\n",
    "\n",
    "**Dica 1**: quando você concluir a remoção do desequilíbrio e quiser testar novamente, crie um dataframe de reamostragem. Na próxima tarefa, você vai criar e carregar um arquivo CSV.\n",
    "\n",
    "Para obter etapas detalhadas que mostram como remover o desequilíbrio, consulte <a href=\"#task4-5\" target=\"_self\">**Remover o desequilíbrio (Tarefa 4.5)**</a> na seção *Apêndice*.\n",
    "\n",
    "Depois de remover o desequilíbrio detectado com o SageMaker Clarify, você terá concluído esta tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_4_5_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 4.6: Retreinar o modelo (opcional)\n",
    "\n",
    "<a id=\"task4-6-continue\"></a>\n",
    "\n",
    "Carregue o novo arquivo no Amazon S3. Depois, crie um estimador e retreine com os novos dados.\n",
    "\n",
    "**Dica 1**: use **s3_client.upload_file** para carregar o novo arquivo no bucket.\n",
    "\n",
    "**Dica 2**: use **xgboost_starter_script.py** e chame **XGBoost**. Depois, retreine o modelo com os novos dados.\n",
    "\n",
    "O modelo retreinado atingiu uma pontuação de F1 superior? Se você usou o SageMaker Debugger, conseguiu resolver todos os problemas descobertos?\n",
    "\n",
    "Para obter etapas detalhadas que mostram como retreinar o modelo, consulte <a href=\"#task4-6\" target=\"_self\">**Retreinar o modelo (Tarefa 4.6)**</a> na seção *Apêndice*.\n",
    "\n",
    "Depois de retreinar o modelo, você terá concluído esta tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_4_6_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafio 5: Transformação em lote\n",
    "\n",
    "O modelo está pronto para implantação. Use um trabalho de transformação em lote com registros em lote e veja os dados de previsão e precisão no Amazon S3. Depois, limpe algumas das instâncias do SageMaker.\n",
    "\n",
    "Para concluir essa tarefa, realize estas subtarefas:\n",
    "\n",
    "- Criar um trabalho de transformação em lote para o modelo.\n",
    "- Visualizar os dados de previsão no Amazon S3.\n",
    "- Limpar instâncias do SageMaker (opcional).\n",
    "\n",
    "Este desafio exige cerca de *40* minutos para ser concluído."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 5.1: Criar um trabalho de transformação em lote para o modelo\n",
    "\n",
    "<a id=\"task5-1-continue\"></a>\n",
    "\n",
    "Crie um trabalho de transformação em lote usando **transformer** no estimador de modelo. Depois, execute o trabalho em lote.\n",
    "\n",
    "**Dica 1**: use o transformador e configure **instance_count**, **instance_type**, **strategy**, **assemble_with** e **output_path**.\n",
    "\n",
    "**Dica 2**: envie os dados de teste, listados em **test_path**, ao endpoint e aguarde os resultados.\n",
    "\n",
    "Para obter etapas detalhadas que mostram como criar um trabalho de transformação em lote, consulte <a href=\"#task5-1\" target=\"_self\">**Criar um trabalho de transformação de lote (Tarefa 5.1)**</a> na seção *Apêndice*.\n",
    "\n",
    "Depois de criar um trabalho de transformação em lote e executá-lo com um conjunto de registros, você terá concluído esta tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_5_1_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 5.2: Visualizar os dados de previsão no Amazon S3\n",
    "\n",
    "<a id=\"task5-2-continue\"></a>\n",
    "\n",
    "Quando o trabalho de transformação em lote estiver concluído, leia os dados do Amazon S3. \n",
    "\n",
    "**Dica 1**: é possível copiar os dados da saída do transformador usando **%aws s3 cp --recursive $transformer.output_path ./**\n",
    "\n",
    "**Dica 2**: quando você tiver os dados, poderá vê-los com **%head test_data_batch.csv.out**\n",
    "\n",
    "Observe as previsões. Há previsões surpreendentes?\n",
    "\n",
    "Para obter etapas detalhadas que mostram como visualizar dados de previsão de um trabalho de transformação em lote, consulte <a href=\"#task5-2\" target=\"_self\">**Visualizar dados de previsão de um trabalho de transformação em lote (Tarefa 5.2)**</a> na seção *Apêndice*.\n",
    "\n",
    "Depois de visualizar os dados do trabalho de transformação em lote, você terá concluído esta tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_5_2_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 5.3: Limpar instâncias do SageMaker (opcional)\n",
    "\n",
    "Para manter um nível baixo de custos, a prática recomendada é excluir as instâncias que não estão sendo mais usadas. É possível excluir instâncias rapidamente usando o SageMaker Studio. Agora, dedique um momento para abrir os recursos atuais no SageMaker Studio e fechar as instância restantes.\n",
    "\n",
    "Se você planeja fazer a próxima tarefa de pipeline, **deixe a instância do notebook em execução**.\n",
    "\n",
    "**Dica 1**: é possível visualizar uma lista de instâncias em execução clicando no ícone **Running Terminals and Kernels** (Terminais e kernels em execução) no SageMaker Studio.\n",
    "\n",
    "**Dica 2**: é possível usar o ícone **Shut down** (Fechar) para interromper a instância.\n",
    "\n",
    "<a id=\"task5-3-continue\"></a>\n",
    "\n",
    "Para obter etapas detalhadas que mostram como limpar instâncias do SageMaker no SageMaker Studio, consulte <a href=\"#task5-3\" target=\"_self\">**Limpar instâncias do SageMaker no SageMaker Studio (Tarefa 5.3)**</a> na seção *Apêndice*.\n",
    "\n",
    "Depois de parar todas as instâncias do SageMaker no SageMaker Studio, você terá concluído esta tarefa."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desafio 6: Criar um pipeline automatizado (opcional)\n",
    "\n",
    "Agora que você já usou o SDK Python do Amazon SageMaker e o Amazon SageMaker Studio para um fluxo de trabalho de machine learning (ML), use o SageMaker Pipelines para dimensionar o fluxo de trabalho. Continue no script do pipeline fornecido no ambiente de laboratório para realizar este desafio. \n",
    "\n",
    "- Crie as etapas do pipeline.\n",
    "    - Consulte os dados processados do SageMaker Feature Store.\n",
    "    - Treine e ajuste o modelo.\n",
    "    - Avalie o modelo treinado.\n",
    "    - Realize um trabalhos de transformação em lote.\n",
    "    - Registre um modelo.\n",
    "    - Avalie o treinamento do modelo com o SageMaker Clarify.\n",
    "- Defina e inicie o pipeline.\n",
    "- Visualize o ML Lineage Tracking.\n",
    "\n",
    "Este desafio exige cerca de *120* minutos para ser concluído.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 6.1: Configurar um pipeline\n",
    "\n",
    "<a id=\"task6-1-continue\"></a>\n",
    "\n",
    "Use um modelo de pipeline e configure entradas e saídas. Quando as configurações estiverem prontas, execute o pipeline. O pipeline pode incluir uma ampla variedade de etapas. Veja uma lista de sugestões de etapas de configuração:\n",
    "- **AutoModelProcess**: uma etapa **Processing** que obtém o arquivo .csv e divide-o em conjuntos de dados de treinamento, teste e validação.\n",
    "- **AutoHyperParameterTuning**: uma etapa **Tuning** que obtém um intervalo de hiperparâmetros e ajusta o modelo.\n",
    "- **AutoEvalBestModel**: uma etapa **Processing** que cria um relatório de avaliação para descrever o melhor modelo.\n",
    "- **CheckAUCScoreAutoEvaluation**: uma etapa **Condition** que avalia os modelos com base em uma métrica de avaliação. \n",
    "- **AutoCreateModel**: uma etapa **Model** que cria um modelo.\n",
    "- **RegisterAutoModel-RegisterModel**: uma etapa **RegisterModel** que registra um modelo.\n",
    "- **AutoModelConfigFile**: uma etapa **Processing** que cria um relatório de viés.\n",
    "- **AutoTransform**: uma etapa **Transform** que executa um trabalho de transformação em lote.\n",
    "- **ClarifyProcessingStep**: uma etapa **Processing** que executa um trabalho do SageMaker Clarify.\n",
    "\n",
    "**Dica 1**: há várias etapas de pipeline que você pode escolher. Para saber mais sobre as etapas de pipeline e visualizar o código de exemplo de cada etapa, consulte o documento *Criar e gerenciar etapas de pipeline* na seção *Recursos adicionais*.\n",
    "\n",
    "**Dica 2**: inicie com uma etapa **Processing** para obter os dados. Depois, crie uma etapa **Tuning** para ajustar o modelo. Depois, crie uma etapa **Model** para criar o modelo.\n",
    "\n",
    "**Dica 3**: as etapas detalhadas contêm uma solução de exemplo e incluem etapas para criar relatórios de avaliação, gerar um relatório de viés, executar um trabalho de transformação em lote e executar um trabalho do SageMaker Clarify. \n",
    "\n",
    "Para obter etapas detalhadas que mostram como configurar um pipeline, veja <a href=\"#task6-1\" target=\"_self\">**Configurar um pipeline (Tarefa 6.1)**</a> na seção *Apêndice*.\n",
    "\n",
    "Depois de configurar o pipeline e iniciar o trabalho de pipeline, você terá concluído esta tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_6_1_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 6.2: Monitorar o pipeline\n",
    "\n",
    "<a id=\"task6-2-continue\"></a>\n",
    "\n",
    "Monitore o pipeline durante a execução, visualizando as entradas e as saídas. \n",
    "\n",
    "**Dica 1**: use “RunPipeline.describe()” para descrever o pipeline recém-criado.\n",
    "\n",
    "**Dica 2**: é possível visualizar as etapas do pipeline em execução na IU do SageMaker Studio. Abra o menu **SageMaker resources** (Recursos do SageMaker), selecione **Pipelines** e escolha o pipeline que você criou. \n",
    "\n",
    "Para obter etapas detalhadas que mostram como monitorar um pipeline, consulte <a href=\"#task6-2\" target=\"_self\">**Monitorar um pipeline**</a> no *Apêndice*.\n",
    "\n",
    "Ao terminar de monitorar o pipeline, você terá concluído esta tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_6_2_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parabéns! Você usou um conjunto de dados de seguro de automóvel para detectar sinistros com possibilidade de fraude. Você explorou uma solução técnica para prever a probabilidade de que um determinado sinistro de seguro de automóvel seja fraudulenta usando o SageMaker Studio e o SDK Python do Amazon SageMaker.\n",
    "\n",
    "## Limpeza\n",
    "\n",
    "Você concluiu este notebook. Passe para a próxima parte do laboratório da seguinte forma:\n",
    "\n",
    "- Feche este arquivo de notebook.\n",
    "- Retorne à sessão do laboratório e continue com a **Conclusão**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursos adicionais\n",
    "\n",
    "- [métricas do Autopilot](https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-metrics-validation.html)\n",
    "- [Etapa de processamento](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apêndice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-1\" id=\"task1-1\"></a>\n",
    "\n",
    "### Apêndice: Examinar os dados (Tarefa 1.1)\n",
    "\n",
    "Para examinar os dados, especifique o caminho e carregue os dados usando o Pandas. Dedique um momento para examinar um exemplo das duas tabelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read-csv-files\n",
    "claims_data = pd.read_csv(\"./data/claims_preprocessed.csv\", index_col=0)\n",
    "customers_data = pd.read_csv(\"./data/customers_preprocessed.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#claims-data-sample\n",
    "claims_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customers-data-sample\n",
    "customers_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar este laboratório, retorne à <a href=\"#task1-1-continue\" target=\"_self\">Tarefa 1.1</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-2-1\" id=\"task1-2-1\"></a>\n",
    "\n",
    "### Apêndice: Explorar um conjunto de dados no SageMaker Studio (Tarefa 1.2)\n",
    "\n",
    "Comece a exploração de dados no SageMaker Data Wrangler. Importe os arquivos do bucket do S3 e analise os dados.\n",
    "\n",
    "A próxima etapa abrirá uma nova aba no SageMaker Studio. Para seguir essas orientações, escolha uma das seguintes opções:\n",
    "- **Opção 1:** visualizar as abas lado a lado. Para criar uma visualização de tela dividida por meio da janela principal do SageMaker Studio, arraste a aba **capstone.ipynb** para a lateral ou selecione a aba **capstone.ipynb** e, na barra de ferramentas, escolha **File** (Arquivo) e **New View for Notebook** (Nova visualização do notebook). Agora, as orientações ficam visíveis enquanto você explora o grupo de recursos.\n",
    "- **Opção 2:** alternar entre as abas do SageMaker Studio para seguir essas instruções.\n",
    "\n",
    "1. Na lateral esquerda do SageMaker Studio, escolha o ícone **Home** (Página inicial).\n",
    "1. Expanda a seção **Data** (Dados) e escolha **Data Wrangler**.\n",
    "\n",
    "O SageMaker Studio abre a aba **Data Wrangler**.\n",
    "\n",
    "1. Escolha **+** **Create Data Wrangler flow** (+ Criar fluxo do Data Wrangler).\n",
    "\n",
    "O SageMaker Studio abre a aba **untitled.flow**.\n",
    "\n",
    "1. Aguarde a conclusão do carregamento da aba **untitled.flow**, indicada por uma barra de progresso. A conclusão pode demorar de dois a três minutos.\n",
    "\n",
    "O SageMaker Studio abre a página **Create connection** (Criar conexão) da aba *Data Wrangler*.\n",
    "\n",
    "1. Abra o menu de contexto (clique com o botão direito do mouse) na aba do arquivo **untitled.flow** e, para alterar o nome do arquivo, escolha **Rename Data Wrangler Flow...** (Renomear o fluxo do Data Wrangler...).\n",
    "\n",
    "O SageMaker Studio abre a janela de mensagem **Rename File** (Renomear arquivo).\n",
    "\n",
    "1. Em **New Name** (Novo nome), insira “CapstoneDataWrangler.flow”.\n",
    "1. Escolha <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">Rename (Renomear)</span>.\n",
    "\n",
    "A janela de mensagem **Rename File** (Renomear arquivo) é fechada.\n",
    "\n",
    "1. Na aba *CapstoneDataWrangler.flow*, na seção **Fontes de dados**, escolha **Amazon S3**.\n",
    "\n",
    "O SageMaker Studio abre a página **Import a dataset from S3** (Importar um conjunto de dados do S3) dentro da aba *DataWrangler.flow*.\n",
    "\n",
    "1. Na lista de buckets, abra o bucket que contém **databucket** no nome.\n",
    "1. Escolha o primeiro conjunto de dados, um arquivo chamado **claims.csv**.\n",
    "\n",
    "1. Escolha <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">Importar</span>.\n",
    "\n",
    "1. Retorne à visualização **Data flow** (Fluxo de dados), escolha o **&lt; Fluxo de dados** localizado na parte superior esquerda da aba *CapstoneDataWrangler.flow*.\n",
    "1. Selecione a aba **Import** (Importar), localizada na parte superior esquerda da aba *CapstoneDataWrangler.flow* tab.\n",
    "\n",
    "O SageMaker Studio abre a página *Create connection** (Criar conexão).\n",
    "\n",
    "1. Na aba *CapstoneDataWrangler.flow*, na seção **Fontes de dados**, escolha **Amazon S3**.\n",
    "\n",
    "O SageMaker Studio abre a página **Import a dataset from S3** (Importar um conjunto de dados do S3) dentro da aba *DataWrangler.flow*.\n",
    "\n",
    "1. Na lista de buckets, abra o bucket que contém **databucket** no nome.\n",
    "1. Escolha o segundo conjunto de dados, um arquivo chamado **customers.csv**.\n",
    "1. Escolha <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">Importar</span>.\n",
    "\n",
    "1. Retorne à visualização **Data flow** (Fluxo de dados), escolha o **&lt; Fluxo de dados** localizado na parte superior esquerda da aba *CapstoneDataWrangler.flow*.\n",
    "\n",
    "1. Na aba Fluxo de dados, selecione o sinal **+** ao lado do ícone **Data types** (Tipos de dados) e escolha **Get data insights** (Obter informações de dados).\n",
    "\n",
    "1. Crie o relatório e explore as informações.\n",
    "\n",
    "1. Retorne à aba **Data flow** (Fluxo de dados), selecione o sinal **+** ao lado do ícone **Data types** (Tipos de dados) e escolha **Add analysis** (Adicionar análise).\n",
    "\n",
    "1. Crie a análise e explore os resultados.\n",
    "\n",
    "Use qualquer tipo de relatório que ajude a explorar os conjuntos de dados por completo. Ao concluir, continue na próxima tarefa.\n",
    "\n",
    "Para continuar este laboratório, retorne à <a href=\"#task1-2-continue\" target=\"_self\">Tarefa 1.2</a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-2-2\" id=\"task1-2-2\"></a>\n",
    "\n",
    "### Apêndice: Explorar um conjunto de dados no notebook (Tarefa 1.2)\n",
    "\n",
    "Há muitas maneiras de explorar os conjuntos de dados. Veja vários exemplos de etapas de exploração de dados que você pode seguir. Use-as como referência para iniciar a exploração dos aspectos do conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gender-graph\n",
    "import matplotlib.pyplot as plt\n",
    "customers_data.customer_gender_female.value_counts(normalize=True).plot.bar()\n",
    "plt.xticks([0, 1], [\"Male\", \"Female\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fraud-graph\n",
    "claims_data.fraud.value_counts(normalize=True).plot.bar()\n",
    "plt.xticks([0, 1], [\"Not Fraud\", \"Fraud\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#education-category-graphs\n",
    "educ = customers_data.customer_education.value_counts(normalize=True, sort=False)\n",
    "plt.bar(educ.index, educ.values)\n",
    "plt.xlabel(\"Customer Education Level\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#claim-amount-graph\n",
    "plt.hist(claims_data.total_claim_amount, bins=30)\n",
    "plt.xlabel(\"Total Claim Amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#claims-filed-graph\n",
    "customers_data.num_claims_past_year.hist(density=True)\n",
    "plt.suptitle(\"Number of Claims in the Past Year\")\n",
    "plt.xlabel(\"Number of claims per year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paid-plot-graphs\n",
    "sns.pairplot(\n",
    "    data=customers_data, vars=[\"num_insurers_past_5_years\", \"months_as_customer\", \"customer_age\"]\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fraud-insurers-graph\n",
    "combined_data = customers_data.join(claims_data)\n",
    "sns.lineplot(x=\"num_insurers_past_5_years\", y=\"fraud\", data=combined_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#months-as-customer-graph\n",
    "sns.boxplot(x=customers_data[\"months_as_customer\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customer-age-graph\n",
    "sns.boxplot(x=customers_data[\"customer_age\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fraud-gender-graph\n",
    "combined_data.groupby(\"customer_gender_female\").mean()[\"fraud\"].plot.bar()\n",
    "plt.xticks([0, 1], [\"Male\", \"Female\"])\n",
    "plt.suptitle(\"Fraud by Gender\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation-matrix-graph\n",
    "cols = [\n",
    "    \"fraud\",\n",
    "    \"customer_gender_male\",\n",
    "    \"customer_gender_female\",\n",
    "    \"months_as_customer\",\n",
    "    \"num_insurers_past_5_years\",\n",
    "]\n",
    "corr = combined_data[cols].corr()\n",
    "\n",
    "# plot the correlation matrix\n",
    "sns.heatmap(corr, annot=True, cmap=\"Reds\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load-combined-data\n",
    "combined_data = pd.read_csv(\"./data/claims_customer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove-unnecessary-columns\n",
    "combined_data = combined_data.loc[:, ~combined_data.columns.str.contains(\"^Unnamed: 0\")]\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe-combined-data\n",
    "combined_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate-statistics\n",
    "combined_stats = []\n",
    "\n",
    "for col in combined_data.columns:\n",
    "    combined_stats.append(\n",
    "        (\n",
    "            col,\n",
    "            combined_data[col].nunique(),\n",
    "            combined_data[col].isnull().sum() * 100 / combined_data.shape[0],\n",
    "            combined_data[col].value_counts(normalize=True, dropna=False).values[0] * 100,\n",
    "            combined_data[col].dtype,\n",
    "        )\n",
    "    )\n",
    "\n",
    "stats_df = pd.DataFrame(\n",
    "    combined_stats,\n",
    "    columns=[\"feature\", \"unique_values\", \"percent_missing\", \"percent_largest_category\", \"datatype\"],\n",
    ")\n",
    "stats_df.sort_values(\"percent_largest_category\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap-graph\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "corr_list = [\n",
    "    \"customer_age\",\n",
    "    \"months_as_customer\",\n",
    "    \"total_claim_amount\",\n",
    "    \"injury_claim\",\n",
    "    \"vehicle_claim\",\n",
    "    \"incident_severity\",\n",
    "    \"fraud\",\n",
    "]\n",
    "\n",
    "corr_df = combined_data[corr_list]\n",
    "corr = round(corr_df.corr(), 2)\n",
    "\n",
    "fix, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "mask = np.zeros_like(corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "ax = sns.heatmap(corr, mask=mask, ax=ax, annot=True, cmap=\"OrRd\")\n",
    "\n",
    "ax.set_xticklabels(ax.xaxis.get_ticklabels(), fontsize=10, ha=\"right\", rotation=45)\n",
    "ax.set_yticklabels(ax.yaxis.get_ticklabels(), fontsize=10, va=\"center\", rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar este laboratório, retorne à <a href=\"#task1-2-continue\" target=\"_self\">Tarefa 1.2</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-3-1\" id=\"task1-3-1\"></a>\n",
    "\n",
    "### Apêndice: Unificar tabelas no SageMaker Studio (Tarefa 1.3)\n",
    "\n",
    "1. Retorne à visualização **Data flow** (Fluxo de dados), escolha o **&lt; Fluxo de dados** localizado na parte superior esquerda da aba *CapstoneDataWrangler.flow*.\n",
    "1. Selecione o sinal **+** ao lado do ícone **claims.CSV Data types** (Tipos de dados claims.CSV) e, no menu de contexto, escolha **Join** (Unificar).\n",
    "\n",
    "O SageMaker Data Wrangler exibe a página **Unificar**.\n",
    "\n",
    "1. Escolha o ícone **customers.csv Data types** (Tipos de dados customers.csv).\n",
    "1. Selecione <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">Configurar</span>.\n",
    "1. Em **Join Type** (Tipo de junção), selecione **Inner** (Interna).\n",
    "1. Na seção **Columns** (Colunas):\n",
    "\n",
    "    - Em **Left** (Esquerda), selecione <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">policy_id</span>.\n",
    "    \n",
    "    - Em **Right** (Direita), selecione <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">policy_id</span>.\n",
    "\n",
    "1. Escolha <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">Visualizar</span>.\n",
    "\n",
    "1. Escolha <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">Adicionar</span>.\n",
    "\n",
    "Para continuar este laboratório, retorne à <a href=\"#task1-3-continue\" target=\"_self\">Tarefa 1.3</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-3-2\" id=\"task1-3-2\"></a>\n",
    "\n",
    "### Apêndice: Gerar um relatório de viés de pré-treinamento (Tarefa 1.3)\n",
    "\n",
    "Crie um relatório de viés do SageMaker Clarify usando um fluxo do SageMaker Data Wrangler.\n",
    "\n",
    "1. Escolha a aba **CapstoneDataWrangler.flow**.\n",
    "1. Acesse a visualização **Data flow** (Fluxo de dados). Se necessário, escolha o **&lt; Data flow** (&lt; Fluxo de dados) localizado na parte superior esquerda da aba *DataWranglerLab.flow*. \n",
    "1. Selecione o sinal **+** ao lado do ícone **Join** (Unificar) e, no menu de contexto, escolha **Add analysis** (Adicionar análise).\n",
    "1. Na seção **Create analysis** (Criar análise):\n",
    "\n",
    "- Em **Analysis type** (Tipo de análise), selecione **Bias Report** (Relatório de viés).\n",
    "- Em **Analysis name** (Nome da análise), insira “viés de fraude por idade”.\n",
    "- Em **Select the column your model predicts (target)** (Selecionar a coluna que o modelo prevê (destino)), selecione **fraud**.\n",
    "- Em **Is your predicted column a value or threshold?** (A coluna prevista é um valor ou um limite?), escolha a opção **value** (valor).\n",
    "- Em **Valores previstos**, insira **1**.\n",
    "- Em **Select the column to analyze for bias** (Selecionar a coluna para analisar o viés), selecione **customer_age**.\n",
    "\n",
    "1. Selecione <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">Check for bias (Verificar viés)</span>.\n",
    "\n",
    "Após a conclusão do trabalho, visualize as métricas retornadas. Observe se há viés e planeje as etapas de processamento que deverão ocorrer na coluna analisada. \n",
    "\n",
    "1. Selecione <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">Salvar</span> para manter as análises que deseja salvar.\n",
    "\n",
    "Você pode repetir essas etapas em todas as colunas em que deseja analisar o viés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar este laboratório, retorne à <a href=\"#task1-3-continue\" target=\"_self\">Tarefa 1.3</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-4-1\" id=\"task1-4-1\"></a>\n",
    "\n",
    "### Apêndice: Preparar dados usando o SageMaker Data Wrangler (Tarefa 1.4)\n",
    "\n",
    "Combine os conjuntos de dados. Unifique-os no SageMaker Data Wrangler usando o **policy_id**.\n",
    "\n",
    "Com o SageMaker Data Wrangler, é possível unificar dados em qualquer ponto no fluxo. É possível concluir a preparação de dados em arquivos individuais antes de unificá-los ou transformar os recursos após a unificação. Um fluxo do SageMaker Data Wrangler é flexível.\n",
    "\n",
    "Se você não unificou as tabelas na tarefa 1.3, as etapas a seguir mostrarão esse processo.\n",
    "\n",
    "1. Retorne à visualização **Data flow** (Fluxo de dados), escolha o **&lt; Fluxo de dados** localizado na parte superior esquerda da aba *CapstoneDataWrangler.flow*.\n",
    "1. Selecione o sinal **+** ao lado do ícone **Data types** (Tipos de dados) e, no menu de contexto, escolha **Join** (Unificar).\n",
    "\n",
    "O SageMaker Data Wrangler exibe a página **Join** (Unificar).\n",
    "\n",
    "1. Selecione o segundo ícone **Data types** (Tipos de dados).\n",
    "1. Selecione <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">Configurar</span>.\n",
    "1. Em **Join Type** (Tipo de junção), selecione **Inner** (Interna).\n",
    "1. Na seção **Columns** (Colunas):\n",
    "\n",
    "    - Em **Left** (Esquerda), selecione <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">policy_id</span>.\n",
    "    \n",
    "    - Em **Right** (Direita), selecione <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">policy_id</span>.\n",
    "\n",
    "1. Escolha <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">Visualizar</span>.\n",
    "\n",
    "1. Escolha <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">Adicionar</span>.\n",
    "\n",
    "Com as tabelas de dados unificadas, transforme os dados combinados.\n",
    "\n",
    "1. Retorne à visualização **Data flow** (Fluxo de dados), escolha o **&lt; Fluxo de dados** localizado na parte superior esquerda da aba *CapstoneDataWrangler.flow*.\n",
    "1. Selecione o sinal **+** ao lado do ícone **Join** (Unificar) e, no menu de contexto, escolha **Add transform** (Adicionar transformação).\n",
    "\n",
    "É possível adicionar várias transformações usando esse menu. Uma visualização do conjunto de dados é mostrada do lado esquerdo do menu de transformação.\n",
    "\n",
    "Adicione as seguintes etapas de transformação ao fluxo do SageMaker Data Wrangler:\n",
    "- Codificar de maneira categórica (codificação one-hot): **authorities_contacted**, **collision_type**, **customer_gender**, **driver_relationship**, **incident_type** e **policy_state** usando uma estratégia de manipulação de **Skip** (ignorar) inválidos, selecione o estilo de saída **Columns** (Colunas).\n",
    "- Codificar de maneira categórica (codificação ordinal): **customer_education**, **incident_severity**, **police_report_available** e **policy_liability** usando uma estratégia de manipulação de **Skip** (ignorar) inválidos.\n",
    "- Analisar coluna como tipo: **vehicle_claim** e **total_claim_amount** de **Float** para **Long**.\n",
    "- Gerenciar colunas (Remover coluna): **customer_zip** e **policy_id_1**.\n",
    "- Gerenciar colunas (Mover coluna): **fraud** (usando **Mover para início**).\n",
    "- Gerenciar colunas (Renomear colunas): substitua o símbolo **/** de **collision_type_N/A** e de **driver_relationship_N/A** por um **_**.\n",
    "- Gerenciar colunas (Renomear coluna): renomeie **policy_id_0** como **policy_id**.\n",
    "\n",
    "Se algum nome de coluna contiver um caractere **/**, renomeie a coluna para substituir **/** por **_**. Se algum nome de coluna contiver um caractere de espaço em branco, renomeie a coluna para substituir o espaço em branco por **_**. Por exemplo, toda coluna criada com a codificação one-hot que tiver **N/A** como valor, precisará ser renomeada. O SageMaker Feature Store não aceita colunas que contenham o caractere **/** ou espaço em branco.\n",
    "\n",
    "Quando você tiver transformado os dados e puder começar a treinar o modelo, continue na próxima tarefa. É possível voltar a este fluxo a qualquer momento para fazer alterações considerando as descobertas feitas durante o treinamento e o ajuste.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar este laboratório, retorne à <a href=\"#task1-4-continue\" target=\"_self\">Tarefa 1.4</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-4-2\" id=\"task1-4-2\"></a>\n",
    "\n",
    "### Apêndice: Importar um conjunto de exemplo de dados processados (Tarefa 1.4)\n",
    "\n",
    "Se o pré-processamento for interrompido ou se você quiser carregar um conjunto de dados que já foi processado, acesse os dados processados armazenados na pasta de dados no bucket do S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed-data-import\n",
    "s3_client.upload_file(Filename=\"data/claims_customer.csv\", Bucket=bucket, Key=f\"{prefix}/data/raw/claims_customer.csv\")\n",
    "df_processed = pd.read_csv(\"./data/claims_customer.csv\", index_col=None)\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar este laboratório, retorne à <a href=\"#task1-4-continue\" target=\"_self\">Tarefa 1.4</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task2-1\" id=\"task2-1\"></a>\n",
    "\n",
    "### Apêndice: Criar um grupo de recursos usando a opção Exportar para (Tarefa 2.1)\n",
    "\n",
    "O SageMaker Data Wrangler pode exportar dados para o SageMaker Feature Store. Ele cria um notebook com todo o código necessário para configurar um grupo de recursos e fazer a ingestão dos dados transformados no grupo de recursos.\n",
    "\n",
    "1. Escolha **Add step** (Adicionar etapa).\n",
    "\n",
    "1. Escolha **Custom transform** (Transformação personalizada).\n",
    "\n",
    "1. Em **Name** (Nome), insira “event_time”. \n",
    "\n",
    "1. Selecione **Python (PySpark)**, se essa opção ainda não estiver selecionada.\n",
    "\n",
    "1. Em **Your custom transform** (Sua transformação personalizada), insira o seguinte:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "from pyspark.sql.functions import lit\n",
    "date_time = datetime.date.today()\n",
    "\n",
    "df = df.withColumn(\"event_time\", lit(time.mktime(date_time.timetuple())))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Escolha <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">Visualizar</span>.\n",
    "\n",
    "1. Escolha <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">Adicionar</span>.\n",
    "\n",
    "Essa opção adiciona **event_time** como uma coluna ao conjunto de dados. O SageMaker Feature Store exige um **event_time** e um ID de **record** exclusivos. Use **policy_id** como o ID de **record**.\n",
    "\n",
    "1. Para retornar ao fluxo de dados, selecione o ícone **&lt; Data flow** (&lt; Fluxo de dados).\n",
    "\n",
    "1. Selecione o ícone **+** ao lado das suas transformações no SageMaker Data Wrangler.\n",
    "\n",
    "1. Selecione **Export to** (Exportar dados).\n",
    "\n",
    "1. Escolha **SageMaker Feature Store (via Jupyter Notebook)** (SageMaker Feature Store (por meio do caderno Jupyter)).\n",
    "\n",
    "Um novo notebook é aberto.\n",
    "\n",
    "1. Na primeira célula, altere as seguinte variáveis:\n",
    "- Em **record_identifier_feature_name**, substitua **None** (Nenhum) por `\"policy_id\"`. Se você unificou as tabelas de clientes e de sinistros e não removeu a segunda coluna **policy_id**, poderá ser necessário substituir **None** (Nenhum) por `\"policy_id_0\"`. Não altere o valor de **None** (Nenhum) após a instrução **if**.\n",
    "- Em **event_time_feature_name**, substitua **None** (Nenhum) por `\"event_time\"`. Não altere o valor de **None** (Nenhum) após a instrução **if**.\n",
    "\n",
    "**Saída selecionada:** quando você concluir a edição da célula, ela deverá estar semelhante a este exemplo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_identifier_feature_name = \"policy_id\"\n",
    "if record_identifier_feature_name is None:\n",
    "   raise SystemExit(\"Select a column name as the feature group record identifier.\")\n",
    "\n",
    "event_time_feature_name = \"event_time\"\n",
    "if event_time_feature_name is None:\n",
    "   raise SystemExit(\"Select a column name as the event time feature name.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Percorra todas as células para criar uma definição de recurso, criar um grupo de recursos e fazer a ingestão dos dados transformados no grupo de recursos usando um trabalho de processamento. \n",
    "\n",
    "Quando as células estiverem concluídas, o Feature Store estará pronto para uso.\n",
    "\n",
    "Para continuar este laboratório, retorne à <a href=\"#task2-1-continue\" target=\"_self\">Tarefa 2.1</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task2-2\" id=\"task2-2\"></a>\n",
    "\n",
    "### Apêndice: Extrair registros de um armazenamento off-line com o Athena (Tarefa 2.2)\n",
    "\n",
    "Configure uma consulta do Athena com **athena_query**. Em seguida, defina **query_string**. Por fim, execute a consulta e visualize um exemplo dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-and-run-athena-query\n",
    "try:\n",
    "    # If there is a feature group, get the name\n",
    "    feature_group_name = sagemaker_session.boto_session.client(\"sagemaker\", region_name=region).list_feature_groups()['FeatureGroupSummaries'][0]['FeatureGroupName']\n",
    "    feature_group = FeatureGroup(name=feature_group_name, sagemaker_session=sagemaker_session)\n",
    "\n",
    "    # Confirm the Athena settings are configured\n",
    "    try:\n",
    "        boto3.client('athena').update_work_group(\n",
    "            WorkGroup='primary',\n",
    "            ConfigurationUpdates={\n",
    "                'EnforceWorkGroupConfiguration':False\n",
    "            }\n",
    "        )\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Configure the query\n",
    "    query = feature_group.athena_query()\n",
    "    table = query.table_name\n",
    "    query_string = f'SELECT * FROM \"{table}\" '\n",
    "    output_location = f\"s3://{sagemaker_session.default_bucket()}/query_results/\"\n",
    "    print(f\"Athena query output location: \\n{output_location}\")\n",
    "\n",
    "    # Run the query\n",
    "    query.run(query_string=query_string, output_location=output_location)\n",
    "    query.wait()\n",
    "    df_feature_store = query.as_dataframe()\n",
    "    \n",
    "    # Wait for data to appear in the feature group\n",
    "    attempts = 0\n",
    "    while len(df_feature_store.index) == 0 and attempts < 30:\n",
    "        print(\"Waiting for feature group to populate...\")\n",
    "        time.sleep(60)\n",
    "        # Rerun the query\n",
    "        query.run(query_string=query_string, output_location=output_location)\n",
    "        query.wait()\n",
    "        df_feature_store = query.as_dataframe()\n",
    "        # Increment the attempts\n",
    "        attempts += 1\n",
    "    if len(df_feature_store.index) != 0:\n",
    "        print(\"The feature group is populated.\")\n",
    "except IndexError as e:\n",
    "    # If there is no feature group, thrown an error\n",
    "    print(\"No feature groups were found. Please create a feature group.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de executar o bloco de código anterior, o Amazon Athena consulta os registros salvos no bucket do Amazon S3 cujos nomes começam com *sagemaker*. O objeto de consulta salvo fica em um diretório chamado **query_results**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar este laboratório, retorne à <a href=\"#task2-2-continue\" target=\"_self\">Tarefa 2.2</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task3-1\" id=\"task3-1\"></a>\n",
    "\n",
    "### Apêndice: Nomear um experimento e uma execução (Tarefa 3.1)\n",
    "\n",
    "Para criar um experimento, use a biblioteca **sagemaker.experiments.run**. Defina o **experiment_name**, um **run_name** e a **description**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "#create experiment and run-names\n",
    "create_date = strftime(\"%m%d%H%M\")\n",
    "capstone_experiment_name=\"capstone-experiment-{}\".format(create_date)\n",
    "capstone_run_name = \"lab-capstone-run-{}\".format(create_date)\n",
    "\n",
    "# define a run_tag\n",
    "run_tags = [{'Key': 'lab-capstone', 'Value': 'lab-capstone-run'}]\n",
    "\n",
    "# provide a description\n",
    "description=\"Using SM Experiments with the Auto dataset.\"\n",
    "\n",
    "print(f\"Experiment name - {capstone_experiment_name},  run name - {capstone_run_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar este laboratório, retorne à <a href=\"#task3-1-continue\" target=\"_self\">Tarefa 3.1</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task3-2\" id=\"task3-2\"></a>\n",
    "\n",
    "### Apêndice: Dividir os dados em conjuntos de dados de treinamento, teste e validação (Tarefa 3.2)\n",
    "\n",
    "Para dividir os dados, use **np.split** e especifique como deseja fazer isso. Depois, crie arquivos CSV e carregue-os no bucket do S3. Em seguida, defina as entradas de treinamento. Por fim, crie a variável **data_inputs**. Use a variável data_inputs durante todo o desafio para especificar os conjuntos de dados de treinamento e de validação ao treinar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-validation-test-split\n",
    "try:\n",
    "    # If there is a feature group, use it\n",
    "    df_feature_store = df_feature_store.iloc[: , :-4]\n",
    "    df_processed_pre_split = df_feature_store\n",
    "    print(\"Using the records from the feature group\")\n",
    "except NameError:\n",
    "    # If there is no feature group, use the processed dataset\n",
    "    df_processed = pd.read_csv(\"./data/claims_customer.csv\", index_col=None)\n",
    "    df_processed_pre_split = df_processed\n",
    "    print(\"Using the processed records from Amazon S3\")\n",
    "\n",
    "# Split the data into train, validation, and test datasets\n",
    "train_data, validation_data, test_data = np.split(\n",
    "    df_processed_pre_split.sample(frac=1, random_state=1729),\n",
    "    [int(0.7 * len(df_processed_pre_split)), int(0.9 * len(df_processed_pre_split))],\n",
    ")\n",
    "\n",
    "# Create the CSV files and upload them to your default bucket\n",
    "train_data.to_csv(\"train_data.csv\", index=False, header=False)\n",
    "validation_data.to_csv(\"validation_data.csv\", index=False, header=False)\n",
    "test_data.to_csv(\"test_data.csv\", index=False, header=False)\n",
    "\n",
    "train_path = S3Uploader.upload(\"train_data.csv\", \"s3://{}/{}\".format(bucket, prefix))\n",
    "validation_path = S3Uploader.upload(\"validation_data.csv\", \"s3://{}/{}\".format(bucket, prefix))\n",
    "test_path = S3Uploader.upload(\"test_data.csv\", \"s3://{}/{}\".format(bucket, prefix))\n",
    "\n",
    "# Set the training inputs\n",
    "train_input = TrainingInput(train_path, content_type=\"text/csv\")\n",
    "validation_input = TrainingInput(validation_path, content_type=\"text/csv\")\n",
    "test_input = TrainingInput(test_path, content_type=\"text/csv\")\n",
    "\n",
    "data_inputs = {\n",
    "    \"train\": train_input,\n",
    "    \"validation\": validation_input\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar este laboratório, retorne à <a href=\"#task3-2-continue\" target=\"_self\">Tarefa 3.2</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task3-3-1\" id=\"task3-3-1\"></a>\n",
    "\n",
    "### Apêndice: Configurar e executar um trabalho de treinamento básico (Tarefa 3.3)\n",
    "\n",
    "Se você quiser começar com um trabalho de treinamento básico, use o contêiner **XGBoost** básico. Depois, configure o estimador, indicando o contêiner e a função que deseja usar. Depois de definir essas configurações, escolha os hiperparâmetros. Você pode usar os valores padrão fornecidos no código a seguir ou editá-los considerando suas descobertas durante a preparação de dados.\n",
    "\n",
    "Para executar o trabalho de treinamento, chame **fit()**, definindo as entradas como a variável **data_inputs** e definindo as configurações de **run_name** e **experiment_name**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker import image_uris\n",
    "#train-model\n",
    "# Retrieve the container image\n",
    "container = sagemaker.image_uris.retrieve(\n",
    "    region=boto3.Session().region_name, \n",
    "    framework=\"xgboost\", \n",
    "    version=\"1.5-1\"\n",
    ")\n",
    "\n",
    "# Set the hyperparameters\n",
    "eta=0.2\n",
    "gamma=4\n",
    "max_depth=5\n",
    "min_child_weight=6\n",
    "num_round=800\n",
    "objective='binary:logistic'\n",
    "subsample=0.8\n",
    "\n",
    "hyperparameters = {\n",
    "    \"eta\":eta,\n",
    "    \"gamma\":gamma,\n",
    "    \"max_depth\":max_depth,\n",
    "    \"min_child_weight\":min_child_weight,\n",
    "    \"num_round\":num_round,\n",
    "    \"objective\":objective,\n",
    "    \"subsample\":subsample\n",
    "}\n",
    "\n",
    "# Set up the estimator\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,    \n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    "    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    max_run=1800,\n",
    "    hyperparameters=hyperparameters,\n",
    "    tags = run_tags\n",
    ")\n",
    "\n",
    "with Run(\n",
    "    experiment_name=capstone_experiment_name,\n",
    "    run_name=capstone_run_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "    run.log_parameter(\"eta\", eta)\n",
    "    run.log_parameter(\"gamma\", gamma)\n",
    "    run.log_parameter(\"max_depth\", max_depth)\n",
    "    run.log_parameter(\"min_child_weight\", min_child_weight)\n",
    "    run.log_parameter(\"objective\", objective)\n",
    "    run.log_parameter(\"subsample\", subsample)\n",
    "    run.log_parameter(\"num_round\", num_round)\n",
    "\n",
    "# Train the model associating the training run with the current \"experiment\"\n",
    "    xgb.fit(\n",
    "        inputs = data_inputs\n",
    "    )        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar este laboratório, retorne à <a href=\"#task3-3-continue\" target=\"_self\">Tarefa 3.3</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task3-3-2\" id=\"task3-3-2\"></a>\n",
    "\n",
    "### Apêndice: Configurar e executar um trabalho de treinamento com o SageMaker Debugger ativado e analisar os relatórios (Tarefa 3.3)\n",
    "\n",
    "O SageMaker Debugger ajuda a encontrar relatórios adicionais que possam informar o ajuste dos hiperparâmetros rapidamente, economizando tempo ao iniciar a execução de mais trabalhos de treinamento com intervalos de hiperparâmetros. Para habilitar o Debugger, configure **DebuggerHookConfig** e **rules**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enable-debugger\n",
    "# Retrieve the container image\n",
    "container = sagemaker.image_uris.retrieve(\n",
    "    region=boto3.Session().region_name, \n",
    "    framework=\"xgboost\", \n",
    "    version=\"1.5-1\"\n",
    ")\n",
    "\n",
    "# Set the hyperparameters\n",
    "eta=0.2\n",
    "gamma=4\n",
    "max_depth=5\n",
    "min_child_weight=6\n",
    "num_round=300\n",
    "objective='binary:logistic'\n",
    "subsample=0.7\n",
    "        \n",
    "hyperparameters = {\n",
    "        \"eta\":eta,\n",
    "        \"gamma\":gamma,\n",
    "        \"max_depth\":max_depth,\n",
    "        \"min_child_weight\":min_child_weight,\n",
    "        \"num_round\":num_round,\n",
    "        \"objective\":objective,\n",
    "        \"subsample\":subsample\n",
    "}\n",
    "\n",
    "# Set up the estimator\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role, \n",
    "    base_job_name=base_job_name,\n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    "    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    max_run=1800,\n",
    "    hyperparameters=hyperparameters,\n",
    "    tags = run_tags,\n",
    "\n",
    "    #Set the Debugger Hook Config\n",
    "    debugger_hook_config=DebuggerHookConfig(\n",
    "        s3_output_path=bucket_path,  # Required\n",
    "        collection_configs=[\n",
    "            CollectionConfig(name=\"metrics\", parameters={\"save_interval\": str(save_interval)}),\n",
    "            CollectionConfig(name=\"feature_importance\", parameters={\"save_interval\": str(save_interval)},),\n",
    "            CollectionConfig(name=\"full_shap\", parameters={\"save_interval\": str(save_interval)}),\n",
    "            CollectionConfig(name=\"average_shap\", parameters={\"save_interval\": str(save_interval)}),\n",
    "        ],\n",
    "        ),\n",
    "        #Set the Debugger Profiler Configuration\n",
    "        profiler_config = ProfilerConfig(\n",
    "            system_monitor_interval_millis=500,\n",
    "            framework_profile_params=FrameworkProfile()\n",
    "    ),\n",
    "        #Configure the Debugger Rule Object\n",
    "        rules = [\n",
    "            ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "            Rule.sagemaker(rule_configs.create_xgboost_report()),  \n",
    "            Rule.sagemaker(rule_configs.overfit()),\n",
    "            Rule.sagemaker(rule_configs.overtraining()),\n",
    "            Rule.sagemaker(rule_configs.loss_not_decreasing(),\n",
    "                rule_parameters={\n",
    "                    \"collection_names\": \"metrics\",\n",
    "                    \"num_steps\": str(save_interval * 2),\n",
    "                }\n",
    "            )\n",
    "    ]\n",
    ")\n",
    "with Run(\n",
    "    experiment_name=capstone_experiment_name,\n",
    "    run_name=capstone_run_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "    run.log_parameter(\"eta\", eta)\n",
    "    run.log_parameter(\"gamma\", gamma)\n",
    "    run.log_parameter(\"max_depth\", max_depth)\n",
    "    run.log_parameter(\"min_child_weight\", min_child_weight)\n",
    "    run.log_parameter(\"objective\", objective)\n",
    "    run.log_parameter(\"subsample\", subsample)\n",
    "    run.log_parameter(\"num_round\", num_round)\n",
    "# Train the model\n",
    "xgb.fit(\n",
    "    inputs = data_inputs\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar este laboratório, retorne à <a href=\"#task3-3-continue\" target=\"_self\">Tarefa 3.3</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task3-4\" id=\"task3-4\"></a>\n",
    "\n",
    "### Apêndice: Configurar os intervalos de hiperparâmetros de treinamento (Tarefa 3.4)\n",
    "\n",
    "Agora que você já treinou pelo menos um modelo, aplique o que aprendeu com o processamento dos dados e o SageMaker Debugger para informar quais são os intervalos selecionados para os hiperparâmetros. Edite os seguintes intervalos de hiperparâmetros e execute o trabalho de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune-model\n",
    "# Setup the hyperparameter ranges\n",
    "hyperparameter_ranges = {\n",
    "    \"alpha\": ContinuousParameter(0, 2),\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "    \"max_depth\": IntegerParameter(1, 10),\n",
    "    \"min_child_weight\": ContinuousParameter(1, 10),\n",
    "    \"num_round\": IntegerParameter(100, 1000)\n",
    "}\n",
    "\n",
    "# Define the target metric and the objective type (max/min)\n",
    "objective_metric_name = \"validation:auc\"\n",
    "objective_type=\"Maximize\"\n",
    "\n",
    "# Define the HyperparameterTuner\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator = xgb,\n",
    "    objective_metric_name = objective_metric_name,\n",
    "    hyperparameter_ranges = hyperparameter_ranges,\n",
    "    objective_type = objective_type,\n",
    "    max_jobs=12,\n",
    "    max_parallel_jobs=4,\n",
    "    early_stopping_type=\"Auto\"\n",
    ")\n",
    "\n",
    "# Tune the model\n",
    "tuner.fit(\n",
    "    inputs = data_inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar este laboratório, retorne à <a href=\"#task3-4-continue\" target=\"_self\">Tarefa 3.4</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-1\" id=\"task4-1\"></a>\n",
    "\n",
    "### Apêndice: Criar um modelo (Tarefa 4.1)\n",
    "\n",
    "Crie um modelo do XGBoost chamando **create_model** com **model_name**, **role** e **container_def** definidos por você."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model-configurations\n",
    "model_name = \"capstone-clarify-model\"\n",
    "model = xgb.create_model(name=model_name)\n",
    "container_def = model.prepare_container_def()\n",
    "sagemaker_session.create_model(model_name, role, container_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar este laboratório, retorne à <a href=\"#task4-1-continue\" target=\"_self\">Tarefa 4.1</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-2\" id=\"task4-2\"></a>\n",
    "\n",
    "### Apêndice: Criar uma configuração de modelo do SageMaker Clarify (Tarefa 4.2)\n",
    "\n",
    "Crie uma configuração de modelo do SageMaker Clarify usando **SageMakerClarifyProcessor**. Defina **instance_count** e **instance_type**. Use **role** e **session** criados no início do Projeto final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define-clarify-processor\n",
    "clarify_processor = clarify.SageMakerClarifyProcessor(\n",
    "    role=role, \n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.m5.xlarge\", \n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar este laboratório, retorne à <a href=\"#task4-2-continue\" target=\"_self\">Tarefa 4.2</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-3\" id=\"task4-3\"></a>\n",
    "\n",
    "### Apêndice: Criar uma configuração de viés do SageMaker Clarify (Tarefa 4.3)\n",
    "\n",
    "Para criar uma configuração de viés do SageMaker Clarify, escolha um caminho de saída para os dados e defina o caminho de entrada do trabalho de treinamento, além de **label**, **headers** e **dataset_type**.\n",
    "\n",
    "Depois, crie **ModelConfig** e **ModelPredictedLabelConfig**.\n",
    "\n",
    "Por fim, configure **BiasConfig** com os campos que o SageMaker Clarify deverá observar. Você pode adicionar ou remover os campos que deseja explorar, considerando as descobertas iniciais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define-data-config\n",
    "bias_report_output_path = \"s3://{}/{}/clarify-bias\".format(bucket, prefix)\n",
    "bias_data_config = clarify.DataConfig(\n",
    "    s3_data_input_path=train_path,\n",
    "    s3_output_path=bias_report_output_path,\n",
    "    label=\"fraud\",\n",
    "    headers=train_data.columns.to_list(),\n",
    "    dataset_type=\"text/csv\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define-model-config\n",
    "model_config = clarify.ModelConfig(\n",
    "    model_name=model_name,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    accept_type=\"text/csv\",\n",
    "    content_type=\"text/csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define-label-config\n",
    "predictions_config = clarify.ModelPredictedLabelConfig(probability_threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define-bias-config\n",
    "bias_config = clarify.BiasConfig(\n",
    "    label_values_or_threshold=[1], facet_name=\"customer_gender_female\", facet_values_or_threshold=[0], group_name=\"customer_age\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar este laboratório, retorne à <a href=\"#task4-3-continue\" target=\"_self\">Tarefa 4.3</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-4\" id=\"task4-4\"></a>\n",
    "\n",
    "### Apêndice: Gerar relatórios de viés, dados e modelo usando SageMaker Clarify (Tarefa 4.4)\n",
    "\n",
    "Agora que o trabalho do SageMaker Clarify já está configurado, execute-o chamando **run_bias**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run-bias-report\n",
    "clarify_processor.run_bias(\n",
    "    data_config=bias_data_config,\n",
    "    bias_config=bias_config,\n",
    "    model_config=model_config,\n",
    "    model_predicted_label_config=predictions_config,\n",
    "    pre_training_methods=\"all\",\n",
    "    post_training_methods=\"all\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar este laboratório, retorne à <a href=\"#task4-4-continue\" target=\"_self\">Tarefa 4.4</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-5\" id=\"task4-5\"></a>\n",
    "\n",
    "### Apêndice: Remover desequilíbrio (Tarefa 4.5)\n",
    "\n",
    "Neste exemplo, você está aumentando a taxa de amostragem de **customer_gender_female** para reduzir o viés no conjunto de dados. Se você encontrar outras características que apresentem viés, também poderá remover esse desequilíbrio. A opção **random_state** foi definida como “42”, mas você pode alterar isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display-summary\n",
    "gender = train_data[\"customer_gender_female\"]\n",
    "gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove-imbalance\n",
    "sm = SMOTE(random_state=42)\n",
    "train_data_upsampled, gender_res = sm.fit_resample(train_data, gender)\n",
    "train_data_upsampled[\"customer_gender_female\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar este laboratório, retorne à <a href=\"#task4-5-continue\" target=\"_self\">Tarefa 4.5</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-6\" id=\"task4-6\"></a>\n",
    "\n",
    "### Apêndice: Retreinar o modelo (Tarefa 4.6)\n",
    "\n",
    "Você encontrou um desequilíbrio e tem um novo conjunto de dados de treinamento. Use esse conjunto de dados e retreine o arquivo. Para fazer isso, carregue o novo arquivo e crie um estimador. Depois, retreine os dados com **fit()**. Há vários hiperparâmetros de exemplo incluídos no código abaixo. Você pode adicionar, remover ou ajustar esses hiperparâmetros durante o retreinamento para encontrar o melhor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload-upsampled-csv\n",
    "train_data_upsampled.to_csv(\"data/upsampled_train.csv\", index=False, header=False)\n",
    "retrain_path = S3Uploader.upload(\"data/upsampled_train.csv\", \"s3://{}/{}\".format(bucket, prefix))\n",
    "retrain_input = TrainingInput(retrain_path, content_type=\"text/csv\")\n",
    "\n",
    "retrain_data_inputs = {\n",
    "    \"train\": retrain_input,\n",
    "    \"validation\": validation_input\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create-estimator\n",
    "hyperparameters= {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.7\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": \"300\",\n",
    "}\n",
    "\n",
    "xgb_retrained = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role, \n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters=hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrain-upsampled-data\n",
    "xgb_retrained.fit(\n",
    "    inputs = retrain_data_inputs\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar este laboratório, retorne à <a href=\"#task4-6-continue\" target=\"_self\">Tarefa 4.6</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task5-1\" id=\"task5-1\"></a>\n",
    "\n",
    "### Apêndice: Criar um trabalho de transformação em lote (Tarefa 5.1)\n",
    "\n",
    "Use o estimador de modelo e crie um trabalho de transformação em lote com **transformer**. Defina a estratégia de **MultiRecord** para aumentar a eficiência do processamento. Depois, passe o **test_path** e aguarde a execução da inferência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create-batch-transformer\n",
    "# Use the retrained model if it exists, otherwise, use the original model\n",
    "try:\n",
    "    model = xgb_retrained\n",
    "except NameError:\n",
    "    model = xgb\n",
    "\n",
    "# Create the transformer\n",
    "transformer = model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    strategy=\"MultiRecord\",\n",
    "    assemble_with=\"Line\",\n",
    "    accept=\"text/csv\",\n",
    "    output_path=\"s3://{}/{}/batch-transform/\".format(bucket, prefix)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run-batch-transform-job\n",
    "test_data_batch = test_data.drop(\"fraud\", axis=1)\n",
    "test_data_batch.to_csv(\"test_data_batch.csv\", index=False, header=False)\n",
    "test_path_batch = S3Uploader.upload(\"test_data_batch.csv\", \"s3://{}/{}\".format(bucket, prefix))\n",
    "\n",
    "transformer.transform(test_path_batch, content_type=\"text/csv\", split_type=\"Line\", join_source=\"Input\")\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar este laboratório, retorne à <a href=\"#task5-1-continue\" target=\"_self\">Tarefa 5.1</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task5-2\" id=\"task5-2\"></a>\n",
    "\n",
    "### Apêndice: Visualizar dados de previsão e precisão de um trabalho de transformação em lote (Tarefa 5.2)\n",
    "\n",
    "Quando o trabalho de transformação em lote for concluído, visualize os dados de previsão armazenados no Amazon S3. Você pode consultar o caminho de saída que definiu no **transformer** e amostrar os dados.\n",
    "\n",
    "Nessa saída, a previsão **fraud** é acrescentada ao final de cada registro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $transformer.output_path ./\n",
    "test_data = pd.read_csv(\"test_data_batch.csv.out\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar este laboratório, retorne à <a href=\"#task5-2-continue\" target=\"_self\">Tarefa 5.2</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task5-3\" id=\"task5-3\"></a>\n",
    "\n",
    "### Apêndice: limpar as instâncias de SageMaker no SageMaker Studio (Tarefa 5.3)\n",
    "\n",
    "Ao desenvolver modelos no SageMaker Studio, verifique periodicamente se há instâncias que você deseja limpar. Se houver, você poderá fechá-las por meio do SageMaker Studio.\n",
    "\n",
    "1. Na barra de menus à esquerda, selecione o ícone **Running Terminals and Kernels** (Terminais e kernels em execução) (círculo com um quadrado no meio).\n",
    "\n",
    "1. Se houver instâncias que ainda estejam abertas, à direita de cada tipo de instância, escolha o ícone **Shut down** (Fechar). \n",
    "\n",
    "Você pode visualizar as aplicações que estão em execução em cada instância para confirmar quais deseja fechar.\n",
    "\n",
    "1. Se uma janela pop-up aparecer, selecione **Shut down all** (Fechar tudo).\n",
    "\n",
    "1. Selecione o ícone **Refresh List** (Atualizar lista) periodicamente até que a instância não apareça mais na lista. Podem ser necessários de dois a cinco minutos para que a instância feche.\n",
    "\n",
    "Você não precisa fechar a instância que o notebook **capstone.ipynb** está usando.\n",
    "\n",
    "Para continuar este laboratório, retorne à <a href=\"#task5-3-continue\" target=\"_self\">Tarefa 5.3</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task6-1\" id=\"task6-1\"></a>\n",
    "\n",
    "### Apêndice: configurar um pipeline (Tarefa 6.1)\n",
    "\n",
    "Para criar um pipeline, defina cada etapa do processo do pipeline e execute-o.\n",
    "\n",
    "Neste exemplo, você cria as seguintes etapas:\n",
    "- **AutoModelProcess**: uma etapa **Processing** que obtém o arquivo .csv e divide-o em conjuntos de dados de treinamento, teste e validação.\n",
    "- **AutoHyperParameterTuning**: uma etapa **Tuning** que obtém um intervalo de hiperparâmetros e ajusta o modelo.\n",
    "- **AutoEvalBestModel**: uma etapa **Processing** que cria um relatório de avaliação para descrever o melhor modelo.\n",
    "- **CheckAUCScoreAutoEvaluation**: uma etapa **Condition** que avalia os modelos com base em uma métrica de avaliação. \n",
    "- **AutoCreateModel**: uma etapa **Model** que cria um modelo.\n",
    "- **RegisterAutoModel-RegisterModel**: uma etapa **RegisterModel** que registra um modelo.\n",
    "- **AutoModelConfigFile**: uma etapa **Processing** que cria um relatório de viés.\n",
    "- **AutoTransform**: uma etapa **Transform** que executa um trabalho de transformação em lote.\n",
    "- **ClarifyProcessingStep**: uma etapa **Processing** que executa um trabalho do SageMaker Clarify.\n",
    "\n",
    "Se você não souber como proceder em algum momento durante a criação do pipeline, personalize o código a seguir ou use-o como um guia para criar o pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run-pipeline\n",
    "# Set the variables\n",
    "model_name = \"Auto-model\"\n",
    "sklearn_processor_version=\"0.23-1\"\n",
    "model_package_group_name=\"AutoModelPackageGroup\"\n",
    "pipeline_name= \"AutoModelSMPipeline\"\n",
    "clarify_image = sagemaker.image_uris.retrieve(framework='sklearn',version=sklearn_processor_version,region=region)\n",
    "\n",
    "# Upload files to the default S3 bucket\n",
    "s3_client.put_object(Bucket=bucket,Key='data/')\n",
    "s3_client.put_object(Bucket=bucket,Key='input/code/')\n",
    "s3_client.upload_file(Filename=\"data/batch_data.csv\", Bucket=bucket, Key=\"data/batch_data.csv\")  #If you edit this, make sure to also edit the headers listed in generate_config to match your column names.\n",
    "s3_client.upload_file(Filename=\"data/claims_customer.csv\", Bucket=bucket, Key=\"data/claims_customer.csv\")  #If you edit this, make sure to also edit the headers listed in generate_config to match your column names.\n",
    "s3_client.upload_file(Filename=\"pipelines/evaluate.py\", Bucket=bucket, Key=\"input/code/evaluate.py\")\n",
    "s3_client.upload_file(Filename=\"pipelines/generate_config.py\", Bucket=bucket, Key=\"input/code/generate_config.py\")\n",
    "s3_client.upload_file(Filename=\"pipelines/preprocess.py\", Bucket=bucket, Key=\"input/code/preprocess.py\")\n",
    "\n",
    "# Configure important settings. Change the input_data if you want to\n",
    "# use a file other than the claims_customer.csv and batch_data.csv files.\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "processing_instance_type = ParameterString(\n",
    "        name=\"ProcessingInstanceType\",\n",
    "        default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "training_instance_type = ParameterString(\n",
    "        name=\"TrainingInstanceType\",\n",
    "        default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "input_data = ParameterString(\n",
    "        name=\"InputData\",\n",
    "        default_value=\"s3://{}/data/claims_customer.csv\".format(bucket), \n",
    ")\n",
    "batch_data = ParameterString(\n",
    "        name=\"BatchData\",\n",
    "        default_value=\"s3://{}/data/batch_data.csv\".format(bucket),\n",
    ")\n",
    "\n",
    "# Run a scikit-learn script to do data processing on SageMaker using \n",
    "# using the SKLearnProcessor class\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "        framework_version=sklearn_processor_version,\n",
    "        instance_type=processing_instance_type.default_value, \n",
    "        instance_count=processing_instance_count,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        role=role,\n",
    ")\n",
    "\n",
    "# Configure the processing step to pull in the input_data\n",
    "step_process = ProcessingStep(\n",
    "        name=\"AutoModelProcess\",\n",
    "        processor=sklearn_processor,\n",
    "        outputs=[\n",
    "            ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\",\\\n",
    "                             destination=f\"s3://{bucket}/output/train\" ),\n",
    "            ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\",\\\n",
    "                            destination=f\"s3://{bucket}/output/validation\"),\n",
    "            ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\",\\\n",
    "                            destination=f\"s3://{bucket}/output/test\"),\n",
    "            ProcessingOutput(output_name=\"batch\", source=\"/opt/ml/processing/batch\",\\\n",
    "                            destination=f\"s3://{bucket}/data/batch\"),\n",
    "            ProcessingOutput(output_name=\"baseline\", source=\"/opt/ml/processing/baseline\",\\\n",
    "                            destination=f\"s3://{bucket}/input/baseline\")\n",
    "        ],\n",
    "        code=f\"s3://{bucket}/input/code/preprocess.py\",\n",
    "        job_arguments=[\"--input-data\", input_data],\n",
    ")\n",
    "\n",
    "# Set up the model path, image uri, and hyperparameters for the estimator\n",
    "model_path = f\"s3://{bucket}/output\"\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.5-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=training_instance_type.default_value,\n",
    ")\n",
    "\n",
    "fixed_hyperparameters = {\n",
    "    \"eval_metric\":\"auc\",\n",
    "    \"objective\":\"binary:logistic\",\n",
    "    \"num_round\":\"100\",\n",
    "    \"rate_drop\":\"0.3\",\n",
    "    \"tweedie_variance_power\":\"1.4\"\n",
    "}\n",
    "\n",
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    hyperparameters=fixed_hyperparameters,\n",
    "    output_path=model_path,\n",
    "    base_job_name=f\"auto-train\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "# Set the hyperparameter ranges for the tuning step and configure the tuning step\n",
    "hyperparameter_ranges = {\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "    \"min_child_weight\": ContinuousParameter(1, 10),\n",
    "    \"alpha\": ContinuousParameter(0, 2),\n",
    "    \"max_depth\": IntegerParameter(1, 10),\n",
    "}\n",
    "objective_metric_name = \"validation:auc\"\n",
    "\n",
    "step_tuning = TuningStep(\n",
    "    name = \"AutoHyperParameterTuning\",\n",
    "    tuner = HyperparameterTuner(xgb_train, objective_metric_name, hyperparameter_ranges, max_jobs=2, max_parallel_jobs=2),\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    },\n",
    ")\n",
    "\n",
    "# Configure the processing step for evaluation\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"script-auto-eval\",\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"AutoEvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\",\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"AutoEvalBestModel\",\n",
    "    processor=script_eval,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_tuning.get_top_model_s3_uri(top_k=0,s3_bucket=bucket,prefix=\"output\"),\n",
    "            destination=\"/opt/ml/processing/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\",\\\n",
    "                            destination=f\"s3://{bucket}/output/evaluation\"),\n",
    "    ],\n",
    "    code=f\"s3://{bucket}/input/code/evaluate.py\",\n",
    "    property_files=[evaluation_report],\n",
    ")\n",
    "\n",
    "# Configure model creation\n",
    "model = Model(\n",
    "    image_uri=image_uri,        \n",
    "    model_data=step_tuning.get_top_model_s3_uri(top_k=0,s3_bucket=bucket,prefix=\"output\"),\n",
    "    name=model_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "inputs = CreateModelInput(\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    accelerator_type=\"ml.inf1.xlarge\",\n",
    ")\n",
    "\n",
    "step_create_model = CreateModelStep(\n",
    "    name=\"AutoCreateModel\",\n",
    "    model=model,\n",
    "    inputs=inputs,\n",
    ")\n",
    "\n",
    "script_processor = ScriptProcessor(\n",
    "    command=['python3'],\n",
    "    image_uri=clarify_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=processing_instance_type,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "bias_report_output_path = f\"s3://{bucket}/clarify-output/bias\"\n",
    "clarify_instance_type = 'ml.m5.xlarge'\n",
    "step_config_file = ProcessingStep(\n",
    "    name=\"AutoModelConfigFile\",\n",
    "    processor=script_processor,\n",
    "    code=f\"s3://{bucket}/input/code/generate_config.py\",\n",
    "    job_arguments=[\"--modelname\",step_create_model.properties.ModelName,\"--bias-report-output-path\",bias_report_output_path,\"--clarify-instance-type\",clarify_instance_type,\\\n",
    "                  \"--default-bucket\",bucket,\"--num-baseline-samples\",\"50\",\"--instance-count\",\"1\"],\n",
    "    depends_on= [step_create_model.name]\n",
    ")\n",
    "\n",
    "# Configure the step to perform a batch transform job\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    assemble_with=\"Line\",\n",
    "    accept=\"text/csv\",    \n",
    "    output_path=f\"s3://{bucket}/AutoTransform\"\n",
    ")\n",
    "\n",
    "step_transform = TransformStep(\n",
    "    name=\"AutoTransform\",\n",
    "    transformer=transformer,\n",
    "    inputs=TransformInput(data=batch_data,content_type=\"text/csv\",join_source=\"Input\",split_type=\"Line\")\n",
    ")\n",
    "\n",
    "# Configure the SageMaker Clarify processing step\n",
    "analysis_config_path = f\"s3://{bucket}/clarify-output/bias/analysis_config.json\"\n",
    "\n",
    "data_config = sagemaker.clarify.DataConfig(\n",
    "    s3_data_input_path=f's3://{bucket}/output/train/train.csv', \n",
    "    s3_output_path=bias_report_output_path,\n",
    "    label=0,\n",
    "    headers=list(pd.read_csv(\"./data/claims_customer.csv\", index_col=None).columns), #If you edit this, make sure to also edit the headers listed in generate_config to match your column names.\n",
    "    dataset_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "clarify_processor = sagemaker.clarify.SageMakerClarifyProcessor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=clarify_instance_type,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "config_input = ProcessingInput(\n",
    "    input_name=\"analysis_config\",\n",
    "    source=analysis_config_path,\n",
    "    destination=\"/opt/ml/processing/input/analysis_config\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    s3_input_mode=\"File\",\n",
    "    s3_compression_type=\"None\",\n",
    ")\n",
    "\n",
    "data_input = ProcessingInput(\n",
    "    input_name=\"dataset\",\n",
    "    source=data_config.s3_data_input_path,\n",
    "    destination=\"/opt/ml/processing/input/data\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    s3_input_mode=\"File\",\n",
    "    s3_data_distribution_type=data_config.s3_data_distribution_type,\n",
    "    s3_compression_type=data_config.s3_compression_type,\n",
    ")\n",
    "\n",
    "result_output = ProcessingOutput(\n",
    "    source=\"/opt/ml/processing/output\",\n",
    "    destination=data_config.s3_output_path,\n",
    "    output_name=\"analysis_result\",\n",
    "    s3_upload_mode=\"EndOfJob\",\n",
    ")\n",
    "\n",
    "step_clarify = ProcessingStep(\n",
    "    name=\"ClarifyProcessingStep\",\n",
    "    processor=clarify_processor,\n",
    "    inputs= [data_input, config_input],\n",
    "    outputs=[result_output],\n",
    "    depends_on = [step_config_file.name]\n",
    ")\n",
    "\n",
    "# Configure the model registration step\n",
    "model_statistics = MetricsSource(\n",
    "    s3_uri=\"s3://{}/output/evaluation/evaluation.json\".format(bucket),\n",
    "    content_type=\"application/json\"\n",
    ")\n",
    "explainability = MetricsSource(\n",
    "    s3_uri=\"s3://{}/clarify-output/bias/analysis.json\".format(bucket),\n",
    "    content_type=\"application/json\"\n",
    ")\n",
    "\n",
    "bias = MetricsSource(\n",
    "    s3_uri=\"s3://{}/clarify-output/bias/analysis.json\".format(bucket),\n",
    "    content_type=\"application/json\"\n",
    ") \n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=model_statistics,\n",
    "    explainability=explainability,\n",
    "    bias=bias\n",
    ")\n",
    "\n",
    "step_register = RegisterModel(\n",
    "    name=\"RegisterAutoModel\",\n",
    "    estimator=xgb_train,\n",
    "    model_data=step_tuning.get_top_model_s3_uri(top_k=0,s3_bucket=bucket,prefix=\"output\"),\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    model_metrics=model_metrics,\n",
    ")\n",
    "\n",
    "# Create the model evaluation step\n",
    "cond_lte = ConditionGreaterThan(\n",
    "    left=JsonGet(\n",
    "        step=step_eval,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"binary_classification_metrics.auc.value\"\n",
    "    ),\n",
    "    right=0.75,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"CheckAUCScoreAutoEvaluation\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_create_model,step_config_file,step_transform,step_clarify,step_register],\n",
    "    else_steps=[],\n",
    ")\n",
    "\n",
    "# Define the pipeline\n",
    "def get_pipeline(\n",
    "    region,\n",
    "    role=None,\n",
    "    default_bucket=None,\n",
    "    model_package_group_name=\"AutoModelPackageGroup\",\n",
    "    pipeline_name=\"AutoModelPipeline\",\n",
    "    base_prefix = None,\n",
    "    custom_image_uri = None,\n",
    "    sklearn_processor_version=None\n",
    "    ):\n",
    "    \"\"\"Gets a SageMaker ML Pipeline instance working with auto data.\n",
    "    Args:\n",
    "        region: AWS region to create and run the pipeline.\n",
    "        role: IAM role to create and run steps and pipeline.\n",
    "        default_bucket: the bucket to use for storing the artifacts\n",
    "    Returns:\n",
    "        an instance of a pipeline\n",
    "    \"\"\"\n",
    "\n",
    "    # pipeline instance\n",
    "    pipeline = Pipeline(\n",
    "        name=pipeline_name,\n",
    "        parameters=[\n",
    "            processing_instance_type,\n",
    "            processing_instance_count,\n",
    "            training_instance_type,\n",
    "            input_data,\n",
    "            batch_data,\n",
    "        ],\n",
    "        steps=[step_process,step_tuning,step_eval,step_cond],\n",
    "        sagemaker_session=sagemaker_session\n",
    "    )\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = get_pipeline(\n",
    "    region = region,\n",
    "    role=role,\n",
    "    default_bucket=bucket,\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    pipeline_name=pipeline_name,\n",
    "    custom_image_uri=clarify_image,\n",
    "    sklearn_processor_version=sklearn_processor_version\n",
    ")\n",
    "\n",
    "pipeline.upsert(role_arn=role)\n",
    "\n",
    "# Run the pipeline\n",
    "RunPipeline = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar este laboratório, retorne à <a href=\"#task6-1-continue\" target=\"_self\">Tarefa 6.1</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task6-2\" id=\"task6-2\"></a>\n",
    "\n",
    "### Apêndice: monitorar um pipeline (Tarefa 6.2)\n",
    "\n",
    "Agora que você já criou e executou o pipeline, monitore-o. Veja o status do pipeline no SageMaker Studio.\n",
    "\n",
    "Se você quiser excluir o pipeline, remova-o usando **delete_pipeline**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe-pipeline\n",
    "RunPipeline.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list-pipeline-steps\n",
    "RunPipeline.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove-pipeline\n",
    "response = sagemaker_session.boto_session.client(\"sagemaker\", region_name=region).delete_pipeline(PipelineName='AutoModelSMPipeline')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar este laboratório, retorne à <a href=\"#task6-2-continue\" target=\"_self\">Tarefa 6.2</a>."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "741de909edea0d5644898c592544ed98bede62b404d20772e5c4abc3c2f12566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
