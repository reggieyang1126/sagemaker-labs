{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# キャップストーン: SageMaker Studio と SageMaker Python SDK を使用して、エンドツーエンドの表形式データ機械学習プロジェクトを構築する"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境の設定\n",
    "\n",
    "ラボの開始に必要となる、基本的な設定コードは以下に用意されています。パッケージのインストールと変数の作成のために、まずこれらのセルを読み込んで実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U shap\n",
    "%pip install -U smdebug\n",
    "%pip install imbalanced-learn\n",
    "%pip install pytest-cov\n",
    "%pip install pytest-filter-subpackage\n",
    "%pip install sagemaker\n",
    "%pip install -U seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#必要なライブラリ\n",
    "\n",
    "import boto3\n",
    "import datetime as datetime\n",
    "import io\n",
    "import IPython\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt  # visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import re\n",
    "import sagemaker\n",
    "import seaborn as sns  # visualization\n",
    "import statistics\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sagemaker import clarify\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from sagemaker.dataset_definition.inputs import AthenaDatasetDefinition, DatasetDefinition, RedshiftDatasetDefinition\n",
    "from sagemaker.debugger import CollectionConfig, DebuggerHookConfig, FrameworkProfile, ProfilerConfig, ProfilerRule, Rule, rule_configs\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.experiments.run import Run, load_run\n",
    "from sagemaker.feature_store.feature_definition import FeatureDefinition\n",
    "from sagemaker.feature_store.feature_definition import FeatureTypeEnum\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.processing import FeatureStoreOutput\n",
    "from sagemaker.processing import Processor, ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.workflow.condition_step import ConditionStep, JsonGet\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThan\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterFloat, ParameterString\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本的な変数とコードの設定\n",
    "\n",
    "%matplotlib inline\n",
    "base_job_name = \"capstone-smdebugger-job\"\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "bucket_path = \"s3://{}\".format(bucket)\n",
    "prefix = \"sagemaker/capstone\"\n",
    "region = boto3.Session().region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sagemaker_session = sagemaker.Session()\n",
    "save_interval = 5\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットの説明\n",
    "\n",
    "Amazon Simple Storage Service (Amazon S3) バケットに、以下の 5 つのテーブルが保存されています。\n",
    "- **claims.csv**: 保険金請求の raw データを含むテーブル\n",
    "- **customers.csv**: 顧客の raw データを含むテーブル\n",
    "- **claims_preprocessed.csv**: 保険金請求の処理済みデータを含むテーブル\n",
    "- **customers_preprocessed.csv**: 顧客の処理済みデータを含むテーブル\n",
    "- **claims_customer.csv**: 処理済みの保険金請求データと顧客データを **policy_id** で結合したテーブル\n",
    "\n",
    "このラボでは、まず **claims.csv** と **customers.csv** のテーブルから見ていきます。**課題 1** で、Amazon SageMaker Data Wrangler を使用し、これらのテーブルを処理します。作業がうまくいかない場合や、処理済みのデータセットを参照する場合は、処理済みのテーブルの内容を確認できます。\n",
    "\n",
    "このデータセットでは、claims.csv テーブルの **fraud** 列がターゲットです。\n",
    "\n",
    "claims.csv テーブルには、以下のフィールドがあります。\n",
    "\n",
    "- **policy_id**: 保険契約の固有 ID\n",
    "- **driver_relationship**: ドライバーとの関係性に関するリスト (配偶者、本人、子ども、その他、該当なし)\n",
    "- **incident_type**: 報告された事故のタイプ (侵入、衝突、盗難)\n",
    "- **collision_type**: 衝突した場所 (前面、背面、側面、該当なし)\n",
    "- **incident_severity**: 事故の重大度 (軽微、重大、全損)\n",
    "- **authorities_contacted**: 最初に通報した公的機関 (なし、警察、救急車、消防)\n",
    "- **num_vehicles_involved**: 事故に巻き込まれた車両の数 (1～6 台の範囲)\n",
    "- **num_injuries**: 事故による負傷者の数 (1～4 人の範囲)\n",
    "- **num_witnesses**: 事故の目撃者の数 (1～5 人の範囲)\n",
    "- **police_report_available**: 警察の報告書があるかどうか (はい、または いいえ)\n",
    "- **injury_claim**: 傷害に対する保険金請求額 (米ドル) (300～576,300 USD)\n",
    "- **vehicle_claim**: 車両損害に対する保険金請求額 (米ドル) (1,000～51,051 USD)\n",
    "- **total_claim_amount**: 傷害と車両損害に対する保険金請求額の合計 (2,100～588,868 USD)\n",
    "- **incident_month**: 事故が発生した月 (1～12 の範囲)\n",
    "- **incident_day**: 事故が発生した日 (1～31 の範囲)\n",
    "- **incident_dow**: 事故が発生した曜日 (日曜日から土曜日を表す 0～6 の範囲)\n",
    "- **incident_hour**: 事故が発生した時刻 (0～23 の範囲)\n",
    "- **fraud**: 保険契約が不正であったかどうか (0 または 1)\n",
    "\n",
    "customers.csv テーブルには、以下のフィールドがあります。\n",
    "\n",
    "- **policy_id**: 保険契約の固有 I\n",
    "- **customer_age**: 当該顧客の年齢 (18～70 歳の範囲)\n",
    "- **months_as_customer**: この顧客が保険料を支払った月数 (1～495 の範囲)\n",
    "- **num_claims_past_year**: 当該顧客が過去 1 年間に行った保険金請求の件数\n",
    "- **num_insurers_past_5_years**: 当該顧客が過去 5 年間に加入していた保険会社数\n",
    "- **policy_state**: 当該顧客が住んでいる州 (AZ、CA、ID、NV、OR、WA)\n",
    "- **policy_deductable**: 保険の免責金額 (米ドル) (750～1,100 USD の範囲)\n",
    "- **policy_annual_premium**: 年間保険料 (米ドル) (2,200～3,000 USD の範囲)\n",
    "- **policy_liability**: 対人賠償の上限額。単一の対人賠償およびすべての対人賠償額の上限額 (15/30、25/50、60/90、100/200)\n",
    "- ***customer_zip**: 当該顧客の郵便番号 (83201～99362 の範囲)\n",
    "- **customer_gender**: 当該顧客の性別 (男性、女性、その他、不明)\n",
    "- **customer_education**: 当該顧客の教育レベル (高校未満、高校、準学士号、学士号、上級学位)\n",
    "- **auto_year**: 車両の製造年 (2001～2020 の範囲)\n",
    "\n",
    "これらのテーブルを、**policy_id** 列を使用した 内部結合で結合します。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題ラボのナビゲーション\n",
    "\n",
    "このラボには、課題のタスクやノートブックの最後にある付録に移動するためのリンクが用意されています。付録の項目を確認するには、解説のハイパーリンクをクリックします。現在作業中の課題に戻るには、付録に記載されている、対応するタスクのハイパーリンクをクリックします。\n",
    "\n",
    "このラボは、以下のように構成されています。\n",
    "\n",
    "- 課題 1: SageMaker Data Wrangler を使用してデータセットを分析して準備する\n",
    "- 課題 2: SageMaker Feature Store で特徴量グループを作成する\n",
    "- 課題 3: モデルをトレーニングする\n",
    "- 課題 4: モデルのバイアスを評価する\n",
    "- 課題 5: バッチ変換\n",
    "- 課題 6: 自動化されたパイプラインを構築する\n",
    "- 付録"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題 1: SageMaker Data Wrangler を使用してデータセットを分析して準備する\n",
    "\n",
    "AnyCompany Consulting は、自動車保険詐欺のデータセットを分析し、新規の保険金請求について詐欺の可能性があるかどうかを予測するのに役立つモデルを構築したいという依頼を受けました。同社は、それぞれの保険金請求が不正かどうかをラベル付けした 5,000 件の顧客レコードを保有しています。このデータを使って、新しいレコードに対しバッチ推論を実行する前に、モデルのトレーニング、テスト、検証を行うことができます。\n",
    "\n",
    "Amazon SageMaker Data Wrangler の分析機能を使用して、重要な列のデータ分布を可視化し、列間の相関をチェックし、データリーケージをチェックします。次に、簡単なベースラインモデルを構築します。そして、SageMaker Data Wrangler のデータ処理機能を使用して、よりパフォーマンスの高いモデルトレーニングに適するように列を変換します。\n",
    "\n",
    "このタスクを完了するために、以下のサブタスクを実行します。\n",
    "\n",
    "- データを表示する。\n",
    "- Amazon SageMaker Studio で探索的データ分析を完了する。\n",
    "- Amazon SageMaker Clarify のプロセッサジョブを使用してバイアスレポートを実行する。\n",
    "- データを準備する。\n",
    "\n",
    "この課題の所要時間は約 _100_ 分です。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 1.1: データを表示する\n",
    "\n",
    "<a id=\"task1-1-continue\"></a>\n",
    "\n",
    "リポジトリに保存されている自動車保険の表形式データセットにアクセスし、データセットのサンプルを表示します。このリポジトリには、顧客データ (**customers.csv**) と保険金請求データ (**claims.csv**) の 2 つの未処理テーブルが含まれています。\n",
    "\n",
    "**ヒント 1**: 未処理のテーブルは、**./data/** フォルダに保存されています。\n",
    "\n",
    "**ヒント 2**: **claims.csv** と **customers.csv** テーブルは、未処理のテーブルです。\n",
    "\n",
    "少し時間を取ってテーブルを確認してください。目立ったフィールドはありますか。 慎重な前処理が必要なフィールドはありますか。\n",
    "\n",
    "データの表示方法については、「<a href=\"#task1-1\" target=\"_self\">**データを表示する**</a>」を参照してください。\n",
    "\n",
    "自動車保険詐欺のテーブルにアクセスし、データセットのサンプルを確認したら、このタスクは完了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここにタスク 1.1 のコードを追加する\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 1.2: SageMaker Studio で探索的データ分析を完了する\n",
    "\n",
    "<a id=\"task1-2-continue\"></a>\n",
    "\n",
    "データを表示し、データセット内の潜在的な問題を特定し、ターゲットに対して強い相関がある列があるかどうかを確認したら、探索的データ分析は完了です。データは SageMaker Data Wrangler とノートブックで調査できます。\n",
    "\n",
    "具体的には、以下の項目について時間を取って確認してください。\n",
    "- **列のヒストグラム**: 列を視覚的に表示し、データセットにどのような値が含まれているかを確認します。\n",
    "- **クイックモデル**: データセットを見て、予想されるモデルの結果を考えます。\n",
    "- **特徴量の相関**: ターゲットと強い相関がある列があるかどうかを確認します。\n",
    "- **データリーケージ**: ターゲット値に依存するデータがあるかどうかを確認します。\n",
    "\n",
    "SageMaker Data Wrangler を開くと、SageMaker Studio の新しいタブが開きます。以下のオプション２つのうち、どちらか1 つを実行して手順を進めます。\n",
    "- **オプション 1:** タブを並べて表示します。メインの SageMaker Studio ウィンドウから分割画面ビューを作成するには、[**capstone_ja_jp.ipynb**] タブを横にドラッグするか、[**capstone_ja_jp.ipynb**] タブを選択 (右クリック) し、[**New View for Notebook**] をクリックします。これで Data Wrangler のフローを実行しながら、操作方法を表示できるようになりました。\n",
    "- **オプション 2:** SageMaker Studio のタブを切り替えながら、手順を進めます。Data Wrangler の手順の調査を終了する場合は、[**capstone.ipynb**] タブをクリックしてノートブックに戻ります。\n",
    "\n",
    "新しいフローファイルの作成時に **The following instance type is not available: ml.m5.4xlarge.Try selecting a different instance below.** (次のインスタンスタイプは利用できません: ml.m5.4xlarge。以下に示す別のインスタンスを選択してください) というエラーメッセージが表示される場合は、別のインスタンスタイプを選択します。代わりに **ml.m5.8xlarge** を試してみてください。\n",
    "\n",
    "**An error occurred loading this view** (このビューを読み込む際にエラーが発生しました) と表示される場合は、[**untitled.flow**] タブを閉じ、ファイルブラウザからフローファイルを開き直してください。\n",
    "\n",
    "**ヒント 1**: データセットを調査する方法はいくつもあります。SageMaker Data Wrangler のフローを開き、調査を開始できます。**claims.csv** と **customers.csv** の両方を、**databucket-** で始まる S3 バケットから Data Wrangler にインポートする必要があります。\n",
    "\n",
    "**ヒント 2**: 2 つ目のテーブルをインポートするには、[**Data flow**] に戻り、[**Import**] タブをクリックして、別のデータセットをインポートします。\n",
    "\n",
    "**ヒント 3**: Data Wrangler では、[**Get data insights**] と [**Add analysis**] の 2 つの方法でデータを調査できます。データを使ってサンプルグラフをいくつか表示した後、必要に応じてノートブックの他のプロットツールを使ってデータを分析をすることもできます。**plt** と **sns** のライブラリはインストールされています。使い慣れた分析ツールを自由に使って、データセットを調査してください。 \n",
    "\n",
    "結合したデータセットから、より意味のある結果が得られましたか。\n",
    "\n",
    "SageMaker Studio でデータセットを調査する方法については、「<a href=\"#task1-2-1\" target=\"_self\">**データセットを SageMaker Studio で確認する**</a>」を参照してください。\n",
    "\n",
    "ノートブックでデータセットを調査する方法については、「<a href=\"#task1-2-2\" target=\"_self\">**データセットをノートブックで確認する**</a>」を参照してください。\n",
    "\n",
    "データセットを調査し、実行する処理手順を確認したら、このタスクは完了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここにタスク 1.2 のコードを追加する\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 1.3: SageMaker Clarify のプロセッサジョブを使用してバイアスレポートを実行する\n",
    "\n",
    "<a id=\"task1-3-continue\"></a>\n",
    "\n",
    "SageMaker Clarify を使用して、トレーニング前のバイアスレポートを実行し、データ内のクラスの不均衡を特定します。SageMaker Data Wrangler フローを使用して、SageMaker Studio でバイアスレポートを実行します。\n",
    "1. まず、2 つのテーブルを結合します。\n",
    "\n",
    "- 統合: **Inner** 結合で **claims.csv** を **customers.csv** に**policy_id**を基に統合してください。\n",
    "\n",
    "**ヒント 1**: トレーニング前のバイアスレポートを作成するには、Data Wrangler フローに新しい分析を追加し、[**Analysis type**] で [**Bias Report**] を選択します。\n",
    "\n",
    "**ヒント 2**: バイアスレポートを何度か実行し、その都度異なる特徴量を使って分析できます。\n",
    "\n",
    "Data Wranglerを使用してテーブルを結合する方法の詳細な手順については、**付録** セクションの <a href=\"#task1-3-1\" target=\"_self\">**SageMaker Studio でのテーブルの結合 (タスク 1.3)**</a> を参照してください。\n",
    "\n",
    "トレーニング前のバイアスレポートの実行方法については、<a href=\"#task1-3-2\" target=\"_self\">**トレーニング前のバイアスレポートを実行する (タスク 1.3)**</a> を参照してください。\n",
    "\n",
    "トレーニング前のバイアスレポートを実行し、レポートを確認したら、このタスクは完了です。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 1.4: データを準備する\n",
    "\n",
    "<a id=\"task1-4-continue\"></a>\n",
    "\n",
    "SageMaker Studio の SageMaker Data Wrangler を使用して、データセットを準備します。以下の変換を列挙していますが、他の変換も自由に使用してください。\n",
    "\n",
    "- Join: **claims.csv** から **customers.csv** に **policy_id** に基づいて **Inner** 結合する。\n",
    "- Encode categorical (one-hot エンコーディング): **authorities_contacted**、**collision_type**、**customer_gender**、**driver_relationship**、**incident_type**、**policy_state** をエンコードする。\n",
    "- Ordinal encode: **customer_education**、**policy_liability**、**incident_severity**、**policy_report_available** をエンコードする。\n",
    "- Parse column as type: **vehicle_claim** と **total_claim_amount** を **Float** から **Long** に変換する。\n",
    "- Drop column: **customer_zip** を削除する。\n",
    "- Move column: **fraud** を移動する (**Move to start** を使用)。\n",
    "- Rename column: **collision_type_N/A** から **/** を削除と **driver_relationship_N/A**から **_** を削除する。\n",
    "\n",
    "- Rename column:  **policy_id_0**を**policy_id**に変更.\n",
    "\n",
    "**ヒント 1**: Data Wrangler の Join を使用して、保険金請求テーブルと顧客テーブルを結合します。\n",
    "\n",
    "**ヒント 2**: **policy_id** 列に基づいてテーブルを結合します。\n",
    "\n",
    "**ヒント 3**: [**Add transform**] オプションを使用して、変換を追加します。\n",
    "\n",
    "モデルトレーニングに最も影響を与えるのはどの変換だと思いますか。\n",
    "\n",
    "Data Wrangler を使用してデータを準備する方法については、「<a href=\"#task1-4-1\" target=\"_self\">**SageMaker Data Wrangler を使用してデータを準備する**</a>」を参照してください。\n",
    "\n",
    "既に処理済みのデータのサンプルセットをインポートしたい場合には、「<a href=\"#task1-4-2\" target=\"_self\">**処理済みのデータのサンプルセットをインポートする**</a>」を参照してください。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題 2: SageMaker Feature Store で特徴量グループを作成する\n",
    "\n",
    "データセットの処理が完了したので、今後の分析に再利用できるように特徴量と特徴量グループを作成します。SageMaker Feature Store を使用して、作成した特徴量を特徴量グループに保存し、モデルをトレーニングする際にこれらの特徴量をクエリします。\n",
    "\n",
    "このタスクを完了するために、以下のサブタスクを実行します。\n",
    "\n",
    "1. SageMaker Feature Store に特徴量をエクスポートする。\n",
    "2. Amazon Athena を使用してオフラインストアの特徴量グループをクエリする。\n",
    "\n",
    "この課題の所要時間は約 *30* 分です。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 2.1: SageMaker Feature Store に特徴量をエクスポートする\n",
    "\n",
    "<a id=\"task2-1-continue\"></a>\n",
    "\n",
    "SageMaker Data Wrangler の [**Export to**] 機能を使用して、カスタムの Jupyter Notebook を作成します。このノートブックでは、特徴量の定義と特徴量グループを作成し、レコードを特徴量グループに取り込みます。ノートブックで、以下の手順を実行します。\n",
    "\n",
    "- record 列と event_time 列に値を設定する。\n",
    "- ノートブックのセルを実行して、特徴量グループを作成する。\n",
    "- ノートブックのセルを実行して、作成した特徴量グループを確認する。\n",
    "- ノートブックのセルを実行して、特徴量グループにレコードを取り込む。\n",
    "\n",
    "**ヒント 1**: これらの手順はすべて SageMaker Studio で行うことができます。特徴量グループの作成が完了したら、このノートブックに戻り、タスク 2.2 に進むことができます。\n",
    "\n",
    "**ヒント 2**: カスタム変換を追加して、**event_time** 列を作成します。\n",
    "\n",
    "**ヒント 3**: カスタム変換を追加するためのコードは以下のとおりです。\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import lit\n",
    "date_time = datetime.date.today()\n",
    "\n",
    "df = df.withColumn(\"event_time\", lit(time.mktime(date_time.timetuple())))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**ヒント 4**: Data Wrangler フローの最後で [**+**] アイコンをクリックして [**Export to**] オプションをクリックし、[**SageMaker Feature Store (via JupyterNotebook)**] を選択します。\n",
    "\n",
    "**ヒント 5**: **enable_online_store** の値を **True** から **False** に変更することで、オンラインストアを無効にできます。\n",
    "\n",
    "SageMaker Feature Store を使用して、推論用ではなく、トレーニング用にレコードを保存し、クエリするにはどうすればよいでしょうか。\n",
    "\n",
    "[**Export to**] オプションを使用して特徴量グループを作成する方法については、「<a href=\"#task2-1\" target=\"_self\">**Export to オプションを使用して特徴量グループを作成する**</a>」を参照してください。\n",
    "\n",
    "特徴量グループを作成し、その特徴量グループにデータを取り込んだら、このタスクは完了です。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 2.2: Athena を使用してオフラインストアの特徴量グループをクエリする\n",
    "\n",
    "<a id=\"task2-2-continue\"></a>\n",
    "\n",
    "Athena を使用してオフラインストアからレコードを抽出します。次の課題では、抽出したレコードをトレーニング用、テスト用、検証用のデータセットに分割します。\n",
    "\n",
    "以下のコードセルを使用して Amazon Athena API 呼び出しを行います。Amazon Athena コンソールを使用してクエリを作成することもできますが、それはこのラボの範囲外です。\n",
    "\n",
    "**ヒント 1**: **feature_group.athena_query()** で Athena クエリを作成し、**query.table_name** でテーブル名を取得できます。\n",
    "\n",
    "**ヒント 2**: **query.run(query_string=query_string, output_location=output_location)** でクエリを実行し、**query.as_dataframe()** で戻り値を dataframe として読み取ることができます。\n",
    "\n",
    "データセットのタイムライン上の異なるポイントで発生する特徴を追跡するには、**event_time** をどのように使用できますか。\n",
    "\n",
    "Athena でオフラインストアからレコードを抽出する方法については、「<a href=\"#task2-2\" target=\"_self\">**Athena でオフラインストアからレコードを抽出する**</a>」を参照してください。\n",
    "\n",
    "返された Athena クエリを dataframe 変数として保存したら、このタスクは完了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ここにタスク 2.2 のコードを追加する\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題 3: モデルをトレーニングする\n",
    "\n",
    "これでモデルをトレーニングする準備が整いました。データをトレーニング用、テスト用、検証用のデータセットに分割し、モデルをトレーニングします。\n",
    "\n",
    "先ほどこのデータで SageMaker Autopilot を実行したところ、**F1** が **0.616**、**正解率**が **0.978**、**AUC** が **0.918**、**再現率**が **0.539** となりました。SageMaker Autopilot が生成するメトリクスについての詳細は、「[Metrics] (https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-metrics-validation.html)」 を参照してください。\n",
    "\n",
    "トレーニングやチューニングを行う際は、値が SageMaker Autopilot のスコアと同等か、それを上回るようにし、Amazon SageMaker Debugger がエラーを報告しないことを確認します。\n",
    "\n",
    "このタスクを完了するために、以下のサブタスクを実行します。\n",
    "\n",
    "- ExperimentとRunを作成する。\n",
    "- データをトレーニング用、テスト用、検証用のデータセットに分割する。\n",
    "- トレーニングジョブを設定して実行する。\n",
    "    - 基本的なトレーニングジョブを開始する。\n",
    "    - SageMaker Debugger を有効にしてトレーニングジョブを実行し、レポートを分析する (オプション)。\n",
    "- ハイパーパラメータのチューニングを実行する。\n",
    "\n",
    "この課題の所要時間は約 *110* 分です。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 3.1: ExperimentとRunを作成する\n",
    "\n",
    "<a id=\"task3-1-continue\"></a>\n",
    "\n",
    "ExperimentとRunの両方に名前を付ける変数を設定します。\n",
    "Experimentには **experiment_name**、**run_name** および **description** が必要です。\n",
    "\n",
    "変数を作成する方法の詳細な手順については、**付録**セクションの <a href=\"#task3-1\" target=\"_self\">**実験と実行に名前を付ける (タスク 3.1)**</a> を参照してください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここにタスク 3.1 のコードを追加する\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 3.2: データをトレーニング用、テスト用、検証用のデータセットに分割する\n",
    "\n",
    "<a id=\"task3-2-continue\"></a>\n",
    "\n",
    "SageMaker Feature Store からクエリした特徴量を使用して、データをトレーニング用、テスト用、検証用のデータセットに分割します。\n",
    "\n",
    "**ヒント 1**: **np.split** を使用して、データセットを 3 つのパーティションに分割します。\n",
    "\n",
    "**ヒント 2**: **to_csv** を使用して、CSV ファイルを作成し、**S3Uploader.upload** を使用して Amazon S3 に作成したファイルを追加します。\n",
    "\n",
    "**ヒント 3**: 分割の最終成果物は、**トレーニング**用と**検証**用の値を持つ **data_inputs** 変数となります。\n",
    "\n",
    "データをトレーニング用、テスト用、検証用のデータセットに分割する方法については、「<a href=\"#task3-2\" target=\"_self\">**データをトレーニング用、テスト用、検証用のデータセットに分割する**</a>」を参照してください。\n",
    "\n",
    "データをトレーニング用、テスト用、検証用のデータセットに分割したら、このタスクは完了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ここにタスク 3.2 のコードを追加する\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 3.3: トレーニングジョブを設定して実行する\n",
    "\n",
    "<a id=\"task3-3-continue\"></a>\n",
    "\n",
    "最初のトレーニングジョブを開始し、コンテナ、Estimator、ハイパーパラメータを設定します。そして、**fit()** でモデルをトレーニングします。より詳細なレポートを確認する場合は、**DebuggerHookConfig** で SageMaker Debugger を有効にしてください。\n",
    "\n",
    "**ヒント 1**: バージョン **1.5-1** の **XGBoost** コンテナを使用します。\n",
    "\n",
    "**ヒント 2**: 開始するには、**eta**、**gamma**、**max_depth**、**min_child_weight**、**num_round**、**objective**、**subsample** のハイパーパラメータを設定する必要があります。\n",
    "\n",
    "**ヒント 3**: 課題 1 で作成した **data_inputs** をトレーニングジョブの **inputs** 値として使用します。\n",
    "\n",
    "**ヒント 4**: inputs と experiment_config を設定することで、トレーニングジョブを構成できます。experiment_config には、**sagemaker_session**, **run_name**,**experiment_name**が含まれています。.\n",
    "\n",
    "**ヒント 5**: SageMaker Debugger を使用する場合は、**DebuggerHookConfig**、**ProfilerConfig**、Debugger **rule** オブジェクトを設定する必要があります。\n",
    "\n",
    "モデルのパフォーマンスと正解率に大きな影響を与えると思われるハイパーパラメータはどれですか。 どのハイパーパラメータを最初にチューニングする予定ですか。\n",
    "\n",
    "基本的なトレーニングジョブを設定し、実行する方法については、「<a href=\"#task3-3-1\" target=\"_self\">**基本的なトレーニングジョブを設定し、実行する**</a>」を参照してください。\n",
    "\n",
    "デバッガーを有効にしてトレーニングジョブを設定して実行し、レポートを分析する方法については、「<a href=\"#task3-3-2\" target=\"_self\">**SageMaker のデバッガーを有効にしてトレーニングジョブを設定して実行し、レポートを分析する**</a>」を参照してください。\n",
    "\n",
    "1 つ以上のトレーニングジョブを実行したら、このタスクは完了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここにタスク 3.3 のコードを追加する\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 3.4: ハイパーパラメータのチューニング\n",
    "\n",
    "<a id=\"task3-4-continue\"></a>\n",
    "\n",
    "トレーニングジョブを終了し、分析しました。その結果に基づいて、ハイパーパラメータの範囲をチューニングし、さらにトレーニングジョブを実行してモデルを改善します。\n",
    "\n",
    "**ヒント 1**: 開始するには、**alpha**、**eta**、**max_depth**、**min_child_weight**、**num_round** のハイパーパラメータの範囲を設定します。\n",
    "\n",
    "**ヒント 2**: **HyperparameterTuner** を実行する際には、分析結果に基づいて **objective_metric_name** と **objective_type** を必ず設定してください。\n",
    "\n",
    "**ヒント 3**: SageMaker Autopilot の結果よりも改善されたかどうかを確認するには、**SageMaker リソース** の [**Experiments and Runs**] メニューを開きます。Runで、**メトリクス**を確認します。**ObjectiveMetric** は **F1** スコアの **0.616** よりも高く、**validation:auc** の**最終的な値**は SageMaker Autopilot スコアの **0.918** よりも高くなっているべきです。\n",
    "\n",
    "ハイパーパラメータのチューニングを行ったとき、モデルのパフォーマンスを最も向上させたのはどれですか。\n",
    "\n",
    "トレーニングハイパーパラメータの範囲を設定する方法については、「<a href=\"#task3-4\" target=\"_self\">**トレーニングハイパーパラメータの範囲を設定する**</a>」を参照してください。\n",
    "\n",
    "トレーニングハイパーパラメータの範囲を設定し、さらにトレーニングジョブを開始したら、このタスクは完了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここにタスク 3.4 のコードを追加する\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題 4: モデルのバイアスを評価する\n",
    "\n",
    "モデルの学習が完了したので、Amazon SageMaker Clarify を使用してモデルを評価します。問題が見つかった場合は、検出された不均衡を解消して、モデルを再トレーニングします。\n",
    "\n",
    "このタスクを完了するために、以下のサブタスクを実行します。\n",
    "\n",
    "- トレーニングジョブからモデルを作成する。\n",
    "- Clarify のモデルの設定を作成する。\n",
    "- Clarify のバイアスの設定を作成する。\n",
    "- Clarify のプロセッサジョブを使用して、バイアス、データ、モデルの各レポートを実行する。\n",
    "- SageMaker Clarify で検出された不均衡を解消する (オプション)。\n",
    "- モデルを再トレーニングする (オプション)。\n",
    "\n",
    "この課題の所要時間は約 *80* 分です。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 4.1: トレーニングジョブからモデルを作成する\n",
    "\n",
    "<a id=\"task4-1-continue\"></a>\n",
    "\n",
    "定義した **model_name**、**role**、**container_def** を使って **create_model** を呼び出し、XGBoost モデルを作成します。\n",
    "\n",
    "**ヒント 1**: **xgb.create_model()** を呼び出し、モデルの名前を決めます。\n",
    "\n",
    "**ヒント 2**: セッションを使用し、**model_name**、**role**、**container_def** を渡して **create_model** を呼び出します。\n",
    "\n",
    "モデルを作成する方法については、「<a href=\"#task4-1\" target=\"_self\">**モデルを作成する**</a>」を参照してください。\n",
    "\n",
    "モデルを作成したら、このタスクは完了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここにタスク 4.1 のコードを追加する\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 4.2: Clarify のモデルの設定を作成する\n",
    "\n",
    "<a id=\"task4-2-continue\"></a>\n",
    "\n",
    "**SageMakerClarifyProcessor** を使用して、Clarify のモデルの設定を作成します。\n",
    "\n",
    "**ヒント 1**: **instance_count** と **instance_type** を設定します。\n",
    "\n",
    "**ヒント 2**: キャップストーンのラボの冒頭で作成した**ロール**と**セッション**を使用します。\n",
    "\n",
    "Clarify のモデルの設定を作成する方法については、「<a href=\"#task4-2\" target=\"_self\">**Clarify のモデルの設定を作成する**</a>」を参照してください。\n",
    "\n",
    "Clarify のモデルの設定を作成したら、このタスクは完了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここにタスク 4.2 のコードを追加する\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 4.3: Clarify のバイアスの設定を作成する\n",
    "\n",
    "<a id=\"task4-3-continue\"></a>\n",
    "\n",
    "データの設定、モデルの設定、ラベルの設定、バイアスの設定を作成します。\n",
    "\n",
    "**ヒント 1**: まず、**DataConfig** を作成し、入力パス、出力パス、ヘッダー、データセットタイプを設定します。\n",
    "\n",
    "**ヒント 2**: 次に、**ModelConfig** を作成し、コンテンツと許可タイプ、モデル名、インスタンスタイプ、インスタンス数を選択します。\n",
    "\n",
    "**ヒント 3**: 次に、**ModelPredictedLabelConfig** を作成し、確率のしきい値を設定します。\n",
    "\n",
    "**ヒント 4**: 最後に **BiasConfig** を作成し、ラベルの値またはしきい値、ファセット名、ファセットの値またはしきい値を設定します。\n",
    "\n",
    "バイアスレポートでは、どのファセットを最初に調査しますか。 バイアスの影響を特に受けやすい特徴はありますか。\n",
    "\n",
    "Clarify のバイアスの設定を作成する方法については、「<a href=\"#task4-3\" target=\"_self\">**Clarify のバイアスの設定を作成する**</a>」を参照してください。\n",
    "\n",
    "Clarify のバイアスの設定を作成したら、このタスクは完了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここにタスク 4.3 のコードを追加する\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 4.4: Clarify のプロセッサジョブを使用してバイアス、データ、モデルのレポートを実行する\n",
    "\n",
    "<a id=\"task4-4-continue\"></a>\n",
    "\n",
    "バイアス、データ、モデルの各レポートについて、既にすべての設定を選択しました。では、レポートを実行してみましょう。\n",
    "\n",
    "**ヒント 1**: **data_config**、**bias_config**、**model_predicted_label_config**、**model_config** を **run_bias** に渡します。\n",
    "\n",
    "**ヒント 2**: **pre_training_methods** と **post_training_methods** も設定する必要があります。\n",
    "\n",
    "SageMaker Clarify を使ってバイアス、データ、モデルのレポートを実行する方法については、「<a href=\"#task4-4\" target=\"_self\">**SageMaker Clarify を使ってバイアス、データ、モデルのレポートを実行する**</a>」を参照してください。\n",
    "\n",
    "Clarify プロセッサジョブを使用してバイアス、データ、モデルの各レポートを実行したら、このタスクは完了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここにタスク 4.4 のコードを追加する\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 4.5: SageMaker Clarify で検出した不均衡を解消する (オプション)\n",
    "\n",
    "<a id=\"task4-5-continue\"></a>\n",
    "\n",
    "SageMaker Clarify で検出された不均衡を解消する方法はいくつもあります。使い慣れた方法を使用してください。このラボでは、列の 1 つからバイアスを解消する SMOTE (Synthetic Minority Over-sampling Technique) の例を紹介します。\n",
    "\n",
    "**ヒント 1**: 不均衡を解消し、再テストを行う場合は、新しくリサンプリングされたデータフレームを作成します。次のタスクでは、新しい CSV ファイルを作成し、アップロードします。\n",
    "\n",
    "不均衡を解消する方法については、「<a href=\"#task4-5\" target=\"_self\">**不均衡を削除する**</a>」を参照してください。\n",
    "\n",
    "SageMaker Clarify で検出された不均衡を解消したら、このタスクは完了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここにタスク 4.5 のコードを追加する\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 4.6: モデルを再トレーニングする (オプション)\n",
    "\n",
    "<a id=\"task4-6-continue\"></a>\n",
    "\n",
    "新しいファイルを Amazon S3 にアップロードします。そして、新しいEstimatorを作成し、新しいデータで再トレーニングします。\n",
    "\n",
    "**ヒント 1**: **s3_client.upload_file** を使用し、新しいファイルをバケットにアップロードします。\n",
    "\n",
    "**ヒント 2**: **xgboost_starter_script.py** を使用し、**XGBoost** を呼び出します。そして、新しいデータで再トレーニングします。\n",
    "\n",
    "再トレーニングしたモデルは、より高い F1 スコアになりましたか。 SageMaker Debugger を使用した場合、発見された問題をすべて解決できましたか。\n",
    "\n",
    "モデルを再トレーニングする方法については、「<a href=\"#task4-6\" target=\"_self\">**モデルを再トレーニングする**</a>」を参照してください。\n",
    "\n",
    "モデルを再トレーニングしたら、このタスクは完了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここにタスク 4.6 のコードを追加する\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題 5: バッチ変換\n",
    "\n",
    "モデルをデプロイする準備ができました。バッチレコードでバッチ変換ジョブを使用して、Amazon S3 に保存されている予測データと正解率データを確認します。そして、SageMaker インスタンスのいくつかをクリーンアップします。\n",
    "\n",
    "このタスクを完了するために、以下のサブタスクを実行します。\n",
    "\n",
    "- モデルのバッチ変換ジョブを作成する。\n",
    "- Amazon S3 に保存されている予測データを確認する。\n",
    "- SageMaker インスタンスをクリーンアップする (オプション)\n",
    "\n",
    "この課題の所要時間は約 *40* 分です。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 5.1: モデルのバッチ変換ジョブを作成する\n",
    "\n",
    "<a id=\"task5-1-continue\"></a>\n",
    "\n",
    "モデルEstimatorの**Transformer**を使用し、バッチ変換ジョブを作成します。そして、そのバッチジョブを実行します。\n",
    "\n",
    "**ヒント 1**: Transformerを使用して、**instance_count**、**instance_type**、**strategy**、**assemble_with**、**output_path** を設定します。\n",
    "\n",
    "**ヒント 2**: **test_path** に記載されているテストデータをエンドポイントに送信し、結果を待ちます。\n",
    "\n",
    "バッチ変換ジョブを作成する方法については、「<a href=\"#task5-1\" target=\"_self\">**バッチ変換ジョブを作成する**</a>」を参照してください。\n",
    "\n",
    "バッチ変換ジョブを作成し、レコードのセットで実行したら、このタスクは完了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここにタスク 5.1 のコードを追加する\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 5.2: Amazon S3 に保存されている予測データを確認する\n",
    "\n",
    "<a id=\"task5-2-continue\"></a>\n",
    "\n",
    "バッチ変換ジョブが完了したら、Amazon S3 からデータを読み込みます。\n",
    "\n",
    "**ヒント 1**: **%aws s3 cp --recursive $transformer.output_path ./** を使用して、Transformerの出力からデータをコピーできます。\n",
    "\n",
    "**ヒント 2**: データを取得したら、**%head test_data_batch.csv.out** で確認できます。\n",
    "\n",
    "予測値を見てみましょう。意外な予測値はありますか。\n",
    "\n",
    "バッチ変換ジョブの予測データを確認する方法については、「<a href=\"#task5-2\" target=\"_self\">**バッチ変換ジョブの予測データと正解率データを確認する**</a>」を参照してください。\n",
    "\n",
    "バッチ変換ジョブの予測データを確認したら、このタスクは完了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここにタスク 5.2 のコードを追加する\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 5.3: SageMaker インスタンスをクリーンアップする (オプション)\n",
    "\n",
    "コストを低く抑えるためのベストプラクティスは、使わなくなったインスタンスを削除することです。SageMaker Studio を使用すると、インスタンスをすばやく削除できます。少し時間を取って SageMaker Studio で現在のリソースリストを開き、残っているインスタンスを削除してください。\n",
    "\n",
    "次のパイプラインタスクを完了する予定がある場合は、**ノートブックインスタンスを実行したままにしておきます**。\n",
    "\n",
    "**ヒント 1**: SageMaker Studio の **Running Terminals and Kernels** アイコンをクリックすると、実行中のインスタンスのリストを表示できます。\n",
    "\n",
    "**ヒント 2**: **Shut down** アイコンをクリックするとインスタンスを停止できます。\n",
    "\n",
    "<a id=\"task5-3-continue\"></a>\n",
    "\n",
    "SageMaker Studio で SageMaker インスタンスをクリーンアップする方法については、「<a href=\"#task5-3\" target=\"_self\">**SageMaker Studio で SageMaker インスタンスをクリーンアップする**</a>」を参照してください。\n",
    "\n",
    "SageMaker Studio ですべての SageMaker インスタンスを停止したら、このタスクは完了です。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題 6: 自動化されたパイプラインを構築する (オプション)\n",
    "\n",
    "Amazon SageMaker SDK と Amazon SageMaker Studio を使用して機械学習 (ML) ワークフローを構築しました。次に、SageMaker Pipelines を使用してワークフローをスケールします。この課題では、ラボ環境のために用意されたパイプラインスクリプトを見ていきます。\n",
    "\n",
    "- パイプラインステップを作成する。\n",
    "    - SageMaker Feature Store から処理済みデータをクエリする。\n",
    "    - モデルをトレーニングし、チューニングする。\n",
    "    - トレーニングしたモデルを評価する。\n",
    "    - バッチ変換ジョブを実行する。\n",
    "    - モデルを登録する。\n",
    "    - SageMaker Clarify でモデルトレーニングを評価する。\n",
    "- パイプラインを定義し、開始する。\n",
    "- 機械学習の系統追跡を表示する。\n",
    "\n",
    "この課題の所要時間は約 *120* 分です。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 6.1: パイプラインを設定する\n",
    "\n",
    "<a id=\"task6-1-continue\"></a>\n",
    "\n",
    "パイプラインのテンプレートを使用し、入力と出力を設定します。設定が完了したら、パイプラインを実行します。パイプラインには、さまざまなステップを含めることができます。以下は、設定に使用されるステップの推奨リストです。\n",
    "- **AutoModelProcess**: .csv ファイルを取り込み、トレーニング用、テスト用、検証用のデータセットに分割する **Processing** ステップ。\n",
    "- **AutoHyperParameterTuning**: ハイパーパラメータの範囲を指定し、モデルをチューニングする **Tuning** ステップ。\n",
    "- **AutoEvalBestModel**: 最適なモデルを示す評価レポートを作成する **Processing** ステップ。\n",
    "- **CheckAUCScoreAutoEvaluation**: 評価メトリクスに基づきモデルを評価する **Condition** ステップ。\n",
    "- **AutoCreateModel**: モデルを作成する **Model** ステップ。\n",
    "- **RegisterAutoModel-RegisterModel**: モデルを登録する **RegisterModel** ステップ。\n",
    "- **AutoModelConfigFile**: バイアスレポートを作成する **Processing** ステップ。\n",
    "- **AutoTransform**: バッチ変換ジョブを実行する **Transform** ステップ。\n",
    "- **ClarifyProcessingStep**: SageMaker Clarify のジョブを実行する **Processing** ステップ。\n",
    "\n",
    "**ヒント 1**: 多くのパイプラインステップから選択できます。パイプラインステップの詳細と各ステップのサンプルコードについては、「[Pipeline Steps](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing)」を参照してください。\n",
    "\n",
    "**ヒント 2**: まず、データを取り込むために **Processing** ステップから始めます。次に、**Tuning** ステップを作成し、モデルをチューニングします。そして、**Model** ステップを作成し、モデルを作成します。\n",
    "\n",
    "**ヒント 3**: このチュートリアルには、評価レポートの作成、バイアスレポートの作成、バッチ変換ジョブの実行、SageMaker Clarify ジョブの実行の手順を含むサンプルソリューションが含まれています。\n",
    "\n",
    "パイプラインを設定する方法については、「<a href=\"#task6-1\" target=\"_self\">**パイプラインを設定する**</a>」を参照してください。\n",
    "\n",
    "パイプラインを設定し、パイプラインジョブを開始したら、このタスクは完了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここにタスク 6.1 のコードを追加する\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスク 6.2: パイプラインをモニタリングする\n",
    "\n",
    "<a id=\"task6-2-continue\"></a>\n",
    "\n",
    "パイプラインの実行中に、入力と出力を表示し、パイプラインをモニタリングします。\n",
    "\n",
    "**ヒント 1**: `RunPipeline.describe()` を使用して、作成したパイプラインを指定します。\n",
    "\n",
    "**ヒント 2**: SageMaker Studio UI で実行中のパイプラインステップを表示できます。[**Home**] メニューを開いて [**Pipelines**] をクリックし、作成したパイプラインを選択します。\n",
    "\n",
    "パイプラインをモニタリングする方法については、「<a href=\"#task6-2\" target=\"_self\">**パイプラインをモニタリングする**</a>」を参照してください。\n",
    "\n",
    "パイプラインのモニタリングが終了したら、このタスクは完了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここにタスク 6.2 のコードを追加する\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "お疲れ様でした。 自動車保険のデータセットを使用して、不正の可能性がある請求を検出しました。SageMaker Studio と SageMaker Python SDK を使用して、既存の自動車保険請求の中で不正の可能性があるものを予測するテクニカルソリューションを検討しました。\n",
    "\n",
    "### クリーンアップ\n",
    "\n",
    "このノートブックを完了しました。ラボの次の部分に進むために、以下を実行してください。\n",
    "\n",
    "- このノートブックファイルを閉じる。\n",
    "- ラボのセッションに戻り、「まとめ」を確認する。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## その他のリソース\n",
    "\n",
    "- [Autopilot metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-metrics-validation.html)\n",
    "- [Processing step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 付録"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-1\" id=\"task1-1\"></a>\n",
    "\n",
    "### 付録: データを表示する (タスク 1.1)\n",
    "\n",
    "データを表示するには、Pandas を使用してパスを指定し、データを読み込みます。少し時間を取って両方のテーブルのサンプルを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV ファイルを読み込む\n",
    "claims_data = pd.read_csv(\"./data/claims_preprocessed.csv\", index_col=0)\n",
    "customers_data = pd.read_csv(\"./data/customers_preprocessed.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保険金請求データサンプル\n",
    "claims_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顧客データサンプル\n",
    "customers_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#task1-1-continue\" target=\"_self\">タスク 1.1</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-2-1\" id=\"task1-2-1\"></a>\n",
    "\n",
    "### 付録: データセットを SageMaker Studio で確認する (タスク 1.2)\n",
    "\n",
    "SageMaker Data Wrangler でデータ調査を開始します。S3 バケットからファイルをインポートし、データを分析します。\n",
    "\n",
    "次のステップでは、SageMaker Studio の新しいタブが表示されます。以下のオプションの 1 つを実行して、手順を進めます。\n",
    "- **オプション 1:** タブを並べて表示する。SageMaker Studio のメインウィンドウから分割画面ビューを作成するには、**capstone_ja_jp.ipynb** タブを横にドラッグするか、**capstone_ja_jp.ipynb** タブを選択し、ツールバーから **File** と **New View for Notebook** を選択します。これで、特徴量グループを探索する際に手順書を表示されながら実行することができます。\n",
    "- **オプション 2:** SageMaker Studio のタブを切り替えながら、手順を進めます。\n",
    "\n",
    "1. 左側にある [**SageMaker Home**] アイコンをクリックします。\n",
    "1. [**Data**]タブをクリックし、 [**Data Wrangler**] をクリックします。\n",
    "\n",
    "SageMaker Studio で [**Data Wrangler**] タブが表示されます。\n",
    "\n",
    "1. **+** **Create Data Wrangler flow**を選択します。\n",
    "\n",
    "SageMaker Studio で [**untitled.flow**] タブが表示されます。\n",
    "\n",
    "1. **SageMaker Studio** で **untitled.flow** ファイルのタブが自動的に開くまで待ちます。これには **2～3** 分かかることがあります。\n",
    "\n",
    "SageMaker Studio で **Create connection** ページが [**Data Wrangler**] タブに表示されます。\n",
    "\n",
    "1. **untitled.flow** ファイルタブのコンテキストメニュー (右クリック) を開き、ファイル名を変更するには、**Rename Data Wrangler Flow...** を選択します。\n",
    "\n",
    "SageMaker Studio で [**Rename File**] メッセージウィンドウが表示されます。\n",
    "\n",
    "1. **New Name** で `CapstoneDataWrangler.flow` と入力します。\n",
    "1. <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">Rename</span> を選択します。\n",
    "\n",
    "**Rename File** メッセージウィンドウが閉じられます。\n",
    "\n",
    "1. [**CapstoneDataWrangler.flow**] タブの [**Available**] セクションで [**Amazon S3**] を選択します。\n",
    "\n",
    "SageMaker Studio で [**CapstoneDataWrangler.flow**] タブで [**Import a dataset from S3**] ページが表示されます。\n",
    "\n",
    "1. バケットリストで、**databucket** の名前が含まれているバケットを選択します。\n",
    "1. ファイル名が **claims.csv** の 1 つ目のデータセットを選択します。\n",
    "\n",
    "1. <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">Import</span> を選択します。\n",
    "\n",
    "1. **Data flow** ビューに戻り、[**CapstoneDataWrangler.flow**] タブの左上にある [**< Data flow**] を選択します。\n",
    "\n",
    "1. [**CapstoneDataWrangler.flow**] タブの左上にある [**Import**] タブを選択します。\n",
    "\n",
    "SageMaker Studio で [**Create connection**] ページが表示されます。\n",
    "\n",
    "1. [**CapstoneDataWrangler.flow**] タブの [**Available**] セクションで [**Amazon S3**] を選択します。\n",
    "\n",
    "SageMaker Studio で [**CapstoneDataWrangler.flow**] タブで [**Import a dataset from S3**] ページが表示されます。\n",
    "\n",
    "1. バケットリストで、**databucket** の名前が含まれているバケットを選択します。\n",
    "1. ファイル名が **customers.csv** の 2 つ目のデータセットを選択します。\n",
    "1. <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">Import</span> を選択します。\n",
    "\n",
    "1. **Data flow** ビューに戻り、[**CapstoneDataWrangler.flow**] タブの左上にある [**< Data flow**] を選択します。\n",
    "\n",
    "1. [Data flow] ビューで、上側の [**Data types**] アイコンの横にある [**+**] 記号をクリックして、[**Get data insights**] をクリックします。\n",
    "\n",
    "1. レポートを作成し、インサイトを確認します。\n",
    "\n",
    "1. [**Data flow**] ビューに戻り、先ほど選択していなかったファイルの[**Data types**] アイコンの横にある [**+**] 記号をクリックして、[**Add analysis**] をクリックします。\n",
    "\n",
    "1. 分析を作成し、結果を確認します。\n",
    "\n",
    "さまざまなレポートタイプを十分に活用してデータセットを調査します。調査が終わったら次のタスクに進むことができます。\n",
    "\n",
    "<a href=\"#task1-2-continue\" target=\"_self\">タスク 1.2</a> に戻って、このラボを続けます。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-2-2\" id=\"task1-2-2\"></a>\n",
    "\n",
    "### 付録: データセットをノートブックで確認する (タスク 1.2)\n",
    "\n",
    "データセットを調査する方法はいくつもあります。ここでは、データ調査のステップの例をいくつか示します。これらを参考にして、さまざまな視点からデータセットを調査しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 性別グラフ\n",
    "import matplotlib.pyplot as plt\n",
    "customers_data.customer_gender_female.value_counts(normalize=True).plot.bar()\n",
    "plt.xticks([0, 1], [\"Male\", \"Female\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不正被害グラフ\n",
    "claims_data.fraud.value_counts(normalize=True).plot.bar()\n",
    "plt.xticks([0, 1], [\"Not Fraud\", \"Fraud\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 教育カテゴリグラフ\n",
    "educ = customers_data.customer_education.value_counts(normalize=True, sort=False)\n",
    "plt.bar(educ.index, educ.values)\n",
    "plt.xlabel(\"Customer Education Level\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保険請求額グラフ\n",
    "plt.hist(claims_data.total_claim_amount, bins=30)\n",
    "plt.xlabel(\"Total Claim Amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 請求件数グラフ\n",
    "customers_data.num_claims_past_year.hist(density=True)\n",
    "plt.suptitle(\"Number of Claims in the Past Year\")\n",
    "plt.xlabel(\"Number of claims per year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 支払いプロットグラフ\n",
    "sns.pairplot(\n",
    "    data=customers_data, vars=[\"num_insurers_past_5_years\", \"months_as_customer\", \"customer_age\"]\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保険会社別不正被害グラフ\n",
    "combined_data = customers_data.join(claims_data)\n",
    "sns.lineplot(x=\"num_insurers_past_5_years\", y=\"fraud\", data=combined_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 月別の顧客グラフ\n",
    "sns.boxplot(x=customers_data[\"months_as_customer\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顧客の年齢グラフ\n",
    "sns.boxplot(x=customers_data[\"customer_age\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 性別の不正被害グラフ\n",
    "combined_data.groupby(\"customer_gender_female\").mean()[\"fraud\"].plot.bar()\n",
    "plt.xticks([0, 1], [\"Male\", \"Female\"])\n",
    "plt.suptitle(\"Fraud by Gender\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相関行列グラフ\n",
    "cols = [\n",
    "    \"fraud\",\n",
    "    \"customer_gender_male\",\n",
    "    \"customer_gender_female\",\n",
    "    \"months_as_customer\",\n",
    "    \"num_insurers_past_5_years\",\n",
    "]\n",
    "corr = combined_data[cols].corr()\n",
    "\n",
    "# 相関行列をプロットする\n",
    "sns.heatmap(corr, annot=True, cmap=\"Reds\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結合データを読み込む\n",
    "combined_data = pd.read_csv(\"./data/claims_customer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不要な列を削除する\n",
    "combined_data = combined_data.loc[:, ~combined_data.columns.str.contains(\"^Unnamed: 0\")]\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結合データの統計情報の抽出\n",
    "combined_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 統計情報を生成する\n",
    "combined_stats = []\n",
    "\n",
    "for col in combined_data.columns:\n",
    "    combined_stats.append(\n",
    "        (\n",
    "            col,\n",
    "            combined_data[col].nunique(),\n",
    "            combined_data[col].isnull().sum() * 100 / combined_data.shape[0],\n",
    "            combined_data[col].value_counts(normalize=True, dropna=False).values[0] * 100,\n",
    "            combined_data[col].dtype,\n",
    "        )\n",
    "    )\n",
    "\n",
    "stats_df = pd.DataFrame(\n",
    "    combined_stats,\n",
    "    columns=[\"feature\", \"unique_values\", \"percent_missing\", \"percent_largest_category\", \"datatype\"],\n",
    ")\n",
    "stats_df.sort_values(\"percent_largest_category\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ヒートマップグラフ\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "corr_list = [\n",
    "    \"customer_age\",\n",
    "    \"months_as_customer\",\n",
    "    \"total_claim_amount\",\n",
    "    \"injury_claim\",\n",
    "    \"vehicle_claim\",\n",
    "    \"incident_severity\",\n",
    "    \"fraud\",\n",
    "]\n",
    "\n",
    "corr_df = combined_data[corr_list]\n",
    "corr = round(corr_df.corr(), 2)\n",
    "\n",
    "fix, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "mask = np.zeros_like(corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "ax = sns.heatmap(corr, mask=mask, ax=ax, annot=True, cmap=\"OrRd\")\n",
    "\n",
    "ax.set_xticklabels(ax.xaxis.get_ticklabels(), fontsize=10, ha=\"right\", rotation=45)\n",
    "ax.set_yticklabels(ax.yaxis.get_ticklabels(), fontsize=10, va=\"center\", rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#task1-2-continue\" target=\"_self\">タスク 1.2</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-3-1\" id=\"task1-3-1\"></a>\n",
    "\n",
    "### 付録: SageMaker Studioにおけるテーブルの結合 (Task 1.3)\n",
    "\n",
    "1. **CapstoneDataWrangler.flow**タブの左上にある **< Data flow** を選択し、**Data flow**に戻る。\n",
    "1. **claims.CSV Data types**アイコンの隣にある **+** サインを選び、コンテキストメニューから**Join**を選ぶ。\n",
    "\n",
    "SageMaker Data Wranglerの**Join**が表示されます。\n",
    "\n",
    "1. **customers.csv** の **Data types** アイコンを選択する\n",
    "\n",
    "1. <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">Configure</span>を選ぶ。\n",
    "\n",
    "1. **Join Type**に**Inner**を選ぶ。\n",
    "\n",
    "1. **Columns** セクション:\n",
    "  - **Left**にて, <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">policy_id</span>を選択する.\n",
    "\n",
    "  - **Right**にて, <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">policy_id</span>を選択する.\n",
    "\n",
    "1.　<span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">Preview</span>を選択する。\n",
    "\n",
    "1. <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">Add</span>を選択する.\n",
    "\n",
    "<a href=\"#task1-3-continue\" target=\"_self\">タスク 1.3</a>に戻って、このラボを続けます。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-3-2\" id=\"task1-3-2\"></a>\n",
    "\n",
    "### 付録: トレーニング前のバイアスレポートを実行する (タスク 1.3)\n",
    "\n",
    "SageMaker Data Wrangler のフローを使用して、SageMaker Clarify のバイアスレポートを作成します。\n",
    "\n",
    "1. **CapstoneDataWrangler.flow** タブを選択します。\n",
    "1. **Data flow**ビューに移動します. もし必要であれば、**CapstoneDataWranglerLab.flow** タブの左上にある　**< Data flow** をクリックしてください。 \n",
    "1. **Join**アイコンの横にある **+** サインを選びコンテキストメニューから**Add analysis**を選択する。\n",
    "\n",
    "1. **Create analysis** セクションにて以下の設定をする:\n",
    "- **Analysis type**にて, **Bias Report**を選択する。\n",
    "- **Analysis name**にて、`fraud bias by age`と設定する。\n",
    "- ターゲット列(Select the column your model predicsts(target))を選択します。このラボでは、ターゲット列は **fraud** です。\n",
    "- **Is your predicted column a value or threshold?** にて, **value** オプションを選択する。\n",
    "- 予測値(predicted value(s))を選択します。このラボでは、**fraud** の値に \"**1**\" を使用します。\n",
    "- **Select the column to analyze for bias**にて, **customer_age**を選択します。\n",
    "\n",
    "1. <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">Run</span>を選択します.\n",
    "\n",
    "ジョブが終了したら、返されたメトリクスを表示します。バイアスがある場合はメモを取り、分析した列に対して適用する処理ステップを考えます。\n",
    "\n",
    "バイアスを分析するすべての列に対して、この手順を繰り返します。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#task1-3-continue\" target=\"_self\">タスク 1.3</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-4-1\" id=\"task1-4-1\"></a>\n",
    "\n",
    "### 付録: SageMaker Data Wrangler を使用してデータを準備する (タスク 1.4)\n",
    "\n",
    "データセットを結合するには、SageMaker Data Wrangler で **policy_id** を使用して結合します。\n",
    "\n",
    "SageMaker Data Wranglerを使用して、フローの中の自由な箇所でデータを結合することができます。データを結合する前にそれぞれのデータをファイルごとに個別に準備することもできますし、結合してから特徴量を変換できます。SageMaker Data Wranglerのフローは柔軟に変更することができます。\n",
    "\n",
    "もしtask 1.3にてテーブルを結合していなければ、以下のステップに従って処理を実行してください。\n",
    "\n",
    "1. **Data flow**ビューに移動します。**CapstoneDataWranglerLab.flow** タブの左上にある　**< Data flow** をクリックしてください。\n",
    "\n",
    "1. **claims.CSV Data types** アイコンの隣にある + サインを選び、コンテキストメニューから **Join** を選択する。\n",
    "\n",
    "SageMaker Data Wranglerの **Join** ページが表示されます。\n",
    "\n",
    "1. **customers.csv** の **Data types** アイコンを選択する。\n",
    "1. <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">Configure</span>を選択する。\n",
    "1. **Join Type**にて, **Inner**を選択する。\n",
    "1. **Columns** セクション:\n",
    "\n",
    "    - **Left**にて, <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">policy_id</span>を選択する。\n",
    "    \n",
    "    - **Right**にて, <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">policy_id</span>を選択する。\n",
    "\n",
    "1. <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">Preview</span>を選択する.\n",
    "\n",
    "1. <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">Add</span>を選択する.\n",
    "\n",
    "データのテーブルを結合することで、結合したデータを変換する。\n",
    "\n",
    "1. **Data flow**ビューに移動します。**CapstoneDataWranglerLab.flow** タブの左上にある　**< Data flow** をクリックしてください。\n",
    "\n",
    "1. **Join**　アイコンの横の **+**　サインを選択します。, コンテキストメニューから **Add transform**を選択します。\n",
    "\n",
    "このメニューを使って、さらに変換を追加します。[Transformation] メニューの左側には、データセットのプレビューが表示されます。\n",
    "\n",
    "SageMaker Data Wrangler フローに以下の変換ステップを加えます:\n",
    "- Encode categorical (one-hot エンコーディング): **authorities_contacted**、**collision_type**、**customer_gender**、**driver_relationship**、**incident_type**、**policy_state** を、**Columns** という出力スタイルで、**Skip** 戦略を使用してエンコードする。\n",
    "- Encode categorical (Ordinal encode): **Skip** 戦略を使用して、**customer_education**、**incident_severity**、**police_report_available**、**policy_liability** をエンコードする。\n",
    "- Parse column as type: **vehicle_claim** と **total_claim_amount** を **Float** から **Long** に変換する。\n",
    "- Manage columns(Drop column): **customer_zip** と **policy_id_1** を削除する。\n",
    "- Manage columns(Move column): **fraud** を移動する (**Move to start** を使用)。\n",
    "- Manage columns(Rename column): **collision_type_N/A** と **driver_relationship_N/A** の **/** 記号を **_** 記号に変更する。\n",
    "- Manage columns(Rename column): **policy_id_0** を **policy_id** に変更する。\n",
    "\n",
    "列名に **/** が含まれる場合は、**/** を **_** に置き換えて列名を変更する必要があります。例えば、one-hot エンコーディングで作成された列で、値が **N/A** となっている列は、列名を変更する必要があります。SageMaker Feature Store では、列名に **/** の文字が含まれる列は受け付けられません。\n",
    "\n",
    "データの変換が完了し、モデルトレーニングを開始する準備ができたら、次のタスクに進むことができます。トレーニングやチューニングの間に問題を発見した場合は、いつでもこのフローに戻って変更できます。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#task1-4-continue\" target=\"_self\">タスク 1.4</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-4-2\" id=\"task1-4-2\"></a>\n",
    "\n",
    "### 付録: 処理済みのデータのサンプルセットをインポートする (タスク 1.4)\n",
    "\n",
    "前処理がうまくいかない場合や、処理済みのデータセットを読み込む場合は、S3 バケットの data フォルダに保存されている処理済みデータにアクセスできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　処理済みデータのインポート\n",
    "s3_client.upload_file(Filename=\"data/claims_customer.csv\", Bucket=bucket, Key=f\"{prefix}/data/raw/claims_customer.csv\")\n",
    "df_processed = pd.read_csv(\"./data/claims_customer.csv\", index_col=None)\n",
    "df_processed.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#task1-4-continue\" target=\"_self\">タスク 1.4</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task2-1\" id=\"task2-1\"></a>\n",
    "\n",
    "### 付録: Export to オプションを使用して特徴量グループを作成する (タスク 2.1)\n",
    "\n",
    "SageMaker Data Wrangler では、SageMaker Feature Store にデータをエクスポートできます。また、特徴量グループを設定し、その特徴量グループに変換されたデータを取り込むのに必要なすべてのコードを含むノートブックを作成できます。\n",
    "\n",
    "1. [**Add step**] をクリックします。\n",
    "\n",
    "1. [**Custom transform**] をクリックします。\n",
    "\n",
    "1. [**Name**] に `event_time` と入力します。\n",
    "\n",
    "1. **Python (PySpark)** を選択します (まだ選択されていない場合)。\n",
    "\n",
    "1. **Your custom transform** で、以下のように入力します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "from pyspark.sql.functions import lit\n",
    "date_time = datetime.date.today()\n",
    "\n",
    "df = df.withColumn(\"event_time\", lit(time.mktime(date_time.timetuple())))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">Preview</span>を選択します。\n",
    "\n",
    "1. <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">Add</span>を選択します。\n",
    "\n",
    "これで、**event_time** がデータセットに列として追加されます。SageMaker Feature Store では、**event_time** と一意の **record** id が必要です。**record** id には、**policy_id** を使用します。\n",
    "\n",
    "1. データフローに戻るには、[**< Data flow**] アイコンをクリックします。\n",
    "\n",
    "1. SageMaker Data Wrangler で、一連の変換の横(event_time)にある [**+**] アイコンをクリックします。\n",
    "\n",
    "1. [**Export to**] をクリックします。\n",
    "\n",
    "1. [**SageMaker Feature Store (via Jupyter Notebook)**] を選択します。\n",
    "\n",
    "新しいノートブックが開きます。\n",
    "\n",
    "1. 最初のセルで、以下の変数を変更します:\n",
    "- **record_identifier_feature_name** の **None** を \"**policy_id**\" に置き換えます。customer テーブルと claim テーブルを結合し、2 番目の policy_id 列を削除しなかった場合、**None** を \"**policy_id_0**\" に置き換える必要がある場合があります。**if** ステートメントにある **None** 値は変更しないでください。\n",
    "- **event_time_feature_name** の **None** を \"**event_time**\" に置き換えます。**if** ステートメントにある **None** 値は変更しないでください。\n",
    "\n",
    "セルの編集が完了すると、以下のようになります。:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_identifier_feature_name = \"policy_id\"\n",
    "if record_identifier_feature_name is None:\n",
    "   raise SystemExit(\"Select a column name as the feature group record identifier.\")\n",
    "\n",
    "event_time_feature_name = \"event_time\"\n",
    "if event_time_feature_name is None:\n",
    "   raise SystemExit(\"Select a column name as the event time feature name.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. すべてのセルを実行して、特徴量の定義と特徴量グループを作成し、処理ジョブを使用して変換されたデータを特徴量グループに取り込みます。 \n",
    "\n",
    "セルの編集が完了したら、Feature Store を使用する準備が整います。\n",
    "\n",
    "<a href=\"#task2-1-continue\" target=\"_self\">タスク 2.1</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task2-2\" id=\"task2-2\"></a>\n",
    "\n",
    "### 付録: Athena でオフラインストアからレコードを抽出する (タスク 2.2)\n",
    "\n",
    "**athena_query** で Athena クエリを設定します。次に、**query_string** を設定します。そして、そのクエリを実行して結果のサンプルを表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# athena-query を設定し実行する\n",
    "try:\n",
    "    # 特徴量グループがある場合、その名前を取得する\n",
    "    feature_group_name = sagemaker_session.boto_session.client(\"sagemaker\", region_name=region).list_feature_groups()['FeatureGroupSummaries'][0]['FeatureGroupName']\n",
    "    feature_group = FeatureGroup(name=feature_group_name, sagemaker_session=sagemaker_session)\n",
    "\n",
    "    # Athena が設定済みであることを確認する\n",
    "    try:\n",
    "        boto3.client('athena').update_work_group(\n",
    "            WorkGroup='primary',\n",
    "            ConfigurationUpdates={\n",
    "                'EnforceWorkGroupConfiguration':False\n",
    "            }\n",
    "        )\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # クエリを設定する\n",
    "    query = feature_group.athena_query()\n",
    "    table = query.table_name\n",
    "    query_string = f'SELECT * FROM \"{table}\" '\n",
    "    output_location = f\"s3://{sagemaker_session.default_bucket()}/query_results/\"\n",
    "    print(f\"Athena query output location: \\n{output_location}\")\n",
    "\n",
    "    # クエリを実行する\n",
    "    query.run(query_string=query_string, output_location=output_location)\n",
    "    query.wait()\n",
    "    df_feature_store = query.as_dataframe()\n",
    "    \n",
    "    # 特徴量グループにデータが表示されるのを待つ\n",
    "    attempts = 0\n",
    "    while len(df_feature_store.index) == 0 and attempts < 30:\n",
    "        print(\"Waiting for feature group to populate...\")\n",
    "        time.sleep(60)\n",
    "        # クエリを再実行する\n",
    "        query.run(query_string=query_string, output_location=output_location)\n",
    "        query.wait()\n",
    "        df_feature_store = query.as_dataframe()\n",
    "        # 試行回数を増やす\n",
    "        attempts += 1\n",
    "    if len(df_feature_store.index) != 0:\n",
    "        print(\"The feature group is populated.\")\n",
    "except IndexError as e:\n",
    "    # 特徴量グループがない場合に、エラーを発生させる\n",
    "    print(\"No feature groups were found. Please create a feature group.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上のコードブロックを実行した後に、Amazon Athenaのクエリレコードが**sagemaker**で名前のはじまるAmazon S3バケットに保存されます。保存されたクエリオブジェクトは**query_results**というディレクトリ内に保存されます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#task2-2-continue\" target=\"_self\">タスク 2.2</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task3-1\" id=\"task3-1\"></a>\n",
    "\n",
    "### 付録: ExperimentとRunを作成する (タスク 3.1)\n",
    "\n",
    "Experimentを作成するには、**sagemaker.experiments.run** を使用してexperimentを設定します。ここで、**experiment_name**、**run_name** と **description** を指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "#experiment と run-namesの作成\n",
    "create_date = strftime(\"%m%d%H%M\")\n",
    "capstone_experiment_name=\"capstone-experiment-{}\".format(create_date)\n",
    "capstone_run_name = \"lab-capstone-run-{}\".format(create_date)\n",
    "\n",
    "# run_tagを定義\n",
    "run_tags = [{'Key': 'lab-capstone', 'Value': 'lab-capstone-run'}]\n",
    "\n",
    "# descriptionを追加\n",
    "description=\"Using SM Experiments with the Auto dataset.\"\n",
    "\n",
    "print(f\"Experiment name - {capstone_experiment_name},  run name - {capstone_run_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#task3-1-continue\" target=\"_self\">タスク 3.1</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task3-2\" id=\"task3-2\"></a>\n",
    "\n",
    "### 付録: データをトレーニング用、テスト用、検証用のデータセットに分割する (タスク 3.2)\n",
    "\n",
    "データを分割するには、**np.split** を使用し、データの分割方法を指定します。そして、CSV ファイルを作成し、S3 バケットにアップロードします。次に、トレーニング用の入力を設定します。最後に、**data_inputs** 変数を作成します。この data_inputs は、課題を通じて、モデルトレーニング時にトレーニング用と検証用のデータセットを指定するために使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#トレーニング用、テスト用、検証用に分割する\n",
    "try:\n",
    "    # 特徴量グループがある場合、それを使用する\n",
    "    df_feature_store = df_feature_store.iloc[: , :-4]\n",
    "    df_processed_pre_split = df_feature_store\n",
    "    print(\"Using the records from the feature group\")\n",
    "except NameError:\n",
    "    # 特徴量グループがない場合、処理済みのデータセットを使用する\n",
    "    df_processed = pd.read_csv(\"./data/claims_customer.csv\", index_col=None)\n",
    "    df_processed_pre_split = df_processed\n",
    "    print(\"Using the processed records from Amazon S3\")\n",
    "\n",
    "# データをトレーニング用、検証用、テスト用のデータセットに分割する\n",
    "train_data, validation_data, test_data = np.split(\n",
    "    df_processed_pre_split.sample(frac=1, random_state=1729),\n",
    "    [int(0.7 * len(df_processed_pre_split)), int(0.9 * len(df_processed_pre_split))],\n",
    ")\n",
    "\n",
    "# CSV ファイルを作成し、デフォルトのバケットにアップロードする\n",
    "train_data.to_csv(\"train_data.csv\", index=False, header=False)\n",
    "validation_data.to_csv(\"validation_data.csv\", index=False, header=False)\n",
    "test_data.to_csv(\"test_data.csv\", index=False, header=False)\n",
    "\n",
    "train_path = S3Uploader.upload(\"train_data.csv\", \"s3://{}/{}\".format(bucket, prefix))\n",
    "validation_path = S3Uploader.upload(\"validation_data.csv\", \"s3://{}/{}\".format(bucket, prefix))\n",
    "test_path = S3Uploader.upload(\"test_data.csv\", \"s3://{}/{}\".format(bucket, prefix))\n",
    "\n",
    "# トレーニング用の入力を設定する\n",
    "train_input = TrainingInput(train_path, content_type=\"text/csv\")\n",
    "validation_input = TrainingInput(validation_path, content_type=\"text/csv\")\n",
    "test_input = TrainingInput(test_path, content_type=\"text/csv\")\n",
    "\n",
    "data_inputs = {\n",
    "    \"train\": train_input,\n",
    "    \"validation\": validation_input\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#task3-2-continue\" target=\"_self\">タスク 3.2</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task3-3-1\" id=\"task3-3-1\"></a>\n",
    "\n",
    "### 付録: 基本的なトレーニングジョブを設定し、実行する (タスク 3.3)\n",
    "\n",
    "基本的なトレーニングジョブから始める場合、ベーシックな **XGBoost** コンテナを使用します。そして、使用するコンテナとロールに注意しながらestimatorを設定します。これらの設定が完了したら、ハイパーパラメータを選択します。以下のコードで提供されるデフォルト値を使用してもいいですし、データ準備中に気付いたことに応じて編集していただいても構いません。\n",
    "\n",
    "トレーニングジョブを実行するには、**fit()** を呼び出し、入力に **data_inputs** 変数を使用し、設定に**run_name**と**experiment_name** を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker import image_uris\n",
    "# モデルをトレーニングする\n",
    "# コンテナイメージを取得する\n",
    "container = sagemaker.image_uris.retrieve(\n",
    "    region=boto3.Session().region_name, \n",
    "    framework=\"xgboost\", \n",
    "    version=\"1.5-1\"\n",
    ")\n",
    "\n",
    "# ハイパーパラメータを設定する\n",
    "eta=0.2\n",
    "gamma=4\n",
    "max_depth=5\n",
    "min_child_weight=6\n",
    "num_round=800\n",
    "objective='binary:logistic'\n",
    "subsample=0.8\n",
    "\n",
    "hyperparameters = {\n",
    "    \"eta\":eta,\n",
    "    \"gamma\":gamma,\n",
    "    \"max_depth\":max_depth,\n",
    "    \"min_child_weight\":min_child_weight,\n",
    "    \"num_round\":num_round,\n",
    "    \"objective\":objective,\n",
    "    \"subsample\":subsample\n",
    "}\n",
    "\n",
    "# Estimatorを設定する\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,    \n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    "    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    max_run=1800,\n",
    "    hyperparameters=hyperparameters,\n",
    "    tags = run_tags\n",
    ")\n",
    "\n",
    "with Run(\n",
    "    experiment_name=capstone_experiment_name,\n",
    "    run_name=capstone_run_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "    run.log_parameter(\"eta\", eta)\n",
    "    run.log_parameter(\"gamma\", gamma)\n",
    "    run.log_parameter(\"max_depth\", max_depth)\n",
    "    run.log_parameter(\"min_child_weight\", min_child_weight)\n",
    "    run.log_parameter(\"objective\", objective)\n",
    "    run.log_parameter(\"subsample\", subsample)\n",
    "    run.log_parameter(\"num_round\", num_round)\n",
    "\n",
    "# モデルをトレーニングする\n",
    "    xgb.fit(\n",
    "        inputs = data_inputs\n",
    "    )        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#task3-3-continue\" target=\"_self\">タスク 3.3</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task3-3-2\" id=\"task3-3-2\"></a>\n",
    "\n",
    "### 付録: SageMaker のデバッガーを有効にしてトレーニングジョブを設定して実行し、レポートを分析する (タスク 3.3)\n",
    "\n",
    "SageMaker Debugger を使用すると、ハイパーパラメータのチューニングに役立つ追加レポートがすばやく提供されるため、ハイパーパラメータの範囲を指定して、より多くトレーニングジョブを実行する際の時間を短縮できます。デバッガーを有効にするには、**DebuggerHookConfig** と **rules** を設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# デバッガーを有効にする\n",
    "# コンテナイメージを取得する\n",
    "container = sagemaker.image_uris.retrieve(\n",
    "    region=boto3.Session().region_name, \n",
    "    framework=\"xgboost\", \n",
    "    version=\"1.5-1\"\n",
    ")\n",
    "\n",
    "# ハイパーパラメータを設定する\n",
    "eta=0.2\n",
    "gamma=4\n",
    "max_depth=5\n",
    "min_child_weight=6\n",
    "num_round=300\n",
    "objective='binary:logistic'\n",
    "subsample=0.7\n",
    "        \n",
    "hyperparameters = {\n",
    "        \"eta\":eta,\n",
    "        \"gamma\":gamma,\n",
    "        \"max_depth\":max_depth,\n",
    "        \"min_child_weight\":min_child_weight,\n",
    "        \"num_round\":num_round,\n",
    "        \"objective\":objective,\n",
    "        \"subsample\":subsample\n",
    "}\n",
    "\n",
    "# Estimatorを設定する\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role, \n",
    "    base_job_name=base_job_name,\n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    "    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    max_run=1800,\n",
    "    hyperparameters=hyperparameters,\n",
    "    tags = run_tags,\n",
    "\n",
    "    # デバッガーのフック構成を設定する\n",
    "    debugger_hook_config=DebuggerHookConfig(\n",
    "        s3_output_path=bucket_path,  # Required\n",
    "        collection_configs=[\n",
    "            CollectionConfig(name=\"metrics\", parameters={\"save_interval\": str(save_interval)}),\n",
    "            CollectionConfig(name=\"feature_importance\", parameters={\"save_interval\": str(save_interval)},),\n",
    "            CollectionConfig(name=\"full_shap\", parameters={\"save_interval\": str(save_interval)}),\n",
    "            CollectionConfig(name=\"average_shap\", parameters={\"save_interval\": str(save_interval)}),\n",
    "        ],\n",
    "        ),\n",
    "        # デバッガーのプロファイラー構成を設定する\n",
    "        profiler_config = ProfilerConfig(\n",
    "            system_monitor_interval_millis=500,\n",
    "            framework_profile_params=FrameworkProfile()\n",
    "    ),\n",
    "        # デバッガーのルールオブジェクトを設定する\n",
    "        rules = [\n",
    "            ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "            Rule.sagemaker(rule_configs.create_xgboost_report()),  \n",
    "            Rule.sagemaker(rule_configs.overfit()),\n",
    "            Rule.sagemaker(rule_configs.overtraining()),\n",
    "            Rule.sagemaker(rule_configs.loss_not_decreasing(),\n",
    "                rule_parameters={\n",
    "                    \"collection_names\": \"metrics\",\n",
    "                    \"num_steps\": str(save_interval * 2),\n",
    "                }\n",
    "            )\n",
    "    ]\n",
    ")\n",
    "with Run(\n",
    "    experiment_name=capstone_experiment_name,\n",
    "    run_name=capstone_run_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "    run.log_parameter(\"eta\", eta)\n",
    "    run.log_parameter(\"gamma\", gamma)\n",
    "    run.log_parameter(\"max_depth\", max_depth)\n",
    "    run.log_parameter(\"min_child_weight\", min_child_weight)\n",
    "    run.log_parameter(\"objective\", objective)\n",
    "    run.log_parameter(\"subsample\", subsample)\n",
    "    run.log_parameter(\"num_round\", num_round)\n",
    "# モデルをトレーニングする\n",
    "xgb.fit(\n",
    "    inputs = data_inputs\n",
    ") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#task3-3-continue\" target=\"_self\">タスク 3.3</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task3-4\" id=\"task3-4\"></a>\n",
    "\n",
    "### 付録: トレーニングハイパーパラメータの範囲を設定する (タスク 3.4)\n",
    "\n",
    "少なくとも 1 つのモデルトレーニングが完了したので、データ処理と SageMaker Debugger から得た情報を使用して、ハイパーパラメータの範囲を選択できます。以下のハイパーパラメータ範囲を編集し、チューニングジョブを実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルをチューニングする\n",
    "# ハイパーパラメータの範囲を設定する\n",
    "hyperparameter_ranges = {\n",
    "    \"alpha\": ContinuousParameter(0, 2),\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "    \"max_depth\": IntegerParameter(1, 10),\n",
    "    \"min_child_weight\": ContinuousParameter(1, 10),\n",
    "    \"num_round\": IntegerParameter(100, 1000)\n",
    "}\n",
    "\n",
    "# ターゲットメトリクスとターゲットのタイプ (最大/最小) を定義する\n",
    "objective_metric_name = \"validation:auc\"\n",
    "objective_type=\"Maximize\"\n",
    "\n",
    "# HyperparameterTuner を定義する\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator = xgb,\n",
    "    objective_metric_name = objective_metric_name,\n",
    "    hyperparameter_ranges = hyperparameter_ranges,\n",
    "    objective_type = objective_type,\n",
    "    max_jobs=12,\n",
    "    max_parallel_jobs=4,\n",
    "    early_stopping_type=\"Auto\"\n",
    ")\n",
    "\n",
    "# モデルをチューニングする\n",
    "tuner.fit(\n",
    "    inputs = data_inputs\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#task3-4-continue\" target=\"_self\">タスク 3.4</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-1\" id=\"task4-1\"></a>\n",
    "\n",
    "### 付録: モデルを作成する (タスク 4.1)\n",
    "\n",
    "XGBoost モデルを作成し、定義した **model_name**、**role**、**container_def** を指定して **create_model** を呼び出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの設定\n",
    "model_name = \"capstone-clarify-model\"\n",
    "model = xgb.create_model(name=model_name)\n",
    "container_def = model.prepare_container_def()\n",
    "sagemaker_session.create_model(model_name, role, container_def)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#task4-1-continue\" target=\"_self\">タスク 4.1</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-2\" id=\"task4-2\"></a>\n",
    "\n",
    "### 付録: Clarify のモデルの設定を作成する (タスク 4.2)\n",
    "\n",
    "**SageMakerClarifyProcessor** を使用して、Clarify のモデルの設定を作成します。**instance_count** と **instance_type** を設定します。キャップストーンのラボの冒頭で作成した **role** と **session** を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clarify のプロセッサを定義する\n",
    "clarify_processor = clarify.SageMakerClarifyProcessor(\n",
    "    role=role, \n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.m5.xlarge\", \n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#task4-2-continue\" target=\"_self\">タスク 4.2</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-3\" id=\"task4-3\"></a>\n",
    "\n",
    "### 付録: Clarify のバイアスの設定を作成する (タスク 4.3)\n",
    "\n",
    "Clarify のバイアス設定を作成するには、**label**、**headers**、**dataset_type** を設定するのに加え、データの出力パスを選択し、トレーニングジョブからの入力パスを設定します。\n",
    "\n",
    "次に、**ModelConfig** と **ModelPredictedLabelConfig** を作成します。\n",
    "\n",
    "最後に、SageMaker Clarify で確認するフィールドを含む **BiasConfig** を設定します。最初の結果に基づいて、確認するフィールドを追加または削除することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ設定を定義する\n",
    "bias_report_output_path = \"s3://{}/{}/clarify-bias\".format(bucket, prefix)\n",
    "bias_data_config = clarify.DataConfig(\n",
    "    s3_data_input_path=train_path,\n",
    "    s3_output_path=bias_report_output_path,\n",
    "    label=\"fraud\",\n",
    "    headers=train_data.columns.to_list(),\n",
    "    dataset_type=\"text/csv\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル設定を定義する\n",
    "model_config = clarify.ModelConfig(\n",
    "    model_name=model_name,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    accept_type=\"text/csv\",\n",
    "    content_type=\"text/csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルの設定を定義する\n",
    "predictions_config = clarify.ModelPredictedLabelConfig(probability_threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バイアスの設定を定義する\n",
    "bias_config = clarify.BiasConfig(\n",
    "    label_values_or_threshold=[1], facet_name=\"customer_gender_female\", facet_values_or_threshold=[0], group_name=\"customer_age\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#task4-3-continue\" target=\"_self\">タスク 4.3</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-4\" id=\"task4-4\"></a>\n",
    "\n",
    "### 付録: SageMaker Clarify を使ってバイアス、データ、モデルのレポートを実行する (タスク 4.4)\n",
    "\n",
    "Clarify のジョブが設定されたので、**run_bias** を呼び出してジョブを実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バイアスレポートを実行する\n",
    "clarify_processor.run_bias(\n",
    "    data_config=bias_data_config,\n",
    "    bias_config=bias_config,\n",
    "    model_config=model_config,\n",
    "    model_predicted_label_config=predictions_config,\n",
    "    pre_training_methods=\"all\",\n",
    "    post_training_methods=\"all\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#task4-4-continue\" target=\"_self\">タスク 4.4</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-5\" id=\"task4-5\"></a>\n",
    "\n",
    "### 付録: 不均衡を解消する (タスク 4.5)\n",
    "\n",
    "この例では、データセットのバイアスを抑制するために、**customer_gender_female** をアップサンプリングしています。他の特徴量にバイアスがある場合は、そうした特徴に対しても不均衡を解消することができます。**random_state** は `42` に設定されていますが、この値は変更することもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 概要を表示する\n",
    "gender = train_data[\"customer_gender_female\"]\n",
    "gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不均衡を削除する\n",
    "sm = SMOTE(random_state=42)\n",
    "train_data_upsampled, gender_res = sm.fit_resample(train_data, gender)\n",
    "train_data_upsampled[\"customer_gender_female\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#task4-5-continue\" target=\"_self\">タスク 4.5</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-6\" id=\"task4-6\"></a>\n",
    "\n",
    "### 付録: モデルを再トレーニングする (タスク 4.6)\n",
    "\n",
    "不均衡を検出し、新しいトレーニングデータセットを取得しました。このデータセットを使用して、ファイルを再トレーニングします。この操作を行うには、新しいファイルをアップロードし、新しいEstimatorを作成します。そして、**fit()** でそのデータを再トレーニングします。以下のコードには、サンプルとしていくつかのハイパーパラメータが含まれています。再トレーニングの際に、必要に応じてこれらを追加、削除、調整し、最適なモデルを見つけることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アップサンプリングされた CSV ファイルをアップロードする\n",
    "train_data_upsampled.to_csv(\"data/upsampled_train.csv\", index=False, header=False)\n",
    "retrain_path = S3Uploader.upload(\"data/upsampled_train.csv\", \"s3://{}/{}\".format(bucket, prefix))\n",
    "retrain_input = TrainingInput(retrain_path, content_type=\"text/csv\")\n",
    "\n",
    "retrain_data_inputs = {\n",
    "    \"train\": retrain_input,\n",
    "    \"validation\": validation_input\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimatorを作成する\n",
    "hyperparameters= {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.7\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": \"300\",\n",
    "}\n",
    "\n",
    "xgb_retrained = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role, \n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters=hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アップサンプリングされたデータを再トレーニングする\n",
    "xgb_retrained.fit(\n",
    "    inputs = retrain_data_inputs\n",
    ") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#task4-6-continue\" target=\"_self\">タスク 4.6</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task5-1\" id=\"task5-1\"></a>\n",
    "\n",
    "### 付録: バッチ変換ジョブを作成する (タスク 5.1)\n",
    "\n",
    "モデル Estimatorを使用し、**Transformer** でバッチ変換ジョブを作成します。処理の効率を上げるため、strategy に **MultiRecord** を設定します。次に、**test_path** を渡し、推論が実行されるのを待ちます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチTransformerを作成する \n",
    "# 再トレーニングされたモデルがある場合はそれを使用し、ない場合はオリジナルのモデルを使用する\n",
    "try:\n",
    "    model = xgb_retrained\n",
    "except NameError:\n",
    "    model = xgb\n",
    "\n",
    "# Transformerを作成する\n",
    "transformer = model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    strategy=\"MultiRecord\",\n",
    "    assemble_with=\"Line\",\n",
    "    accept=\"text/csv\",\n",
    "    output_path=\"s3://{}/{}/batch-transform/\".format(bucket, prefix)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチ変換ジョブを実行する\n",
    "test_data_batch = test_data.drop(\"fraud\", axis=1)\n",
    "test_data_batch.to_csv(\"test_data_batch.csv\", index=False, header=False)\n",
    "test_path_batch = S3Uploader.upload(\"test_data_batch.csv\", \"s3://{}/{}\".format(bucket, prefix))\n",
    "\n",
    "transformer.transform(test_path_batch, content_type=\"text/csv\", split_type=\"Line\", join_source=\"Input\")\n",
    "transformer.wait()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#task5-1-continue\" target=\"_self\">タスク 5.1</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task5-2\" id=\"task5-2\"></a>\n",
    "\n",
    "### 付録: バッチ変換ジョブの予測データと正解率データを確認する (タスク 5.2)\n",
    "\n",
    "バッチ変換ジョブが終了したら、Amazon S3 に保存されている予測データを確認します。**Transformer**で設定した出力パスを参照し、データをサンプリングできます。\n",
    "\n",
    "この出力では、各レコードの最後に**fraud**の予測値が付加されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $transformer.output_path ./\n",
    "test_data = pd.read_csv(\"test_data_batch.csv.out\")\n",
    "test_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#task5-2-continue\" target=\"_self\">タスク 5.2</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task5-3\" id=\"task5-3\"></a>\n",
    "\n",
    "### 付録: SageMaker Studio で SageMaker インスタンスをクリーンアップする (タスク 5.3)\n",
    "\n",
    "SageMaker Studio でモデルを開発している間、クリーンアップすべきインスタンスがあるかどうか定期的に確認します。ある場合は、SageMaker Studio からインスタンスをシャットダウンできます。\n",
    "\n",
    "1. 左のメニューバーから、[**Running Terminals and Kernels**] のアイコン (真ん中に四角がある円) をクリックします。\n",
    "\n",
    "1. まだ開いているインスタンスがある場合は、各インスタンスタイプの右側にある [**Shut down**] アイコンをクリックします。\n",
    "\n",
    "各インスタンスで実行中のアプリケーションを表示し、終了してもよいアプリケーションを確認できます。\n",
    "\n",
    "1. ポップアップウィンドウが表示された場合は、[**Shut down all**] をクリックします。\n",
    "\n",
    "1. リスト上にインスタンスが表示されなくなるまで、折を見て **Refresh List** アイコンをクリックします。インスタンスがシャットダウンされるまで 2～5 分かかることがあります。\n",
    "\n",
    "**capstone_ja_jp.ipynb** ノートブックで使用しているインスタンスをシャットダウンする必要はありません。\n",
    "\n",
    "<a href=\"#task5-3-continue\" target=\"_self\">タスク 5.3</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task6-1\" id=\"task6-1\"></a>\n",
    "\n",
    "### 付録: パイプラインを設定する (タスク 6.1)\n",
    "\n",
    "パイプラインを作成するには、パイプラインプロセスの各ステップを定義してから、それを実行します。\n",
    "\n",
    "この例では、以下のステップを作成します:\n",
    "- **AutoModelProcess**: .csv ファイルを取り込み、トレーニング用、テスト用、検証用のデータセットに分割する **Processing** ステップ。\n",
    "- **AutoHyperParameterTuning**: ハイパーパラメータの範囲を取得し、モデルをチューニングする **Tuning** ステップ。\n",
    "- **AutoEvalBestModel**: 最適なモデルを示す評価レポートを作成する **Processing** ステップ。\n",
    "- **CheckAUCScoreAutoEvaluation**: 評価メトリクスに基づきモデルを評価する **Condition** ステップ。\n",
    "- **AutoCreateModel**: モデルを作成する **Model** ステップ。\n",
    "- **RegisterAutoModel-RegisterModel**: モデルを登録する **RegisterModel** ステップ。\n",
    "- **AutoModelConfigFile**: バイアスレポートを作成する **Processing** ステップ。\n",
    "- **AutoTransform**: バッチ変換ジョブを実行する **Transform** ステップ。\n",
    "- **ClarifyProcessingStep**: SageMaker Clarify のジョブを実行する **Processing** ステップ。\n",
    "\n",
    "パイプラインの構築中にうまくいかなくなった場合は、以下のコードをカスタマイズするか、参照して独自のパイプラインを構築できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パイプラインを実行する\n",
    "# 変数を設定する\n",
    "model_name = \"Auto-model\"\n",
    "sklearn_processor_version=\"0.23-1\"\n",
    "model_package_group_name=\"AutoModelPackageGroup\"\n",
    "pipeline_name= \"AutoModelSMPipeline\"\n",
    "clarify_image = sagemaker.image_uris.retrieve(framework='sklearn',version=sklearn_processor_version,region=region)\n",
    "\n",
    "# ファイルをデフォルトの S3 バケットにアップロードする\n",
    "s3_client.put_object(Bucket=bucket,Key='data/')\n",
    "s3_client.put_object(Bucket=bucket,Key='input/code/')\n",
    "s3_client.upload_file(Filename=\"data/batch_data.csv\", Bucket=bucket, Key=\"data/batch_data.csv\")  #If you edit this, make sure to also edit the headers listed in generate_config to match your column names.\n",
    "s3_client.upload_file(Filename=\"data/claims_customer.csv\", Bucket=bucket, Key=\"data/claims_customer.csv\")  #If you edit this, make sure to also edit the headers listed in generate_config to match your column names.\n",
    "s3_client.upload_file(Filename=\"pipelines/evaluate.py\", Bucket=bucket, Key=\"input/code/evaluate.py\")\n",
    "s3_client.upload_file(Filename=\"pipelines/generate_config.py\", Bucket=bucket, Key=\"input/code/generate_config.py\")\n",
    "s3_client.upload_file(Filename=\"pipelines/preprocess.py\", Bucket=bucket, Key=\"input/code/preprocess.py\")\n",
    "\n",
    "# 重要な設定を行う。claims_customer.csv と batch_data.csv 以外の\n",
    "# ファイルを使用する場合は、input_data を変更する\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "processing_instance_type = ParameterString(\n",
    "        name=\"ProcessingInstanceType\",\n",
    "        default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "training_instance_type = ParameterString(\n",
    "        name=\"TrainingInstanceType\",\n",
    "        default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "input_data = ParameterString(\n",
    "        name=\"InputData\",\n",
    "        default_value=\"s3://{}/data/claims_customer.csv\".format(bucket), \n",
    ")\n",
    "batch_data = ParameterString(\n",
    "        name=\"BatchData\",\n",
    "        default_value=\"s3://{}/data/batch_data.csv\".format(bucket),\n",
    ")\n",
    "\n",
    "# scikit-learn スクリプトを実行して、SageMaker でデータ処理を行う\n",
    "# SKLearnProcessor クラスを使用する\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "        framework_version=sklearn_processor_version,\n",
    "        instance_type=processing_instance_type.default_value, \n",
    "        instance_count=processing_instance_count,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        role=role,\n",
    ")\n",
    "\n",
    "# input_data を取り込むための処理ステップを設定する\n",
    "step_process = ProcessingStep(\n",
    "        name=\"AutoModelProcess\",\n",
    "        processor=sklearn_processor,\n",
    "        outputs=[\n",
    "            ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\",\\\n",
    "                             destination=f\"s3://{bucket}/output/train\" ),\n",
    "            ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\",\\\n",
    "                            destination=f\"s3://{bucket}/output/validation\"),\n",
    "            ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\",\\\n",
    "                            destination=f\"s3://{bucket}/output/test\"),\n",
    "            ProcessingOutput(output_name=\"batch\", source=\"/opt/ml/processing/batch\",\\\n",
    "                            destination=f\"s3://{bucket}/data/batch\"),\n",
    "            ProcessingOutput(output_name=\"baseline\", source=\"/opt/ml/processing/baseline\",\\\n",
    "                            destination=f\"s3://{bucket}/input/baseline\")\n",
    "        ],\n",
    "        code=f\"s3://{bucket}/input/code/preprocess.py\",\n",
    "        job_arguments=[\"--input-data\", input_data],\n",
    ")\n",
    "\n",
    "# モデルのパス、コンテナイメージ uri、Estimatorのハイパーパラメータを設定する\n",
    "model_path = f\"s3://{bucket}/output\"\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.5-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=training_instance_type.default_value,\n",
    ")\n",
    "\n",
    "fixed_hyperparameters = {\n",
    "    \"eval_metric\":\"auc\",\n",
    "    \"objective\":\"binary:logistic\",\n",
    "    \"num_round\":\"100\",\n",
    "    \"rate_drop\":\"0.3\",\n",
    "    \"tweedie_variance_power\":\"1.4\"\n",
    "}\n",
    "\n",
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    hyperparameters=fixed_hyperparameters,\n",
    "    output_path=model_path,\n",
    "    base_job_name=f\"auto-train\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "# チューニングステップのハイパーパラメータ範囲を設定し、チューニングステップを設定する\n",
    "hyperparameter_ranges = {\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "    \"min_child_weight\": ContinuousParameter(1, 10),\n",
    "    \"alpha\": ContinuousParameter(0, 2),\n",
    "    \"max_depth\": IntegerParameter(1, 10),\n",
    "}\n",
    "objective_metric_name = \"validation:auc\"\n",
    "\n",
    "step_tuning = TuningStep(\n",
    "    name = \"AutoHyperParameterTuning\",\n",
    "    tuner = HyperparameterTuner(xgb_train, objective_metric_name, hyperparameter_ranges, max_jobs=2, max_parallel_jobs=2),\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    },\n",
    ")\n",
    "\n",
    "# 評価のための処理ステップを設定する\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"script-auto-eval\",\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"AutoEvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\",\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"AutoEvalBestModel\",\n",
    "    processor=script_eval,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_tuning.get_top_model_s3_uri(top_k=0,s3_bucket=bucket,prefix=\"output\"),\n",
    "            destination=\"/opt/ml/processing/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\",\\\n",
    "                            destination=f\"s3://{bucket}/output/evaluation\"),\n",
    "    ],\n",
    "    code=f\"s3://{bucket}/input/code/evaluate.py\",\n",
    "    property_files=[evaluation_report],\n",
    ")\n",
    "\n",
    "# モデルの作成を設定する\n",
    "model = Model(\n",
    "    image_uri=image_uri,        \n",
    "    model_data=step_tuning.get_top_model_s3_uri(top_k=0,s3_bucket=bucket,prefix=\"output\"),\n",
    "    name=model_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "inputs = CreateModelInput(\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    accelerator_type=\"ml.inf1.xlarge\",\n",
    ")\n",
    "\n",
    "step_create_model = CreateModelStep(\n",
    "    name=\"AutoCreateModel\",\n",
    "    model=model,\n",
    "    inputs=inputs,\n",
    ")\n",
    "\n",
    "script_processor = ScriptProcessor(\n",
    "    command=['python3'],\n",
    "    image_uri=clarify_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=processing_instance_type,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "bias_report_output_path = f\"s3://{bucket}/clarify-output/bias\"\n",
    "clarify_instance_type = 'ml.m5.xlarge'\n",
    "step_config_file = ProcessingStep(\n",
    "    name=\"AutoModelConfigFile\",\n",
    "    processor=script_processor,\n",
    "    code=f\"s3://{bucket}/input/code/generate_config.py\",\n",
    "    job_arguments=[\"--modelname\",step_create_model.properties.ModelName,\"--bias-report-output-path\",bias_report_output_path,\"--clarify-instance-type\",clarify_instance_type,\\\n",
    "                  \"--default-bucket\",bucket,\"--num-baseline-samples\",\"50\",\"--instance-count\",\"1\"],\n",
    "    depends_on= [step_create_model.name]\n",
    ")\n",
    "\n",
    "# バッチ変換ジョブを実行するためのステップを設定する\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    assemble_with=\"Line\",\n",
    "    accept=\"text/csv\",    \n",
    "    output_path=f\"s3://{bucket}/AutoTransform\"\n",
    ")\n",
    "\n",
    "step_transform = TransformStep(\n",
    "    name=\"AutoTransform\",\n",
    "    transformer=transformer,\n",
    "    inputs=TransformInput(data=batch_data,content_type=\"text/csv\",join_source=\"Input\",split_type=\"Line\")\n",
    ")\n",
    "\n",
    "# SageMaker Clarify の処理ステップを設定する\n",
    "analysis_config_path = f\"s3://{bucket}/clarify-output/bias/analysis_config.json\"\n",
    "\n",
    "data_config = sagemaker.clarify.DataConfig(\n",
    "    s3_data_input_path=f's3://{bucket}/output/train/train.csv', \n",
    "    s3_output_path=bias_report_output_path,\n",
    "    label=0,\n",
    "    headers=list(pd.read_csv(\"./data/claims_customer.csv\", index_col=None).columns), #If you edit this, make sure to also edit the headers listed in generate_config to match your column names.\n",
    "    dataset_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "clarify_processor = sagemaker.clarify.SageMakerClarifyProcessor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=clarify_instance_type,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "config_input = ProcessingInput(\n",
    "    input_name=\"analysis_config\",\n",
    "    source=analysis_config_path,\n",
    "    destination=\"/opt/ml/processing/input/analysis_config\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    s3_input_mode=\"File\",\n",
    "    s3_compression_type=\"None\",\n",
    ")\n",
    "\n",
    "data_input = ProcessingInput(\n",
    "    input_name=\"dataset\",\n",
    "    source=data_config.s3_data_input_path,\n",
    "    destination=\"/opt/ml/processing/input/data\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    s3_input_mode=\"File\",\n",
    "    s3_data_distribution_type=data_config.s3_data_distribution_type,\n",
    "    s3_compression_type=data_config.s3_compression_type,\n",
    ")\n",
    "\n",
    "result_output = ProcessingOutput(\n",
    "    source=\"/opt/ml/processing/output\",\n",
    "    destination=data_config.s3_output_path,\n",
    "    output_name=\"analysis_result\",\n",
    "    s3_upload_mode=\"EndOfJob\",\n",
    ")\n",
    "\n",
    "step_clarify = ProcessingStep(\n",
    "    name=\"ClarifyProcessingStep\",\n",
    "    processor=clarify_processor,\n",
    "    inputs= [data_input, config_input],\n",
    "    outputs=[result_output],\n",
    "    depends_on = [step_config_file.name]\n",
    ")\n",
    "\n",
    "# モデル登録ステップを設定する\n",
    "model_statistics = MetricsSource(\n",
    "    s3_uri=\"s3://{}/output/evaluation/evaluation.json\".format(bucket),\n",
    "    content_type=\"application/json\"\n",
    ")\n",
    "explainability = MetricsSource(\n",
    "    s3_uri=\"s3://{}/clarify-output/bias/analysis.json\".format(bucket),\n",
    "    content_type=\"application/json\"\n",
    ")\n",
    "\n",
    "bias = MetricsSource(\n",
    "    s3_uri=\"s3://{}/clarify-output/bias/analysis.json\".format(bucket),\n",
    "    content_type=\"application/json\"\n",
    ") \n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=model_statistics,\n",
    "    explainability=explainability,\n",
    "    bias=bias\n",
    ")\n",
    "\n",
    "step_register = RegisterModel(\n",
    "    name=\"RegisterAutoModel\",\n",
    "    estimator=xgb_train,\n",
    "    model_data=step_tuning.get_top_model_s3_uri(top_k=0,s3_bucket=bucket,prefix=\"output\"),\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    model_metrics=model_metrics,\n",
    ")\n",
    "\n",
    "# モデル評価ステップを作成する\n",
    "cond_lte = ConditionGreaterThan(\n",
    "    left=JsonGet(\n",
    "        step=step_eval,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"binary_classification_metrics.auc.value\"\n",
    "    ),\n",
    "    right=0.75,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"CheckAUCScoreAutoEvaluation\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_create_model,step_config_file,step_transform,step_clarify,step_register],\n",
    "    else_steps=[],\n",
    ")\n",
    "\n",
    "# パイプラインを定義する\n",
    "def get_pipeline(\n",
    "    region,\n",
    "    role=None,\n",
    "    default_bucket=None,\n",
    "    model_package_group_name=\"AutoModelPackageGroup\",\n",
    "    pipeline_name=\"AutoModelPipeline\",\n",
    "    base_prefix = None,\n",
    "    custom_image_uri = None,\n",
    "    sklearn_processor_version=None\n",
    "    ):\n",
    "    \"\"\"自動データで動作する SageMaker ML Pipeline インスタンスを取得する。\n",
    "    引数:\n",
    "        region: パイプラインを作成して実行する AWS リージョン\n",
    "        role: ステップおよびパイプラインを作成/実行するための IAM ロール\n",
    "        default_bucket: アーティファクトの保存に使用するバケット\n",
    "    戻り値:\n",
    "        パイプラインのインスタンス\n",
    "    \"\"\"\n",
    "\n",
    "    # パイプラインのインスタンス\n",
    "    pipeline = Pipeline(\n",
    "        name=pipeline_name,\n",
    "        parameters=[\n",
    "            processing_instance_type,\n",
    "            processing_instance_count,\n",
    "            training_instance_type,\n",
    "            input_data,\n",
    "            batch_data,\n",
    "        ],\n",
    "        steps=[step_process,step_tuning,step_eval,step_cond],\n",
    "        sagemaker_session=sagemaker_session\n",
    "    )\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# パイプラインを作成する\n",
    "pipeline = get_pipeline(\n",
    "    region = region,\n",
    "    role=role,\n",
    "    default_bucket=bucket,\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    pipeline_name=pipeline_name,\n",
    "    custom_image_uri=clarify_image,\n",
    "    sklearn_processor_version=sklearn_processor_version\n",
    ")\n",
    "\n",
    "pipeline.upsert(role_arn=role)\n",
    "\n",
    "# パイプラインを実行する\n",
    "RunPipeline = pipeline.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#task6-1-continue\" target=\"_self\">タスク 6.1</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task6-2\" id=\"task6-2\"></a>\n",
    "\n",
    "### 付録: パイプラインをモニタリングする (タスク 6.2)\n",
    "\n",
    "パイプラインの作成と実行が完了したので、パイプラインをモニタリングします。パイプラインのステータスは SageMaker Studio で確認できます。\n",
    "\n",
    "パイプラインを削除する場合は、**delete_pipeline** で削除します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パイプラインを記述する\n",
    "RunPipeline.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パイプラインをモニタリングする\n",
    "RunPipeline.wait(delay=30, max_attempts=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パイプラインステップを一覧表示する\n",
    "RunPipeline.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#パイプラインを削除する\n",
    "# response = sagemaker_session.boto_session.client(\"sagemaker\", region_name=region).delete_pipeline(PipelineName='AutoModelSMPipeline')\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#task6-2-continue\" target=\"_self\">タスク 6.2</a> に戻って、このラボを続けます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "741de909edea0d5644898c592544ed98bede62b404d20772e5c4abc3c2f12566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
