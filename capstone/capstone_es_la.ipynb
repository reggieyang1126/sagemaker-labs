{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curso de culminación: Creación de un proyecto de ML de datos tabulares de extremo a extremo con SageMaker Studio y el SDK para Python de Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración del entorno\n",
    "\n",
    "Este código de configuración básica se ha incluido para ayudarlo a comenzar. Lea y ejecute primero estas celdas para instalar los paquetes y crear las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U shap\n",
    "%pip install -U smdebug\n",
    "%pip install imbalanced-learn\n",
    "%pip install pytest-cov\n",
    "%pip install pytest-filter-subpackage\n",
    "%pip install sagemaker\n",
    "%pip install -U seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required-libraries\n",
    "\n",
    "import boto3\n",
    "import datetime as datetime\n",
    "import io\n",
    "import IPython\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt  # visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import re\n",
    "import sagemaker\n",
    "import seaborn as sns  # visualization\n",
    "import statistics\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sagemaker import clarify\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from sagemaker.dataset_definition.inputs import AthenaDatasetDefinition, DatasetDefinition, RedshiftDatasetDefinition\n",
    "from sagemaker.debugger import CollectionConfig, DebuggerHookConfig, FrameworkProfile, ProfilerConfig, ProfilerRule, Rule, rule_configs\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.experiments.run import Run, load_run\n",
    "from sagemaker.feature_store.feature_definition import FeatureDefinition\n",
    "from sagemaker.feature_store.feature_definition import FeatureTypeEnum\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.processing import FeatureStoreOutput\n",
    "from sagemaker.processing import Processor, ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.workflow.condition_step import ConditionStep, JsonGet\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThan\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterFloat, ParameterString\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic-variable-code-and-settings\n",
    "\n",
    "%matplotlib inline\n",
    "base_job_name = \"capstone-smdebugger-job\"\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "bucket_path = \"s3://{}\".format(bucket)\n",
    "prefix = \"sagemaker/capstone\"\n",
    "region = boto3.Session().region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sagemaker_session = sagemaker.Session()\n",
    "save_interval = 5\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del conjunto de datos\n",
    "\n",
    "Las siguientes cinco tablas se almacenan en un bucket de Amazon Simple Storage Service (Amazon S3):\n",
    "- **claims.csv**: una tabla con datos de reclamaciones sin procesar.\n",
    "- **customers.csv**: una tabla con datos de clientes sin procesar.\n",
    "- **claims_preprocessed.csv**: una tabla con datos de reclamaciones procesados.\n",
    "- **customers_preprocessed.csv**: una tabla con datos de clientes procesados.\n",
    "- **claims_customer.csv**: una tabla unida en **policy_id** de los datos procesados de reclamaciones y clientes.\n",
    "\n",
    "Para este laboratorio, comience con las tablas **claims.csv** y **customers.csv**. Procéselas en el **Desafío 1** con Amazon SageMaker Data Wrangler. Si se traba o quiere una referencia de lo que debería ser el conjunto de datos procesado, puede revisar las tablas preprocesadas.\n",
    "\n",
    "Para este conjunto de datos, el objetivo es **fraud**, una columna en la tabla de reclamaciones.\n",
    "\n",
    "La tabla de reclamaciones incluye los siguientes campos: \n",
    "\n",
    "- **policy_id**: el identificador único de la póliza.\n",
    "- **driver_relationship**: una lista de relaciones (Cónyuge, Uno mismo, Hijo, Otro, N/D).\n",
    "- **incident_type**: el tipo de incidente informado (Entrada forzada, Choque, Robo).\n",
    "- **collision_type**: la ubicación del choque (Frontal, Trasero, Lateral, N/D).\n",
    "- **incident_severity**: la gravedad del incidente (Menor, Mayor, Total).\n",
    "- **authorities_contacted**: el tipo de autoridades que se contactó primero (Ninguna, Policía, Ambulancia, Bomberos).\n",
    "- **num_vehicles_involved**: el número de vehículos involucrados en el incidente (de 1 a 6).\n",
    "- **num_injuries**: el número de lesionados en el incidente (de 1 a 4).\n",
    "- **num_witnesses**: el número de testigos del incidente (de 1 a 5).\n",
    "- **police_report_available**: si hay una denuncia a la policía disponible o no (sí o no).\n",
    "- **injury_claim**: el valor de la reclamación por las lesiones en dólares estadounidenses (300 a 576 300 USD).\n",
    "- **vehicle_claim**: el valor de la reclamación por los daños al vehículo en dólares estadounidenses (1000 a 51 051 USD).\n",
    "- **total_claim_amount**: el valor total reclamado por lesiones y daños (2100 a 588 868 USD).\n",
    "- **incident_month**: el mes del incidente (del 1 al 12).\n",
    "- **incident_day**: el día del incidente (del 1 al 31).\n",
    "- **incident_dow**: el día de la semana del incidente (del 0 al 6, que representan del domingo al sábado).\n",
    "- **incident_hour**: la hora del incidente (del 0 al 23).\n",
    "- **fraud**: si la póliza era fraudulenta o no (0 o 1).\n",
    "\n",
    "La tabla de clientes incluye los siguientes campos:\n",
    "\n",
    "- **policy_id**: el identificador único de la póliza.\n",
    "- **customer_age**: la edad del cliente (de 18 a 70).\n",
    "- **months_as_customer**: el número de meses que el cliente ha pagado el seguro (de 1 a 495).\n",
    "- **num_claims_past_year**: el número de reclamaciones que el cliente realizó en el último año.\n",
    "- **num_insurers_past_5_years**: el número de aseguradoras que el cliente tuvo en los últimos 5 años.\n",
    "- **policy_state**: el estado en el que vive el cliente (AZ, CA, ID, NV, OR, WA).\n",
    "- **policy_deductable**: el valor deducible de la póliza en dólares estadounidenses (de 750 a 1100 USD).\n",
    "- **policy_annual_premium**: la prima anual de la póliza en dólares estadounidenses (de 2200 a 3000 USD).\n",
    "- **policy_liability**: los importes máximos de responsabilidad por lesiones corporales, dividido en lesiones corporales simples y todas las lesiones corporales (15/30, 25/50, 60/90, 100/200).\n",
    "- **customer_zip**: el código postal del cliente (de 83201 a 99362).\n",
    "- **customer_gender**: el sexo del cliente (Masculino, Femenino, Otro, Desconocido).\n",
    "- **customer_education**: el nivel de educación del cliente (Menos que escuela secundaria, Escuela secundaria, Tecnicatura, Licenciatura, Estudios superiores).\n",
    "- **auto_year**: el año de fabricación del automóvil (de 2001 a 2020).\n",
    "\n",
    "Puede realizar una unión interna de estas tablas en la columna **policy_id**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navegación del laboratorio de desafíos\n",
    "\n",
    "Este laboratorio está configurado con vínculos que navegan entre las tareas de los desafíos y el apéndice al final del cuaderno. Si desea revisar un elemento del apéndice, seleccione el hipervínculo asociado. Cuando desee regresar al desafío en el que está trabajando actualmente, seleccione el hipervínculo de la tarea correspondiente en el apéndice.\n",
    "\n",
    "El laboratorio está organizado de la siguiente manera:\n",
    "\n",
    "- Desafío 1: analizar y preparar el conjunto de datos con SageMaker Data Wrangler\n",
    "- Desafío 2: crear grupos de funciones en SageMaker Feature Store\n",
    "- Desafío 3: entrenar el modelo\n",
    "- Desafío 4: evaluar el sesgo del modelo\n",
    "- Desafío 5: transformación por lotes\n",
    "- Desafío 6: crear una canalización automatizada\n",
    "- Apéndice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafío 1: analizar y preparar el conjunto de datos con SageMaker Data Wrangler\n",
    "\n",
    "La Consultora CualquierCompañía ha recibido una solicitud para analizar conjuntos de datos sobre fraudes en seguros de automóviles y crear un modelo que ayude a predecir si es probable que las nuevas reclamaciones sean fraudulentas o no. Tiene 5000 registros de clientes en los que ha etiquetado cada reclamación como fraudulenta o no. Puede utilizar estos datos para entrenar, probar y validar su modelo antes de ejecutar una interferencia en una nueva colección de registros por lotes.\n",
    "\n",
    "Utilice las funciones de análisis de Amazon SageMaker Data Wrangler para visualizar las distribuciones de datos en las columnas importantes y verificar la correlación entre las columnas y la filtración de objetivos. Luego, cree un modelo de referencia rápido. A continuación, utilice las funciones de procesamiento de SageMaker Data Wrangler para transformar las columnas de modo que sean más adecuadas para entrenar un modelo de mayor rendimiento. \n",
    "\n",
    "Para completar esta tarea, realice las siguientes subtareas:\n",
    "\n",
    "- Revise los datos.\n",
    "- Realice un análisis de datos exploratorio en Amazon SageMaker Studio.\n",
    "- Utilice un trabajo de procesador de Amazon SageMaker Clarify para ejecutar un informe de sesgos.\n",
    "<b>- </b>Prepare los datos.\n",
    "\n",
    "El tiempo estimado para completar este desafío es de *100* minutos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 1.1: revisar los datos\n",
    "\n",
    "<a id=\"task1-1-continue\"></a>\n",
    "\n",
    "Acceda al conjunto de datos tabulares de seguro de automóviles almacenado en su repositorio y revise una muestra del conjunto de datos. El repositorio contiene dos tablas sin procesar. Una de los datos de clientes llamada **customers.csv** y otra de los datos de reclamaciones llamada **claims.csv**.\n",
    "\n",
    "**Sugerencia 1**: las tablas sin procesar se encuentran en la carpeta **./data/**.\n",
    "\n",
    "**Sugerencia 2**: las tablas **claims.csv** y **customers.csv** son las tablas sin procesar.\n",
    "\n",
    "Tómese un momento para explorar las tablas. ¿Hay algún campo que se destaque? ¿Hay algún campo que requiera un procesamiento previo?\n",
    "\n",
    "Para conocer los pasos detallados sobre cómo revisar los datos, consulte <a href=\"#task1-1\" target=\"_self\">**Revisar los datos (Tarea 1.1)**</a> en la sección *Apéndice*.\n",
    "\n",
    "Una vez que haya accedido a la tabla de fraudes de seguros de automóviles y revisado una muestra del conjunto de datos, habrá completado esta tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_1_1_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 1.2: realizar un análisis de datos exploratorio en SageMaker Studio \n",
    "\n",
    "<a id=\"task1-2-continue\"></a>\n",
    "\n",
    "Revise los datos para realizar un análisis de datos exploratorio, identifique los posibles problemas en el conjunto de datos y verifique las fuertes correlaciones entre cualquier columna y el objetivo. Puede explorar los datos en SageMaker Data Wrangler y en el cuaderno.\n",
    "\n",
    "Tómese un tiempo para revisar específicamente los siguientes elementos:\n",
    "- **Column histograms (Histogramas de columnas)**: revise las columnas en formato visual y verifique qué tipos de valores hay en el conjunto de datos.\n",
    "- **Quick model (Modelo rápido)**: revise el conjunto de datos y piense en un resultado esperado del modelo.\n",
    "- **Feature correlation (Correlación de funciones)**: verifique si hay una fuerte correlación entre las columnas y el objetivo.\n",
    "- **Target leakage (Filtración de objetivos)**: verifique si hay algún dato que dependa del valor del objetivo.\n",
    "\n",
    "Al abrir SageMaker Data Wrangler se abre una nueva pestaña en SageMaker Studio. Para seguir esas instrucciones, utilice las siguientes opciones:\n",
    "- **Opción 1**: ver las pestañas una al lado de la otra. Para crear una vista en la ventana principal de SageMaker Studio con la pantalla dividida, puede arrastrar la pestaña **capstone.ipynb** hacia un lado o seleccionar (con el botón derecho) la pestaña **capstone.ipynb** y luego **New View for Notebook (Nueva vista para el cuaderno)**. Ahora puede tener las instrucciones visibles mientras trabaja con el flujo de SageMaker Data Wrangler\n",
    "- **Opción 2**: cambiar entre las pestañas de SageMaker Studio para seguir estas instrucciones. Cuando termine de explorar los pasos de SageMaker Data Wrangler, seleccione la pestaña **capstone.ipynb** para volver al cuaderno.\n",
    "\n",
    "Si cuando crea un nuevo archivo aparece el error **“The following instance type is not available: ml.m5.4xlarge. Try selecting a different instance below”** (El siguiente tipo de instancia no está disponible: ml.m5.4xlarge. Intente seleccionar un tipo de instancia diferente), puede seleccionar otro tipo de instancia. Luego intente con **ml.m5.8xlarge**.\n",
    "\n",
    "Si aparece el mensaje **An error occurred loading this view** (Se produjo un error al cargar esta vista), cierre la pestaña **untitled.flow** y vuelva a abrir el archivo del flujo desde el navegador de archivos.\n",
    "\n",
    "**Sugerencia 1**: hay muchas formas de explorar el conjunto de datos. Abra un flujo en SageMaker Data Wrangler para comenzar. Necesitará importar **claims.csv** y **customers.csv** a SageMaker Data Wrangler desde el bucket de S3 que contiene **databucket-** en el nombre.\n",
    "\n",
    "**Sugerencia 2**: para importar una segunda tabla, regrese a su **Data flow** (Flujo de datos), luego seleccione la pestaña **Import** (Importar) para importar otro conjunto de datos.\n",
    "\n",
    "**Sugerencia 3**: **Get data insights** (Obtener información de datos) y **Add analysis** (Agregar análisis) son dos maneras de explorar datos en SageMaker Data Wrangler. Después de revisar algunos gráficos de muestra de sus datos, puede utilizar otras herramientas de trazado en el cuaderno para analizar los datos si lo desea. Se han instalado las bibliotecas **plt** y **sns**. No dude en utilizar cualquier herramienta de análisis que conozca para explorar el conjunto de datos.  \n",
    "\n",
    "**Sugerencia 4**: intente unir dos tablas con la función **Join** (Unir) en **policy_id**. A continuación, ejecute otro reporte de información. Puede utilizar la función de unión **Inner** (Interna) para estas tablas.\n",
    "\n",
    "¿Obtuvo resultados más significativos con un conjunto de datos unidos?\n",
    "\n",
    "Para conocer los pasos detallados sobre cómo explorar un conjunto de datos en SageMaker Studio, consulte <a href=\"#task1-2-1\" target=\"_self\">**Explorar un conjunto de datos en SageMaker Studio (Tarea 1.2)**</a> en la sección *Apéndice*.\n",
    "\n",
    "Para conocer los pasos detallados sobre cómo explorar un conjunto de datos en el cuaderno, consulte <a href=\"#task1-2-2\" target=\"_self\">**Explorar un conjunto de datos en el cuaderno (Tarea 1.2)**</a> en la sección *Apéndice*.\n",
    "\n",
    "Una vez que haya procesado sus datos con SageMaker Data Wrangler, explorado el conjunto de datos e identificado los pasos de procesamiento que quiere realizar, habrá completado esta tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_1_2_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 1.3: utilizar un trabajo de procesador de SageMaker Clarify para ejecutar un informe de sesgos\n",
    "\n",
    "<a id=\"task1-3-continue\"></a>\n",
    "\n",
    "Utilice SageMaker Clarify para ejecutar un informe de sesgos previo al entrenamiento para detectar desequilibrios de clase en los datos. Utilice un flujo de SageMaker Data Wrangler para ejecutar el informe de sesgos en SageMaker Studio.\n",
    "1. Comience por unir las dos tablas.\n",
    "\n",
    "- Unir: realizar una unión **Interna** de **claims.csv** y **customers.csv** en **policy_id**.\n",
    "\n",
    "**Sugerencia 1**: para crear un informe de sesgos previo al entrenamiento, agregar un nuevo análisis al flujo de SageMaker Data Wrangler y seleccionar **Bias Report** (Informe de sesgos) en **Analysis type** (Tipo de análisis).\n",
    "\n",
    "**Sugerencia 2**: puede ejecutar el informe de sesgos varias veces y seleccionar diferentes funciones para analizar cada vez.\n",
    "\n",
    "Para conocer los pasos detallados sobre cómo unir tablas con SageMaker Data Wrangler, consulte <a href=\"#task1-3-1\" target=\"_self\">**Unión de tablas en SageMaker Studio (Tarea 1.3)**</a> en la sección *Apéndice*.\n",
    "\n",
    "Para conocer los pasos detallados sobre cómo ejecutar un informe de sesgos previo al entrenamiento, consulte <a href=\"#task1-3-2\" target=\"_self\">**Ejecutar un informe de sesgo previo al entrenamiento (Tarea 1.3)**</a> en la sección *Apéndice*.\n",
    "\n",
    "Una vez que haya ejecutado el informe de sesgos previo al entrenamiento y revisado el informe, habrá completado esta tarea."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 1.4: preparar los datos\n",
    "\n",
    "<a id=\"task1-4-continue\"></a>\n",
    "\n",
    "Prepare su conjunto de datos con SageMaker Data Wrangler. Céntrese en las siguientes transformaciones, pero no dude en incluir otras:\n",
    "\n",
    "- Codificación categórica (Codificación one-hot): **authorities_contacted**, **collision_type**, **customer_gender**, **driver_relationship**, **incident_type** y **policy_state**.\n",
    "- Codificación ordinal: **customer_education**, **policy_liability**, **incident_severity** y **police_report_available**.\n",
    "- Analizar columna como tipo: **vehicle_claim** y **total_claim_amount** de **Float** (Flotante) a **Long** (Larga).\n",
    "- Administrar columnas (Eliminar columna): **customer_zip**.\n",
    "- Administrar columnas (Mover columna): **fraud** (usar **Move to start** [Mover para comenzar]).\n",
    "- Administrar columnas (Cambiar nombre de columna): reemplazar el símbolo **/** de **collision_type_N/A** y **driver_relationship_N/A** con un **_**.\n",
    "- Administrar columnas (Cambiar nombre de columna): cambiar el nombre **policy_id_0** a **policy_id**.\n",
    "\n",
    "**Sugerencia 1**: una la tabla **claims** a las tablas **customers** con una unión en SageMaker Data Wrangler. \n",
    "\n",
    "**Sugerencia 2**: una las dos tablas en la columna **policy_id**.\n",
    "\n",
    "**Sugerencia 3**: agregue las transformaciones con la opción **Add transform (Agregar transformación)**.\n",
    "\n",
    "¿Qué transformaciones cree que afectan más al entrenamiento de modelos?\n",
    "\n",
    "Para conocer los pasos detallados sobre cómo preparar los datos con SageMaker Data Wrangler, consulte <a href=\"#task1-4-1\" target=\"_self\">**Preparar datos en SageMaker Data Wrangler (Tarea 1.4)**</a> en la sección *Apéndice*.\n",
    "\n",
    "Si desea importar un conjunto de datos procesados de ejemplo, consulte <a href=\"#task1-4-2\" target=\"_self\">**Importar un conjunto de datos procesados de ejemplo (Tarea 1.4)**</a> en la sección *Apéndice*. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafío 2: crear grupos de funciones en SageMaker Feature Store\n",
    "\n",
    "Ahora que ya ha procesado el conjunto de datos, cree funciones y grupos de funciones para utilizar en análisis futuros. Utilice SageMaker Feature Store para almacenarlas en un grupo de funciones y consultarlas cuando entrene su modelo.\n",
    "\n",
    "Para completar esta tarea, realice todas las subtareas siguientes:\n",
    "\n",
    "1. Exportar funciones al almacén de funciones de SageMaker.\n",
    "2. Consultar el grupo de funciones en un almacén sin conexión con Amazon Athena.\n",
    "\n",
    "El tiempo estimado para completar este desafío es de *30* minutos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.1: exportar funciones al almacén de funciones de SageMaker\n",
    "\n",
    "<a id=\"task2-1-continue\"></a>\n",
    "\n",
    "Utilice la función **Export to** (Exportar a) de SageMaker Data Wrangler para crear un cuaderno de Jupyter personalizado. El cuaderno crea una definición de función y un grupo de funciones. El cuaderno ingiere los registros en el grupo de funciones. En el cuaderno, complete los siguientes pasos:\n",
    "\n",
    "- Establezca los valores de record (registro) y event_time (hora_evento).\n",
    "- Ejecute las celdas del cuaderno para crear un grupo de funciones.\n",
    "- Ejecute las celdas del cuaderno para confirmar el grupo de funciones creado.\n",
    "- Ejecute las celdas del cuaderno para ingerir los registros en el grupo de funciones.\n",
    "\n",
    "**Sugerencia 1**: todos estos pasos se pueden completar en SageMaker Studio. Cuando haya finalizado de crear su grupo de funciones, puede regresar a este cuaderno para continuar con la Tarea 2.2.\n",
    "\n",
    "**Sugerencia 2**: agregue una transformación personalizada para crear la columna **event_time**. \n",
    "\n",
    "**Sugerencia 3**: el código para agregar la transformación personalizada es el siguiente:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import lit\n",
    "date_time = datetime.date.today()\n",
    "\n",
    "df = df.withColumn(\"event_time\", lit(time.mktime(date_time.timetuple())))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Sugerencia 4**: al final del flujo de SageMaker Data Wrangler, seleccione el ícono **+**, luego la opción **Export to** (Exportar a) y finalmente **SageMaker Feature Store** (Almacén de funciones de SageMaker) (a través del cuaderno de Jupyter).\n",
    "\n",
    "**Sugerencia 5**: para desconectar el almacén en línea puede cambiar el valor **enable_online_store** de **True** a **False**.\n",
    "\n",
    "¿Cómo utilizaría SageMaker Feature Store para almacenar y consultar sus registros para el entrenamiento, a diferencia de la inferencia?\n",
    "\n",
    "Para conocer los pasos detallados sobre cómo crear un grupo de funciones con la opción **Export to** (Exportar a), consulte <a href=\"#task2-1\" target=\"_self\">**Crear un grupo de funciones con la opción Export to (Tarea 2.1)**</a> en la sección *Apéndice*. \n",
    "\n",
    "Una vez que haya creado un grupo de funciones e ingerido los datos en él, habrá completado esta tarea."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 2.2: consultar el grupo de funciones en un almacén sin conexión con Athena\n",
    "\n",
    "<a id=\"task2-2-continue\"></a>\n",
    "\n",
    "Utilice Athena para extraer registros de un almacén de datos sin conexión. En el próximo desafío puede dividir estos registros en conjuntos de entrenamiento, prueba y validación.\n",
    "\n",
    "Utilice la celda de código proporcionada a continuación para hacer las llamadas a la API de Amazon Athena. Puede utilizar la consola de Amazon Athena para hacer la consulta, pero eso queda fuera del alcance de este laboratorio.\n",
    "\n",
    "**Sugerencia 1**: puede crear una consulta en Athena con **feature_group.athena_query()** y obtener el nombre de la tabla con **query.table_name**.\n",
    "\n",
    "**Sugerencia 2**: puede ejecutar una consulta con **query.run(query_string=query_string, output_location=output_location)** y leer el valor obtenido como un marco de datos con **query.as_dataframe()**.\n",
    "\n",
    "¿Cómo podría utilizar **event_time** para hacer un seguimiento de las funciones que se producen en diferentes puntos de la línea de tiempo de su conjunto de datos?\n",
    "\n",
    "Para conocer los pasos detallados sobre cómo extraer registros de un almacén de datos sin conexión con Athena, consulte <a href=\"#task2-2\" target=\"_self\">**Extraer registros de un almacén de datos sin conexión con Athena (Tarea 2.2)**</a> en la sección *Apéndice*.\n",
    "\n",
    "Una vez que haya guardado la consulta de Athena como una variable de marco de datos, habrá completado esta tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_2_2_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafío 3: entrenar el modelo\n",
    "\n",
    "Su modelo está listo para el entrenamiento. Divida los datos en conjuntos de datos de entrenamiento, prueba y validación para entrenar al modelo. \n",
    "\n",
    "SageMaker Autopilot se ejecutó en estos datos antes y obtuvo una **F1** de **0,616**, una **exactitud** de **0,978**, una **AUC** de **0,918** y una **exhaustividad** de **0,539**. Para conocer más sobre estás métricas que produce SageMaker Autopilot, consulte el documento *piloto-automático-métricas-validación* en la sección de *Recursos adicionales* para obtener más información.\n",
    "\n",
    "Mientras realiza el entrenamiento y el ajuste, trabaje para alcanzar o superar las puntuaciones de SageMaker Autopilot y confirmar que el depurador de Amazon SageMaker no informe errores.\n",
    "\n",
    "Para completar esta tarea, realice las siguientes subtareas:\n",
    "\n",
    "- Cree un experimento y una ejecución.\n",
    "- Divida los datos en conjuntos de datos de entrenamiento, prueba y validación.\n",
    "- Configure y ejecute un trabajo de entrenamiento.\n",
    "    - Ejecute un trabajo de entrenamiento básico.\n",
    "    - Ejecute un trabajo de entrenamiento básico con el depurador de SageMaker habilitado y analice los informes (opcional).\n",
    "- Realice ajustes de hiperparámetros.\n",
    "\n",
    "El tiempo estimado para completar este desafío es de *110* minutos.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 3.1: dar nombre a un experimento y una ejecución\n",
    "\n",
    "<a id=\"task3-1-continue\"></a>\n",
    "\n",
    "Establezca las variables para dar nombre al experimento y a las ejecuciones. \n",
    "Un experimento requiere un **experiment_name**, un **run_name** y una **description**. \n",
    "\n",
    "Para conocer los pasos detallados sobre cómo crear las variables, consulte <a href=\"#task3-1\" target=\"_self\">**Dar nombre a un experimento y una ejecución (Tarea 3.1)**</a> en la sección *Apéndice*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_3_1_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 3.2: dividir los datos en conjuntos de datos de entrenamiento, prueba y validación\n",
    "\n",
    "<a id=\"task3-2-continue\"></a>\n",
    "\n",
    "Utilice las funciones de la consulta en SageMaker Feature Store y divídalas en conjuntos de datos de entrenamiento, prueba y validación.\n",
    "\n",
    "**Sugerencia 1**: utilice **np.split** para dividir los conjuntos de datos en tres particiones.\n",
    "\n",
    "**Sugerencia 2**: utilice **to_csv** para crear archivos CSV y utilice **S3Uploader.upload** para agregar los archivos a Amazon S3.\n",
    "\n",
    "**Sugerencia 3**: el producto final de la división debería ser una variable **data_inputs** con valores para **train** (entrenamiento) y **validation** (validación).\n",
    "\n",
    "Para conocer los pasos detallados sobre cómo dividir los datos en conjuntos de datos de entrenamiento, prueba y validación, consulte <a href=\"#task3-2\" target=\"_self\">**Dividir datos en conjuntos de datos de entrenamiento, prueba y validación (Tarea 3.2)**</a> en la sección *Apéndice*. \n",
    "\n",
    "Una vez que haya dividido los datos en conjuntos de datos de entrenamiento, prueba y validación, habrá completado esta tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_3_2_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 3.3: configurar y ejecutar un trabajo de entrenamiento\n",
    "\n",
    "<a id=\"task3-3-continue\"></a>\n",
    "\n",
    "Comience su primer trabajo de entrenamiento, configure el contenedor, un estimador y los hiperparámetros. A continuación, entrene el modelo con **fit()**. Si desea examinar informes más detallados, habilite el depurador de SageMaker con **DebuggerHookConfig**.\n",
    "\n",
    "**Sugerencia 1**: utilice el contenedor **XGBoost** con la versión **1.5-1**.\n",
    "\n",
    "**Sugerencia 2**: para comenzar, configure los hiperparámetros **eta**, **gamma**, **max_depth**, **min_child_weight**, **num_round**, **objective** y **subsample**.\n",
    "\n",
    "**Sugerencia 3**: utilice **data_inputs** que ha creado antes en el Desafío 1 como valor **inputs** para su trabajo de entrenamiento.\n",
    "\n",
    "**Sugerencia 4**: para configurar un trabajo de entrenamiento puede ajustar inputs y experiment_config. Experiment_config debería contener una **sagemaker_session**, un **run_name** y un **experiment_name**.\n",
    "\n",
    "**Sugerencia 5**: si desea utiliza el depurador de SageMaker, configure el **DebuggerHookConfig**, el **ProfilerConfig** y el objeto del depurador **rule**.\n",
    "\n",
    "¿Qué hiperparámetros tienen más probabilidades de causar un mayor impacto en el rendimiento y la exactitud de su modelo? ¿Qué hiperparámetros piensa ajustar primero?\n",
    "\n",
    "Para conocer los pasos detallados sobre cómo configurar y ejecutar un trabajo de entrenamiento básico, consulte <a href=\"#task3-3-1\" target=\"_self\">**Configurar y ejecutar un trabajo de entrenamiento básico (Tarea 3.3)**</a> en la sección *Apéndice*.\n",
    "\n",
    "Para conocer los pasos detallados sobre cómo configurar y ejecutar un trabajo de entrenamiento básico con el depurador habilitado y analizar los informes, consulte <a href=\"#task3-3-2\" target=\"_self\">**Configurar y ejecutar un trabajo de entrenamiento básico con el depurador de SageMaker habilitado y analizar los informes (Tarea 3.3)**</a> en la sección *Apéndice*.\n",
    "\n",
    "Una vez que haya finalizado uno o más trabajos de entrenamiento, habrá completado esta tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_3_3_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 3.4: ajuste de hiperparámetros\n",
    "\n",
    "<a id=\"task3-4-continue\"></a>\n",
    "\n",
    "Ahora que ya ha finalizado un trabajo de entrenamiento y lo ha analizado, ajuste los rangos de los hiperparámetros en función de sus hallazgos y ejecute más trabajos de entrenamiento para mejorar el modelo.\n",
    "\n",
    "**Sugerencia 1**: para comenzar, establezca los rangos de los hiperparámetros **alpha**, **eta**, **max_depth**, **min_child_weight** y **num_round**.\n",
    "\n",
    "**Sugerencia 2**: cuando ejecute **HyperparameterTuner**, asegúrese de configurar **objective_metric_name** y **objective_type** en función de sus hallazgos.\n",
    "\n",
    "**Sugerencia 3**: para verificar que ha mejorado los resultados de SageMaker Autopilot, abra el menú **Experiments and runs** (Experimentos y ejecuciones) en **SageMaker resources** (Recursos de SageMaker). Dentro de su ejecución, vea las **Metrics** (Métricas). **ObjectiveMetric** (Métrica objetivo) debería ser mayor que la puntuación de **F1** de **0,616** y **validation:auc** debería tener un **Final value** (Valor final) mayor a la puntuación de SageMaker Autopilot de **0,918**.\n",
    "\n",
    "Cuando ajustó los hiperparámetros, ¿cuál fue el que más mejoró el rendimiento del modelo?\n",
    "\n",
    "Para conocer los pasos detallados sobre cómo configurar los rangos de los hiperparámetros de entrenamiento, consulte <a href=\"#task3-4\" target=\"_self\">**Configurar los rangos de los hiperparámetros de entrenamiento (Tarea 3.4)**</a> en la sección *Apéndice*.\n",
    "\n",
    "Una vez que haya configurado los rangos de los hiperparámetros de entrenamiento y haya comenzado más trabajos de entrenamiento, habrá completado esta tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_3_4_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafío 4: evaluar el sesgo del modelo\n",
    "\n",
    "Ahora que ha entrenado el modelo, evalúelo con Amazon SageMaker Clarify. Si encuentra algún problema, puede eliminar el desequilibrio detectado y volver a entrenar el modelo.\n",
    "\n",
    "Para completar esta tarea, realice las siguientes subtareas:\n",
    "\n",
    "- Cree un modelo a partir del trabajo de entrenamiento.\n",
    "- Cree una configuración del modelo de SageMaker Clarify.\n",
    "- Cree una configuración de sesgos de SageMaker Clarify.\n",
    "- Utilice un trabajo de procesador de SageMaker Clarify para ejecutar informes de sesgos, datos y modelos.\n",
    "- Elimine el desequilibrio detectado con SageMaker Clarify (opcional).\n",
    "- Vuelva a entrenar el modelo (opcional).\n",
    "\n",
    "El tiempo estimado para completar este desafío es de *80* minutos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 4.1: crear un modelo a partir del trabajo de entrenamiento\n",
    "\n",
    "<a id=\"task4-1-continue\"></a>\n",
    "\n",
    "Cree un modelo XGBoost, llamando **create_model** con el **model_name**, **role** y **container_def** que usted defina.\n",
    "\n",
    "**Sugerencia 1**: llame a **xgb.create_model()** y seleccione un nombre para su modelo.\n",
    "\n",
    "**Sugerencia 2**: utilice su sesión y llame a **create_model**, indicando el **model_name**, **role** y **container_def**.\n",
    "\n",
    "Para conocer los pasos detallados sobre cómo crear un modelo, consulte <a href=\"#task4-1\" target=\"_self\">**Crear un modelo (Tarea 4.1)**</a> en la sección *Apéndice*.\n",
    "\n",
    "Una vez que haya creado un modelo, habrá completado esta tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_4_1_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 4.2: crear una configuración del modelo de SageMaker Clarify\n",
    "\n",
    "<a id=\"task4-2-continue\"></a>\n",
    "\n",
    "Cree una configuración del modelo de SageMaker Clarify con **SageMakerClarifyProcessor**.\n",
    "\n",
    "**Sugerencia 1**: configure **instance_count** e **instance_type**.\n",
    "\n",
    "**Sugerencia 2**: utilice el **rol** y la **sesión** creados al comienzo del laboratorio del curso de culminación.\n",
    "\n",
    "Para conocer los pasos detallados sobre cómo crear una configuración del modelo de SageMaker Clarify, consulte <a href=\"#task4-2\" target=\"_self\">**Crear una configuración del modelo de SageMaker Clarify (Tarea 4.2)**</a> en la sección *Apéndice*.\n",
    "\n",
    "Una vez que haya creado una configuración del modelo de SageMaker Clarify, habrá completado esta tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_4_2_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 4.3: crear una configuración de sesgos de SageMaker Clarify\n",
    "\n",
    "<a id=\"task4-3-continue\"></a>\n",
    "\n",
    "Cree una configuración de datos, una configuración del modelo, una configuración de etiquetas y una configuración de sesgos.\n",
    "\n",
    "**Sugerencia 1**: comience con **DataConfig** y configure la ruta de entrada, la ruta de salida, los encabezados y el tipo de conjunto de datos.\n",
    "\n",
    "**Sugerencia 2**: a continuación, cree un **ModelConfig** y seleccione el tipo de contenido y de aceptación, el nombre del modelo, el tipo de instancia y el recuento de instancias.\n",
    "\n",
    "**Sugerencia 3**: luego, cree un **ModelPredictedLabelConfig** y configure el umbral de probabilidad.\n",
    "\n",
    "**Sugerencia 4**: finalmente, cree un **BiasConfig** y configure el valor de la etiqueta o umbral, el nombre de la faceta y los valores de las facetas o umbrales.\n",
    "\n",
    "¿Qué facetas desea explorar primero en su informe de sesgos? ¿Existen funciones especialmente susceptibles a los sesgos?\n",
    "\n",
    "Para conocer los pasos detallados sobre cómo crear una configuración de sesgos de SageMaker Clarify, consulte <a href=\"#task4-3\" target=\"_self\">**Crear una configuración de sesgos de SageMaker Clarify (Tarea 4.3)**</a> en la sección *Apéndice*.\n",
    "\n",
    "Una vez que haya creado la configuración de sesgos de SageMaker Clarify, habrá completado esta tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_4_3_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 4.4: utilizar un trabajo de procesador de SageMaker Clarify para ejecutar informes de sesgos, datos y modelos\n",
    "\n",
    "<a id=\"task4-4-continue\"></a>\n",
    "\n",
    "Ya ha elegido todas sus configuraciones para los informes de sesgos, datos y modelos. Ahora, ejecute los informes.\n",
    "\n",
    "**Sugerencia 1**: introduzca los valores de **data_config**, **bias_config**, **model_predicted_label_config** y **model_config** para **run_bias**.\n",
    "\n",
    "**Sugerencia 2**: necesita configurar **pre_training_methods** y **post_training_methods**.\n",
    "\n",
    "Para conocer los pasos detallados sobre cómo ejecutar informes de sesgos, datos y modelos con SageMaker Clarify, consulte <a href=\"#task4-4\" target=\"_self\">*Ejecutar informes de sesgos, datos y modelos con SageMaker Clarify (Tarea 4.4)*</a> en la sección *Apéndice*.\n",
    "\n",
    "Una vez que haya utilizado un trabajo de procesador de SageMaker Clarify para ejecutar informes de sesgos, datos y modelos, habrá completado esta tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_4_4_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 4.5: eliminar el desequilibrio detectado con SageMaker Clarify (opcional)\n",
    "\n",
    "<a id=\"task4-5-continue\"></a>\n",
    "\n",
    "Existen muchas formas de eliminar el desequilibrio detectado con SageMaker Clarify. Utilice cualquier método que conozca. En este laboratorio, se proporciona un ejemplo de Técnica de sobremuestreo sintético de minorías (Synthetic Minority Over-sampling Technique, SMOTE) que elimina el sesgo de las columnas.\n",
    "\n",
    "**Sugerencia 1**: cuando haya terminado de eliminar el desequilibrio y desee volver a realizar la prueba, cree un nuevo marco de datos con las nuevas muestras. En la siguiente tarea cargará un nuevo archivo CVS.\n",
    "\n",
    "Para conocer los pasos detallados sobre cómo eliminar el desequilibrio, consulte <a href=\"#task4-5\" target=\"_self\">*Eliminar el desequilibrio (Tarea 4.5)**</a> en la sección *Apéndice*.\n",
    "\n",
    "Una vez que haya eliminado cualquier desequilibrio detectado con SageMaker Clarify, habrá completado esta tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_4_5_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 4.6: volver a entrenar el modelo (opcional)\n",
    "\n",
    "<a id=\"task4-6-continue\"></a>\n",
    "\n",
    "Cargue el nuevo archivo en Amazon S3. A continuación, cree un nuevo estimador y repita en entrenamiento con los nuevos datos.\n",
    "\n",
    "**Sugerencia 1**: utilice **s3_client.upload_file** para cargar el nuevo archivo en el bucket.\n",
    "\n",
    "**Sugerencia 2**: utilice **xgboost_starter_script.py** y llame a **XGBoost**. Luego, repita el entrenamiento con los nuevos datos.\n",
    "\n",
    "¿El nuevo modelo entrenado obtuvo una puntuación F1 más alta? Si utilizó el depurador de SageMaker, ¿fue capaz de resolver todos los problemas detectados?\n",
    "\n",
    "Para conocer los pasos detallados sobre cómo volver a entrenar el modelo, consulte <a href=\"#task4-6\" target=\"_self\">*Volver a entrenar el modelo (Tarea 4.6)*</a> en la sección *Apéndice*.\n",
    "\n",
    "Una vez que haya vuelto a entrenar el modelo, habrá completado esta tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_4_6_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafío 5: transformación por lotes\n",
    "\n",
    "Su modelo está listo para la implementación. Utilice un trabajo de transformación por lotes con registros por lotes y vea los datos de predicción y exactitud en Amazon S3. A continuación, realice una limpieza de algunas de sus instancias de SageMaker.\n",
    "\n",
    "Para completar esta tarea, realice las siguientes subtareas:\n",
    "\n",
    "- Cree un trabajo de transformación por lotes para su modelo.\n",
    "- Vea los datos de predicción en Amazon S3.\n",
    "- Realice una limpieza de las instancias de SageMaker (opcional).\n",
    "\n",
    "El tiempo estimado para completar este desafío es de *40* minutos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 5.1: crear un trabajo de transformación por lotes para su modelo\n",
    "\n",
    "<a id=\"task5-1-continue\"></a>\n",
    "\n",
    "Cree un trabajo de transformación por lotes mediante el uso de **transformer** en el estimador del modelo. A continuación, ejecute el trabajo por lotes.\n",
    "\n",
    "**Sugerencia 1**: utilice el transformador y configure **instance_count**, **instance_type**, **strategy**, **assemble_with** y **output_path**.\n",
    "\n",
    "**Sugerencia 2**: envíe los datos de la prueba, que se encuentran en **test_path** al punto de enlace y aguarde los resultados.\n",
    "\n",
    "Para conocer los pasos detallados sobre cómo crear un trabajo de transformación por lotes, consulte <a href=\"#task5-1\" target=\"_self\">*Crear un trabajo de transformación por lotes (Tarea 5.1)*</a> en la sección *Apéndice*.\n",
    "\n",
    "Una vez que haya creado un trabajo de transformación por lotes y lo haya ejecutado con un conjunto de registros, habrá completado esta tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_5_1_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 5.2: ver los datos de predicción en Amazon S3\n",
    "\n",
    "<a id=\"task5-2-continue\"></a>\n",
    "\n",
    "Cuando su trabajo de transformación por lotes esté completo, lea los datos en Amazon S3. \n",
    "\n",
    "**Sugerencia 1**: puede copiar los datos de la salida del transformador mediante el uso de **%aws s3 cp --recursive $transformer.output_path ./**\n",
    "\n",
    "**Sugerencia 2**: cuando tenga los datos, puede visualizarlos con **%head test_data_batch.csv.out**\n",
    "\n",
    "Eche un vistazo a las predicciones. ¿Hay alguna predicción que sorprenda?\n",
    "\n",
    "Para conocer los pasos detallados sobre cómo ver los datos de predicción de un trabajo de transformación por lotes, consulte <a href=\"#task5-2\" target=\"_self\">*Ver los datos de predicción de un trabajo de transformación por lotes (Tarea 5.2)*</a> en la sección *Apéndice*.\n",
    "\n",
    "Una vez que haya visualizado los datos de la predicción del trabajo de transformación por lotes, habrá completado esta tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_5_2_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 5.3: realizar una limpieza de las instancias de SageMaker (opcional)\n",
    "\n",
    "Para mantener los costos bajos, la práctica recomendada es eliminar las instancias que ya no utiliza. Puede eliminar rápidamente las instancias con SageMaker Studio. Tómese un momento para abrir su lista de recursos actuales en SageMaker Studio y cierre las instancias restantes.\n",
    "\n",
    "Si planea completar la siguiente tarea de canalización, **deje la instancia del cuaderno en ejecución**.\n",
    "\n",
    "**Sugerencia 1**: para ver una lista de las instancias en ejecución, seleccione el ícono **Running Terminals and Kernels** (Terminales y kernels en ejecución) en SageMaker Studio.\n",
    "\n",
    "**Sugerencia 2**: puede utilizar el ícono **Shut down** (Cerrar) para detener una instancia.\n",
    "\n",
    "<a id=\"task5-3-continue\"></a>\n",
    "\n",
    "Para conocer los pasos detallados sobre cómo realizar una limpieza de las instancias de SageMaker en SageMaker Studio, consulte <a href=\"#task5-3\" target=\"_self\">** Realizar una limpieza de las instancias de SageMaker en SageMaker Studio (Tarea 5.3)**</a> en la sección *Apéndice*.\n",
    "\n",
    "Una vez que haya detenido todas las instancias de SageMaker en SageMaker Studio, habrá completado esta tarea."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafío 6: crear una canalización automatizada (opcional)\n",
    "\n",
    "Ahora que ya ha utilizado el SDK para Python de Amazon SageMaker y Amazon SageMaker Studio para el flujo de trabajo de machine learning (ML), utilice las canalizaciones de SageMaker para escalar su flujo de trabajo. Proceda a través del script de canalización proporcionado en el entorno de laboratorio para completar este desafío. \n",
    "\n",
    "- Cree los pasos de la canalización.\n",
    "    - Haga una consulta de los datos procesados desde SageMaker Feature Store.\n",
    "    - Entrene y ajuste el modelo.\n",
    "    - Evalúe el modelo entrenado.\n",
    "    - Realice un trabajo de transformación por lotes.\n",
    "    - Registre un modelo.\n",
    "    - Evalúe el entrenamiento del modelo con SageMaker Clarify.\n",
    "- Defina y comience una canalización.\n",
    "- Vea el seguimiento de linaje de ML.\n",
    "\n",
    "El tiempo estimado para completar este desafío es de *120* minutos.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 6.1: configurar una canalización\n",
    "\n",
    "<a id=\"task6-1-continue\"></a>\n",
    "\n",
    "Utilice una plantilla de canalización y configure sus entradas y salidas. Cuando las configuraciones estén listas, ejecute la canalización. Su canalización puede incluir una amplia gama de pasos. A continuación hay una lista sugerida de los pasos para la configuración:\n",
    "- **AutoModelProcess**: un paso de **Procesamiento** que extrae el archivo .csv y lo divide en conjuntos de datos de entrenamiento, prueba y validación.\n",
    "- **AutoHyperParameterTuning**: un paso de **Ajuste** que utiliza una amplia gama de hiperparámetros y ajusta el modelo.\n",
    "- **AutoEvalBestModel**: un paso de **Procesamiento** que crea un informe de evaluación para describir al mejor modelo.\n",
    "- **CheckAUCScoreAutoEvaluation**: un paso de **Condición** que evalúa los modelos basados en una métrica de evaluación. \n",
    "- **AutoCreateModel**: un paso de **Modelo** que crea el modelo.\n",
    "- **RegisterAutoModel-RegisterModel**: un paso de **Registro de modelo** que registra el modelo.\n",
    "- **AutoModelConfigFile**: un paso de **Procesamiento** que crea un informe de sesgos.\n",
    "- **AutoTransform**: un paso de **Transformación** que ejecuta un trabajo de transformación por lotes.\n",
    "- **ClarifyProcessingStep**: un paso de **Procesamiento** que ejecuta un trabajo de SageMaker Clarify.\n",
    "\n",
    "**Sugerencia 1**: hay muchos pasos de canalización para escoger. Para conocer más sobre los pasos de canalización y ver un código de muestra para cada paso, consulte el documento *Crear y administrar los pasos de canalización* en la sección de *Recursos adicionales* para obtener más información.\n",
    "\n",
    "**Sugerencia 2**: comience un paso de **Procesamiento** para introducir sus datos. A continuación, cree un paso de **Ajuste** para ajustar el modelo. Luego, cree un paso de **Modelo** para crear su modelo.\n",
    "\n",
    "**Sugerencia 3**: los pasos detallados contienen una solución de muestra e incluyen los pasos para crear informes de evaluación, un informe de sesgos, ejecutar un trabajo de transformación por lotes y ejecutar un trabajo en SageMaker Clarify. \n",
    "\n",
    "Para conocer los pasos detallados sobre cómo configurar una canalización, consulte <a href=\"#task6-1\" target=\"_self\">*Configurar una canalización (Tarea 6.1)*</a> en la sección *Apéndice*.\n",
    "\n",
    "Una vez que haya configurado la canalización e iniciado un trabajo de canalización, habrá completado esta tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_6_1_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 6.2: supervisar la canalización\n",
    "\n",
    "<a id=\"task6-2-continue\"></a>\n",
    "\n",
    "Supervise la canalización mientras está en ejecución y revise las entradas y las salidas. \n",
    "\n",
    "**Sugerencia 1**: utilice `RunPipeline.describe()` para describir la canalización que ha creado.\n",
    "\n",
    "**Sugerencia 2**: puede ver los pasos de la canalización en ejecución en la UI de SageMaker Studio. Abra el menú **SageMaker resources** (Recursos de SageMaker), seleccione **Pipelines** (Canalizaciones) y seleccione la canalización que ha creado. \n",
    "\n",
    "Para conocer los pasos detallados sobre cómo supervisar una canalización, consulte <a href=\"#task6-2\" target=\"_self\">*Supervisar una canalización*</a> en la sección *Apéndice*.\n",
    "\n",
    "Una vez que haya terminado de supervisar la canalización, habrá completado esta tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_your_task_6_2_code_here\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Felicitaciones! Ha utilizado un conjunto de datos de seguros de automóviles para detectar reclamaciones posiblemente fraudulentas. Exploró una solución técnica para predecir la probabilidad de que una determinada reclamación de seguro de automóvil sea fraudulenta a través de SageMaker Studio y el SDK para Python de Amazon SageMaker.\n",
    "\n",
    "### Limpieza\n",
    "\n",
    "Ha completado este cuaderno. Para ir a la siguiente parte del laboratorio, haga lo siguiente:\n",
    "\n",
    "- Cierre este archivo de cuaderno.\n",
    "- Regrese a la sesión de laboratorio y continúe con la **Conclusión**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursos adicionales\n",
    "\n",
    "- [Autopilot metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-metrics-validation.html)\n",
    "- [Processing step](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#step-type-processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apéndice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-1\" id=\"task1-1\"></a>\n",
    "\n",
    "### Apéndice: revisar los datos (Tarea 1.1)\n",
    "\n",
    "Para revisar sus datos, especifique la ruta y cargue los datos con Pandas. Tómese un momento para revisar una muestra de ambas tablas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read-csv-files\n",
    "claims_data = pd.read_csv(\"./data/claims_preprocessed.csv\", index_col=0)\n",
    "customers_data = pd.read_csv(\"./data/customers_preprocessed.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#claims-data-sample\n",
    "claims_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customers-data-sample\n",
    "customers_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con este laboratorio, regrese a la <a href=\"#task1-1-continue\" target=\"_self\">Tarea 1.1</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-2-1\" id=\"task1-2-1\"></a>\n",
    "\n",
    "### Apéndice: explorar un conjunto de datos en SageMaker Studio (Tarea 1.2)\n",
    "\n",
    "Comience su exploración de datos en SageMaker Data Wrangler. Importe sus archivos desde su bucket de S3 y analice los datos.\n",
    "\n",
    "El siguiente paso lo llevará a una nueva pestaña en SageMaker Studio. Para seguir esas instrucciones, utilice las siguientes opciones:\n",
    "- **Opción 1**: ver las pestañas una al lado de la otra. Para crear una pantalla con la vista dividida en la ventana principal de SageMaker Studio, puede arrastrar la pestaña **capstone.ipynb** hacia un lado o elegir la pestaña **capstone.ipynb** y luego, desde la barra de herramientas, seleccionar **File** (Archivo) y **New View for Notebook** (Nueva vista para el cuaderno). Ahora puede tener las instrucciones visibles a medida que explora el grupo de funciones.\n",
    "- **Opción 2**: cambiar entre las pestañas de SageMaker Studio para seguir estas instrucciones.\n",
    "\n",
    "1. En el lado izquierdo de SageMaker Studio, seleccione el ícono **Home** (Inicio).\n",
    "1. Expanda la sección **Data** (Datos) y luego seleccione **Data Wrangler**.\n",
    "\n",
    "SageMaker Studio abrirá la pestaña **Data Wrangler**.\n",
    "\n",
    "1. Seleccione **+** y **Create Data Wrangler flow (Crear un flujo de Data Wrangler)**.\n",
    "\n",
    "SageMaker Studio abrirá la pestaña **untitled.flow**.\n",
    "\n",
    "1. Espere a que la pestaña **untitled.flow** termine de cargar, lo que se indica con una barra de progreso. Puede tomar de 2 a 3 minutos.\n",
    "\n",
    "SageMaker Studio abrirá la página **Create connection** (Crear una conexión) en la pestaña *Data Wrangler*.\n",
    "\n",
    "1. Abra el menú contextual (botón derecho del mouse) en la pestaña del archivo **untitled.flow** y, a continuación, seleccione **Rename Data Wrangler Flow...** (Cambiar el nombre del flujo de Data Wrangler...) para cambiar el nombre del archivo.\n",
    "\n",
    "SageMaker Studio abrirá la ventana de mensaje **Rename File** (Cambiar nombre de archivo).\n",
    "\n",
    "1. En **New Name** (Nombre nuevo), ingrese `CapstoneDataWrangler.flow`.\n",
    "1. Seleccione <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">Rename</span> (Cambiar nombre).\n",
    "\n",
    "La ventana de mensaje **Rename File** (Cambiar nombre de archivo) se cerrará.\n",
    "\n",
    "1. En la pestaña **CapstoneDataWrangler.flow**, en la sección **Data sources** (Orígenes de datos), seleccione **Amazon S3**.\n",
    "\n",
    "SageMaker Studio abrirá la página **Import a dataset from S3** (Importar un conjunto de datos de S3) en la pestaña *DataWrangler.flow*.\n",
    "\n",
    "1. En la lista de buckets, abra el bucket que contiene **databucket** en el nombre.\n",
    "1. Seleccione el primer conjunto de datos, un archivo llamado **claims.cvs**.\n",
    "\n",
    "1. Seleccione <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">Import</span> (Importar).\n",
    "\n",
    "1. Regrese a la vista **Data flow** (Flujo de datos), seleccione **&lt; Data flow** (&lt; Flujo de datos), que se encuentra en la sección superior izquierda de la pestaña *CapstoneDataWrangler.flow*.\n",
    "1. Seleccione la pestaña **Import** (Importar), ubicada en la sección superior izquierda de la pestaña *CapstoneDataWrangler.flow*.\n",
    "\n",
    "SageMaker Studio abrirá la página **Create connection** (Crear una conexión).\n",
    "\n",
    "1. En la pestaña **CapstoneDataWrangler.flow**, en la sección **Data sources** (Orígenes de datos), seleccione **Amazon S3**.\n",
    "\n",
    "SageMaker Studio abrirá la página **Import a dataset from S3** (Importar un conjunto de datos de S3) en la pestaña *DataWrangler.flow*.\n",
    "\n",
    "1. En la lista de buckets, abra el bucket que contiene **databucket** en el nombre.\n",
    "1. Seleccione el segundo conjunto de datos, un archivo llamado **customers.csv**.\n",
    "1. Seleccione <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">Import</span> (Importar).\n",
    "\n",
    "1. Regrese a la vista **Data flow** (Flujo de datos), seleccione **&lt; Data flow** (&lt; Flujo de datos), que se encuentra en la sección superior izquierda de la pestaña *CapstoneDataWrangler.flow*.\n",
    "\n",
    "1. En la pestaña de flujo de datos, seleccione el signo **+** que se encuentra junto al ícono **Data types** (Tipos de datos) y seleccione **Get data insights** (Obtener información de datos).\n",
    "\n",
    "1. Cree el informe y explore la información.\n",
    "\n",
    "1. En la pestaña de flujo de datos, seleccione el signo **+** que se encuentra junto al ícono **Data types** (Tipos de datos) y seleccione **Add analysis** (Agregar análisis).\n",
    "\n",
    "1. Cree el análisis y explore los resultados.\n",
    "\n",
    "Utilice cualquier tipo de informe que lo ayude a explorar a fondo los conjuntos de datos. Una vez que haya finalizado, puede continuar con la siguiente tarea.\n",
    "\n",
    "Para continuar con este laboratorio, regrese a la <a href=\"#task1-2-continue\" target=\"_self\">Tarea 1.2</a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-2-2\" id=\"task1-2-2\"></a>\n",
    "\n",
    "### Apéndice: explorar un conjunto de datos en el cuaderno (Tarea 1.2)\n",
    "\n",
    "Existen muchas formas en las que puede explorar los conjuntos de datos. A continuación hay varios ejemplos de pasos para la exploración de datos que puede utilizar. Utilícelos como referencia para comenzar a explorar los aspectos de los conjuntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gender-graph\n",
    "import matplotlib.pyplot as plt\n",
    "customers_data.customer_gender_female.value_counts(normalize=True).plot.bar()\n",
    "plt.xticks([0, 1], [\"Male\", \"Female\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fraud-graph\n",
    "claims_data.fraud.value_counts(normalize=True).plot.bar()\n",
    "plt.xticks([0, 1], [\"Not Fraud\", \"Fraud\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#education-category-graphs\n",
    "educ = customers_data.customer_education.value_counts(normalize=True, sort=False)\n",
    "plt.bar(educ.index, educ.values)\n",
    "plt.xlabel(\"Customer Education Level\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#claim-amount-graph\n",
    "plt.hist(claims_data.total_claim_amount, bins=30)\n",
    "plt.xlabel(\"Total Claim Amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#claims-filed-graph\n",
    "customers_data.num_claims_past_year.hist(density=True)\n",
    "plt.suptitle(\"Number of Claims in the Past Year\")\n",
    "plt.xlabel(\"Number of claims per year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paid-plot-graphs\n",
    "sns.pairplot(\n",
    "    data=customers_data, vars=[\"num_insurers_past_5_years\", \"months_as_customer\", \"customer_age\"]\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fraud-insurers-graph\n",
    "combined_data = customers_data.join(claims_data)\n",
    "sns.lineplot(x=\"num_insurers_past_5_years\", y=\"fraud\", data=combined_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#months-as-customer-graph\n",
    "sns.boxplot(x=customers_data[\"months_as_customer\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customer-age-graph\n",
    "sns.boxplot(x=customers_data[\"customer_age\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fraud-gender-graph\n",
    "combined_data.groupby(\"customer_gender_female\").mean()[\"fraud\"].plot.bar()\n",
    "plt.xticks([0, 1], [\"Male\", \"Female\"])\n",
    "plt.suptitle(\"Fraud by Gender\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation-matrix-graph\n",
    "cols = [\n",
    "    \"fraud\",\n",
    "    \"customer_gender_male\",\n",
    "    \"customer_gender_female\",\n",
    "    \"months_as_customer\",\n",
    "    \"num_insurers_past_5_years\",\n",
    "]\n",
    "corr = combined_data[cols].corr()\n",
    "\n",
    "# plot the correlation matrix\n",
    "sns.heatmap(corr, annot=True, cmap=\"Reds\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load-combined-data\n",
    "combined_data = pd.read_csv(\"./data/claims_customer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove-unnecessary-columns\n",
    "combined_data = combined_data.loc[:, ~combined_data.columns.str.contains(\"^Unnamed: 0\")]\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe-combined-data\n",
    "combined_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate-statistics\n",
    "combined_stats = []\n",
    "\n",
    "for col in combined_data.columns:\n",
    "    combined_stats.append(\n",
    "        (\n",
    "            col,\n",
    "            combined_data[col].nunique(),\n",
    "            combined_data[col].isnull().sum() * 100 / combined_data.shape[0],\n",
    "            combined_data[col].value_counts(normalize=True, dropna=False).values[0] * 100,\n",
    "            combined_data[col].dtype,\n",
    "        )\n",
    "    )\n",
    "\n",
    "stats_df = pd.DataFrame(\n",
    "    combined_stats,\n",
    "    columns=[\"feature\", \"unique_values\", \"percent_missing\", \"percent_largest_category\", \"datatype\"],\n",
    ")\n",
    "stats_df.sort_values(\"percent_largest_category\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap-graph\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "corr_list = [\n",
    "    \"customer_age\",\n",
    "    \"months_as_customer\",\n",
    "    \"total_claim_amount\",\n",
    "    \"injury_claim\",\n",
    "    \"vehicle_claim\",\n",
    "    \"incident_severity\",\n",
    "    \"fraud\",\n",
    "]\n",
    "\n",
    "corr_df = combined_data[corr_list]\n",
    "corr = round(corr_df.corr(), 2)\n",
    "\n",
    "fix, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "mask = np.zeros_like(corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "ax = sns.heatmap(corr, mask=mask, ax=ax, annot=True, cmap=\"OrRd\")\n",
    "\n",
    "ax.set_xticklabels(ax.xaxis.get_ticklabels(), fontsize=10, ha=\"right\", rotation=45)\n",
    "ax.set_yticklabels(ax.yaxis.get_ticklabels(), fontsize=10, va=\"center\", rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con este laboratorio, regrese a la <a href=\"#task1-2-continue\" target=\"_self\">Tarea 1.2</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-3-1\" id=\"task1-3-1\"></a>\n",
    "\n",
    "### Apéndice: unión de tablas en SageMaker Studio (Tarea 1.3)\n",
    "\n",
    "1. Regrese a la vista **Data flow** (Flujo de datos), seleccione **&lt; Data flow** (&lt; Flujo de datos), que se encuentra en la sección superior izquierda de la pestaña *CapstoneDataWrangler.flow*.\n",
    "1. Seleccione el símbolo **+** que se encuentra junto al ícono de **claims.CVS Data types** (Tipos de datos de claims.CVS) y, en el menú contextual, elija **Join** (Unir).\n",
    "\n",
    "SageMaker Data Wrangler mostrará la página **Join** (Unir).\n",
    "\n",
    "1. Seleccione el ícono **customers.csv Data types** (Tipos de datos customers.cvs).\n",
    "1. Seleccione <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">Configure</span> (Configurar).\n",
    "1. En **Join Type** (Tipo de unión), seleccione **Inner** (Interna).\n",
    "1. En la sección **Columns** (Columnas):\n",
    "\n",
    "    - En **Left** (Izquierda), seleccione <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">policy_id</span>.\n",
    "    \n",
    "    - En **Right** (Derecha), seleccione <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">policy_id</span>.\n",
    "\n",
    "1. Seleccione <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">Preview</span> (Previsualizar).\n",
    "\n",
    "1. Seleccione <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">Add</span> (Agregar).\n",
    "\n",
    "Para continuar con este laboratorio, regrese a la <a href=\"#task1-3-continue\" target=\"_self\">Tarea 1.3</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-3-2\" id=\"task1-3-2\"></a>\n",
    "\n",
    "### Apéndice: ejecutar un informe de sesgos previo al entrenamiento (Tarea 1.3)\n",
    "\n",
    "Cree un informe de sesgos de SageMaker Clarify con el flujo de SageMaker Data Wrangler.\n",
    "\n",
    "1. Seleccione la pestaña **CapstoneDataWrangler.flow**.\n",
    "1. Vaya a la vista **Data flow** (Flujo de datos). Si es necesario, seleccione **&lt; Data flow** (&lt; Flujo de datos), que se encuentra en la sección superior izquierda de la pestaña **DataWranglerLab.flow**. \n",
    "1. Seleccione el símbolo **+** que se encuentra junto al ícono **Join** (Unir) y, en el menú contextual, seleccione **Add analysis** (Agregar análisis).\n",
    "1. En la sección *Create analysis** (Crear análisis):\n",
    "\n",
    "- En **Analysis type** (Tipo de análisis), seleccione **Bias Report** (Informe de sesgos).\n",
    "- En **Analysis name** (Nombre del análisis), ingrese “fraud bias by age”.\n",
    "- En **Select the column your model predicts (target)** (Seleccionar la columna que predice su modelo [objetivo]), seleccione **fraud**.\n",
    "- En **Is your predicted column a value or threshold?** (¿La columna de predicción es un valor o un umbral?), seleccione la opción **value**.\n",
    "- En **Predicted value(s)** (Valor[es] predecido[s])**, ingrese **1**.\n",
    "- En **Select the column to analyze for bias** (Seleccionar la columna para analizar sesgos), seleccione **customer_age**.\n",
    "\n",
    "1. Seleccione <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">Check for bias</span> (Buscar sesgos).\n",
    "\n",
    "Una vez que termine el trabajo, vea las métricas obtenidas. Tome nota si hay algún sesgo y planifique los pasos de procesamiento que desee realizar en la columna que ha analizado. \n",
    "\n",
    "1. Para cualquier análisis que desee guardar, seleccione <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">Save</span> (Guardar).\n",
    "\n",
    "Puede repetir estos pasos para cualquier columna que desee analizar en busca de sesgos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con este laboratorio, regrese a la <a href=\"#task1-3-continue\" target=\"_self\">Tarea 1.3</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-4-1\" id=\"task1-4-1\"></a>\n",
    "\n",
    "### Apéndice: preparar datos en SageMaker Data Wrangler (Tarea 1.4)\n",
    "\n",
    "Combine los conjuntos de datos, únalos en SageMaker Data Wrangler con **policy_id**.\n",
    "\n",
    "Con SageMaker Data Wrangler, puede unir datos en cualquier momento del flujo. Puede completar la preparación de los datos en los archivos individuales antes de unirlos, o puede transformar las funciones después de la unión. Un flujo de SageMaker Data Wrangler es flexible.\n",
    "\n",
    "Si no ha unido las tablas en la tarea 1.3, los siguientes lo guiarán a través del proceso.\n",
    "\n",
    "1. Regrese a la vista **Data flow** (Flujo de datos), seleccione **&lt; Data flow** (&lt; Flujo de datos), que se encuentra en la sección superior izquierda de la pestaña *CapstoneDataWrangler.flow*.\n",
    "1. Seleccione el símbolo **+** que se encuentra junto al ícono de **Data types** (Tipos de datos) y, en el menú contextual, seleccione **Join** (Unir).\n",
    "\n",
    "SageMaker Data Wrangler mostrará la página **Join** (Unir).\n",
    "\n",
    "1. Seleccione el segundo ícono **Data types** (Tipos de datos).\n",
    "1. Seleccione <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">Configure</span> (Configurar).\n",
    "1. En **Join Type** (Tipo de unión), seleccione **Inner** (Interna).\n",
    "1. En la sección **Columns** (Columnas):\n",
    "\n",
    "    - En **Left** (Izquierda), seleccione <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">policy_id</span>.\n",
    "    \n",
    "    - En **Right** (Derecha), seleccione <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">policy_id</span>.\n",
    "\n",
    "1. Seleccione <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">Preview</span> (Previsualizar).\n",
    "\n",
    "1. Seleccione <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">Add</span> (Agregar).\n",
    "\n",
    "Con las tablas de datos unidas, transforme los datos combinados.\n",
    "\n",
    "1. Regrese a la vista **Data flow** (Flujo de datos), seleccione **&lt; Data flow** (&lt; Flujo de datos), que se encuentra en la sección superior izquierda de la pestaña *CapstoneDataWrangler.flow*.\n",
    "1. Seleccione el símbolo **+** que se encuentra junto al ícono de **Join** (Unir) y, en el menú contextual, seleccione **Add transform** (Agregar transformación).\n",
    "\n",
    "Este menú permite agregar múltiples transformaciones a los conjuntos de datos. En la sección izquierda del menú de transformación se muestra una vista previa del conjunto de datos.\n",
    "\n",
    "Agregue los siguientes pasos de transformación al flujo de SageMaker Data Wrangler:\n",
    "- Codificación categórica (Codificación one-hot): **authorities_contacted**, **collision_type**, **customer_gender**, **driver_relationship**, **incident_type** y **policy_state** con una estrategia de gestión de valores no válidos **Skip** (Omitir), seleccione el estilo de salida **Columns** (Columnas).\n",
    "- Codificación categórica (Codificación ordinal): **customer_education**, **incident_severity**, **police_report_available** y **policy_liability** con una estrategia de gestión de valores no válidos **Skip** (Omitir).\n",
    "- Analizar columna como tipo: **vehicle_claim** y **total_claim_amount** de **Float** (Flotante) a **Long** (Larga).\n",
    "- Administrar columnas (Drop column [Eliminar columna]): **customer_zip** y **policy_id_1**.\n",
    "- Administrar columnas (Mover columna): **fraud** (usar **Move to start** [Mover para comenzar]).\n",
    "- Administrar columnas (Rename column [Cambiar nombre de columna]): reemplazar el símbolo **/** de **collision_type_N/A** y **driver_relationship_N/A** con un **_**.\n",
    "- Administrar columnas (Rename column [Cambiar nombre de columna]): cambiar el nombre **policy_id_0** a **policy_id**.\n",
    "\n",
    "Si algún nombre de columna tienen un carácter **/**, cambie el nombre de la columna para reemplazar **/** por **_**. Si algún nombre de columna tienen espacio en blanco, cambie el nombre de la columna para reemplazar el espacio en blanco por **_**. Por ejemplo, se debe cambiar el nombre de cualquier columna creada con la codificación one-hot que tenga **N/A** como valor. SageMaker Feature Store no acepta columnas que tengan una **/** o un espacio.\n",
    "\n",
    "Cuando haya transformado sus datos y pueda comenzar a entrenar al modelo, puede continuar con la siguiente tarea. Siempre puede volver regresar a este flujo y hacer cambios de acuerdo a sus hallazgos durante el entrenamiento y el ajuste.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con este laboratorio, regrese a la Tarea <a href=\"#task1-4-continue\" target=\"_self\">1.4</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task1-4-2\" id=\"task1-4-2\"></a>\n",
    "\n",
    "### Apéndice: importar un conjunto de datos procesados de ejemplo (Tarea 1.4)\n",
    "\n",
    "Si se traba durante el procesamiento previo o desea cargar un conjunto de datos que ya se ha procesado, acceda a los datos procesados almacenados en la carpeta de datos del bucket de S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed-data-import\n",
    "s3_client.upload_file(Filename=\"data/claims_customer.csv\", Bucket=bucket, Key=f\"{prefix}/data/raw/claims_customer.csv\")\n",
    "df_processed = pd.read_csv(\"./data/claims_customer.csv\", index_col=None)\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con este laboratorio, regrese a la Tarea <a href=\"#task1-4-continue\" target=\"_self\">1.4</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task2-1\" id=\"task2-1\"></a>\n",
    "\n",
    "### Apéndice: crear un grupo de funciones con la opción Explore to (Explorar a) (Tarea 2.1)\n",
    "\n",
    "SageMaker Data Wrangler puede exportar datos al almacén de funciones de SageMaker. Crea un cuaderno con todo el código necesario para configurar un grupo de funciones e ingerir los datos transformados en el grupo de funciones.\n",
    "\n",
    "1. Seleccione **Add step** (Agregar paso).\n",
    "\n",
    "1. Seleccione **Custom transform** (Transformación personalizada).\n",
    "\n",
    "1. En **Name** (Nombre), ingresar `event_time`. \n",
    "\n",
    "1. Seleccionar **Python (PySpark)** si aún no está seleccionado.\n",
    "\n",
    "1. En **Your custom transform** (Su transformación personalizada), ingrese lo siguiente:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "from pyspark.sql.functions import lit\n",
    "date_time = datetime.date.today()\n",
    "\n",
    "df = df.withColumn(\"event_time\", lit(time.mktime(date_time.timetuple())))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Seleccione <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">Preview</span> (Previsualizar).\n",
    "\n",
    "1. Seleccione <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">Add</span> (Agregar).\n",
    "\n",
    "Esto agrega **event_time** como una columna a su conjunto de datos. SageMaker Feature Store requiere un **event_time** y una identificación única de **record**. Utilice **policy_id** como su identificación de **record**.\n",
    "\n",
    "1. Para regresar al flujo de datos, seleccione el ícono **&lt;Data flow** (&lt;Flujo de datos).\n",
    "\n",
    "1. Seleccione el ícono **+** que se encuentra junto a sus transformaciones en SageMaker Data Wrangler.\n",
    "\n",
    "1. Seleccione **Export to** (Exportar a).\n",
    "\n",
    "1. Seleccione **SageMaker Feature Store (via Jupyter Notebook)** (Almacén de funciones de SageMaker [a través del cuaderno de Jupyter]).\n",
    "\n",
    "Se abrirá un nuevo cuaderno.\n",
    "\n",
    "1. En la primera celda, cambie las siguientes variables:\n",
    "- En **record_identifier_feature_name**, reemplace **None** por `\"policy_id\"`. Si ha unido las tablas de clientes y reclamaciones y no eliminó la segunda columna **policy_id**, es posible que necesite reemplazar **None** por `\"policy_id_0\"`. No cambie el valor **None** después del enunciado **if**.\n",
    "- En **event_time_feature_name**, reemplace **None** por `\"event_time\"`. No cambie el valor **None** después del enunciado **if**.\n",
    "\n",
    "**Expected output** (Resultado esperado): cuando termine de editar la celda, se debería ver como el siguiente ejemplo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_identifier_feature_name = \"policy_id\"\n",
    "if record_identifier_feature_name is None:\n",
    "   raise SystemExit(\"Select a column name as the feature group record identifier.\")\n",
    "\n",
    "event_time_feature_name = \"event_time\"\n",
    "if event_time_feature_name is None:\n",
    "   raise SystemExit(\"Select a column name as the event time feature name.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Recorra todas las celdas para crear una definición de función, un grupo de funciones, e ingerir los datos transformados en el grupo de funciones a través de un trabajo de procesamiento. \n",
    "\n",
    "Cuando las celdas estén completas, su almacén de funciones estará listo para su uso.\n",
    "\n",
    "Para continuar con este laboratorio, regrese a la <a href=\"#task2-1-continue\" target=\"_self\">Tarea 2.1</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task2-2\" id=\"task2-2\"></a>\n",
    "\n",
    "### Apéndice: extraer registros de un almacén de funciones sin conexión con Athena (Tarea 2.2)\n",
    "\n",
    "Configure una consulta de Athena con **athena_query**. A continuación, configure el **query_string**. Finalmente, ejecute la consulta y vea una muestra de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-and-run-athena-query\n",
    "try:\n",
    "    # If there is a feature group, get the name\n",
    "    feature_group_name = sagemaker_session.boto_session.client(\"sagemaker\", region_name=region).list_feature_groups()['FeatureGroupSummaries'][0]['FeatureGroupName']\n",
    "    feature_group = FeatureGroup(name=feature_group_name, sagemaker_session=sagemaker_session)\n",
    "\n",
    "    # Confirm the Athena settings are configured\n",
    "    try:\n",
    "        boto3.client('athena').update_work_group(\n",
    "            WorkGroup='primary',\n",
    "            ConfigurationUpdates={\n",
    "                'EnforceWorkGroupConfiguration':False\n",
    "            }\n",
    "        )\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Configure the query\n",
    "    query = feature_group.athena_query()\n",
    "    table = query.table_name\n",
    "    query_string = f'SELECT * FROM \"{table}\" '\n",
    "    output_location = f\"s3://{sagemaker_session.default_bucket()}/query_results/\"\n",
    "    print(f\"Athena query output location: \\n{output_location}\")\n",
    "\n",
    "    # Run the query\n",
    "    query.run(query_string=query_string, output_location=output_location)\n",
    "    query.wait()\n",
    "    df_feature_store = query.as_dataframe()\n",
    "    \n",
    "    # Wait for data to appear in the feature group\n",
    "    attempts = 0\n",
    "    while len(df_feature_store.index) == 0 and attempts < 30:\n",
    "        print(\"Waiting for feature group to populate...\")\n",
    "        time.sleep(60)\n",
    "        # Rerun the query\n",
    "        query.run(query_string=query_string, output_location=output_location)\n",
    "        query.wait()\n",
    "        df_feature_store = query.as_dataframe()\n",
    "        # Increment the attempts\n",
    "        attempts += 1\n",
    "    if len(df_feature_store.index) != 0:\n",
    "        print(\"The feature group is populated.\")\n",
    "except IndexError as e:\n",
    "    # If there is no feature group, thrown an error\n",
    "    print(\"No feature groups were found. Please create a feature group.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de ejecutar el bloque de código anterior, el registro de consultas de Amazon Athena se guarda en el bucket de Amazon S3 que tiene un nombre que comienza con *sagemaker*. El objeto de la consulta se guarda en un directorio llamado **query_results**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con este laboratorio, regrese a la <a href=\"#task2-2-continue\" target=\"_self\">Tarea 2.2</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task3-1\" id=\"task3-1\"></a>\n",
    "\n",
    "### Apéndice: nombrar un experimento y una ejecución (Tarea 3.1).\n",
    "\n",
    "Para crear un experimento, utilice la biblioteca **sagemaker.experiments.run**. Configure **experiment_name**, **run_name** y **description**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "#create experiment and run-names\n",
    "create_date = strftime(\"%m%d%H%M\")\n",
    "capstone_experiment_name=\"capstone-experiment-{}\".format(create_date)\n",
    "capstone_run_name = \"lab-capstone-run-{}\".format(create_date)\n",
    "\n",
    "# define a run_tag\n",
    "run_tags = [{'Key': 'lab-capstone', 'Value': 'lab-capstone-run'}]\n",
    "\n",
    "# provide a description\n",
    "description=\"Using SM Experiments with the Auto dataset.\"\n",
    "\n",
    "print(f\"Experiment name - {capstone_experiment_name},  run name - {capstone_run_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con este laboratorio, regrese a la <a href=\"#task3-1-continue\" target=\"_self\">Tarea 3.1</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task3-2\" id=\"task3-2\"></a>\n",
    "\n",
    "### Apéndice: dividir datos en conjuntos de datos de entrenamiento, prueba y validación (Tarea 3.2)\n",
    "\n",
    "Para dividir los datos, utilice **np.split** y especifique cómo quiere dividir los datos. A continuación, cree archivos CSV y cárguelos en el bucket de S3. Luego, configure las entradas del entrenamiento. Finalmente, cree la variable **data_inputs**. Utilice data_inputs a lo largo del desafío para especificar los conjuntos de datos de entrenamiento y validación cuando entrene al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-validation-test-split\n",
    "try:\n",
    "    # If there is a feature group, use it\n",
    "    df_feature_store = df_feature_store.iloc[: , :-4]\n",
    "    df_processed_pre_split = df_feature_store\n",
    "    print(\"Using the records from the feature group\")\n",
    "except NameError:\n",
    "    # If there is no feature group, use the processed dataset\n",
    "    df_processed = pd.read_csv(\"./data/claims_customer.csv\", index_col=None)\n",
    "    df_processed_pre_split = df_processed\n",
    "    print(\"Using the processed records from Amazon S3\")\n",
    "\n",
    "# Split the data into train, validation, and test datasets\n",
    "train_data, validation_data, test_data = np.split(\n",
    "    df_processed_pre_split.sample(frac=1, random_state=1729),\n",
    "    [int(0.7 * len(df_processed_pre_split)), int(0.9 * len(df_processed_pre_split))],\n",
    ")\n",
    "\n",
    "# Create the CSV files and upload them to your default bucket\n",
    "train_data.to_csv(\"train_data.csv\", index=False, header=False)\n",
    "validation_data.to_csv(\"validation_data.csv\", index=False, header=False)\n",
    "test_data.to_csv(\"test_data.csv\", index=False, header=False)\n",
    "\n",
    "train_path = S3Uploader.upload(\"train_data.csv\", \"s3://{}/{}\".format(bucket, prefix))\n",
    "validation_path = S3Uploader.upload(\"validation_data.csv\", \"s3://{}/{}\".format(bucket, prefix))\n",
    "test_path = S3Uploader.upload(\"test_data.csv\", \"s3://{}/{}\".format(bucket, prefix))\n",
    "\n",
    "# Set the training inputs\n",
    "train_input = TrainingInput(train_path, content_type=\"text/csv\")\n",
    "validation_input = TrainingInput(validation_path, content_type=\"text/csv\")\n",
    "test_input = TrainingInput(test_path, content_type=\"text/csv\")\n",
    "\n",
    "data_inputs = {\n",
    "    \"train\": train_input,\n",
    "    \"validation\": validation_input\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con este laboratorio, regrese a la <a href=\"#task3-2-continue\" target=\"_self\">Tarea 3.2</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task3-3-1\" id=\"task3-3-1\"></a>\n",
    "\n",
    "### Apéndice: configurar y ejecutar un trabajo de entrenamiento básico (Tarea 3.3)\n",
    "\n",
    "Si desea comenzar con un trabajo de entrenamiento básico, utilice el contenedor básico **XGBoost**. A continuación, configure un estimador, teniendo en cuenta el contenedor y el rol que desea utilizar. Cuando esas configuraciones están listas, puede seleccionar los hiperparámetros. Puede utilizar los valores predeterminados que se proporcionan en el siguiente código, o puede editarlos en función de sus hallazgos durante la preparación de los datos.\n",
    "\n",
    "Para ejecutar un trabajo de entrenamiento, llame a **fit()**, configure las entradas como su variable **data_inputs** y ajuste las configuraciones de **run_name** y **experiment_name**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker import image_uris\n",
    "#train-model\n",
    "# Retrieve the container image\n",
    "container = sagemaker.image_uris.retrieve(\n",
    "    region=boto3.Session().region_name, \n",
    "    framework=\"xgboost\", \n",
    "    version=\"1.5-1\"\n",
    ")\n",
    "\n",
    "# Set the hyperparameters\n",
    "eta=0.2\n",
    "gamma=4\n",
    "max_depth=5\n",
    "min_child_weight=6\n",
    "num_round=800\n",
    "objective='binary:logistic'\n",
    "subsample=0.8\n",
    "\n",
    "hyperparameters = {\n",
    "    \"eta\":eta,\n",
    "    \"gamma\":gamma,\n",
    "    \"max_depth\":max_depth,\n",
    "    \"min_child_weight\":min_child_weight,\n",
    "    \"num_round\":num_round,\n",
    "    \"objective\":objective,\n",
    "    \"subsample\":subsample\n",
    "}\n",
    "\n",
    "# Set up the estimator\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,    \n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    "    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    max_run=1800,\n",
    "    hyperparameters=hyperparameters,\n",
    "    tags = run_tags\n",
    ")\n",
    "\n",
    "with Run(\n",
    "    experiment_name=capstone_experiment_name,\n",
    "    run_name=capstone_run_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "    run.log_parameter(\"eta\", eta)\n",
    "    run.log_parameter(\"gamma\", gamma)\n",
    "    run.log_parameter(\"max_depth\", max_depth)\n",
    "    run.log_parameter(\"min_child_weight\", min_child_weight)\n",
    "    run.log_parameter(\"objective\", objective)\n",
    "    run.log_parameter(\"subsample\", subsample)\n",
    "    run.log_parameter(\"num_round\", num_round)\n",
    "\n",
    "# Train the model associating the training run with the current \"experiment\"\n",
    "    xgb.fit(\n",
    "        inputs = data_inputs\n",
    "    )        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con este laboratorio, regrese a la <a href=\"#task3-3-continue\" target=\"_self\">Tarea 3.3</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task3-3-2\" id=\"task3-3-2\"></a>\n",
    "\n",
    "### Apéndice: configurar y ejecutar un trabajo de entrenamiento con el depurador de SageMaker habilitado y analizar los informes (Tarea 3.3).\n",
    "\n",
    "El depurador de SageMaker lo ayuda a encontrar rápidamente informes adicionales que pueden informar sobre el ajuste de hiperparámetros, lo que le permite ahorrar tiempo cuando comienza a ejecutar más trabajos de entrenamiento con los rangos de hiperparámetros. Para habilitar el depurador, configure **DebuggerHookConfig** y **rules**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enable-debugger\n",
    "# Retrieve the container image\n",
    "container = sagemaker.image_uris.retrieve(\n",
    "    region=boto3.Session().region_name, \n",
    "    framework=\"xgboost\", \n",
    "    version=\"1.5-1\"\n",
    ")\n",
    "\n",
    "# Set the hyperparameters\n",
    "eta=0.2\n",
    "gamma=4\n",
    "max_depth=5\n",
    "min_child_weight=6\n",
    "num_round=300\n",
    "objective='binary:logistic'\n",
    "subsample=0.7\n",
    "        \n",
    "hyperparameters = {\n",
    "        \"eta\":eta,\n",
    "        \"gamma\":gamma,\n",
    "        \"max_depth\":max_depth,\n",
    "        \"min_child_weight\":min_child_weight,\n",
    "        \"num_round\":num_round,\n",
    "        \"objective\":objective,\n",
    "        \"subsample\":subsample\n",
    "}\n",
    "\n",
    "# Set up the estimator\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role, \n",
    "    base_job_name=base_job_name,\n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    "    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    max_run=1800,\n",
    "    hyperparameters=hyperparameters,\n",
    "    tags = run_tags,\n",
    "\n",
    "    #Set the Debugger Hook Config\n",
    "    debugger_hook_config=DebuggerHookConfig(\n",
    "        s3_output_path=bucket_path,  # Required\n",
    "        collection_configs=[\n",
    "            CollectionConfig(name=\"metrics\", parameters={\"save_interval\": str(save_interval)}),\n",
    "            CollectionConfig(name=\"feature_importance\", parameters={\"save_interval\": str(save_interval)},),\n",
    "            CollectionConfig(name=\"full_shap\", parameters={\"save_interval\": str(save_interval)}),\n",
    "            CollectionConfig(name=\"average_shap\", parameters={\"save_interval\": str(save_interval)}),\n",
    "        ],\n",
    "        ),\n",
    "        #Set the Debugger Profiler Configuration\n",
    "        profiler_config = ProfilerConfig(\n",
    "            system_monitor_interval_millis=500,\n",
    "            framework_profile_params=FrameworkProfile()\n",
    "    ),\n",
    "        #Configure the Debugger Rule Object\n",
    "        rules = [\n",
    "            ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "            Rule.sagemaker(rule_configs.create_xgboost_report()),  \n",
    "            Rule.sagemaker(rule_configs.overfit()),\n",
    "            Rule.sagemaker(rule_configs.overtraining()),\n",
    "            Rule.sagemaker(rule_configs.loss_not_decreasing(),\n",
    "                rule_parameters={\n",
    "                    \"collection_names\": \"metrics\",\n",
    "                    \"num_steps\": str(save_interval * 2),\n",
    "                }\n",
    "            )\n",
    "    ]\n",
    ")\n",
    "with Run(\n",
    "    experiment_name=capstone_experiment_name,\n",
    "    run_name=capstone_run_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "    run.log_parameter(\"eta\", eta)\n",
    "    run.log_parameter(\"gamma\", gamma)\n",
    "    run.log_parameter(\"max_depth\", max_depth)\n",
    "    run.log_parameter(\"min_child_weight\", min_child_weight)\n",
    "    run.log_parameter(\"objective\", objective)\n",
    "    run.log_parameter(\"subsample\", subsample)\n",
    "    run.log_parameter(\"num_round\", num_round)\n",
    "# Train the model\n",
    "xgb.fit(\n",
    "    inputs = data_inputs\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con este laboratorio, regrese a la <a href=\"#task3-3-continue\" target=\"_self\">Tarea 3.3</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task3-4\" id=\"task3-4\"></a>\n",
    "\n",
    "### Apéndice: configurar los rangos de los hiperparámetros de entrenamiento (Tarea 3.4)\n",
    "\n",
    "Ahora que ha entrenado al menos un modelo, puede utilizar lo que ha aprendido del procesamiento de datos y el depurador de SageMaker para informar qué rangos selecciona para sus hiperparámetros. Edite los siguientes rangos de hiperparámetros y ejecute el trabajo de ajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune-model\n",
    "# Setup the hyperparameter ranges\n",
    "hyperparameter_ranges = {\n",
    "    \"alpha\": ContinuousParameter(0, 2),\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "    \"max_depth\": IntegerParameter(1, 10),\n",
    "    \"min_child_weight\": ContinuousParameter(1, 10),\n",
    "    \"num_round\": IntegerParameter(100, 1000)\n",
    "}\n",
    "\n",
    "# Define the target metric and the objective type (max/min)\n",
    "objective_metric_name = \"validation:auc\"\n",
    "objective_type=\"Maximize\"\n",
    "\n",
    "# Define the HyperparameterTuner\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator = xgb,\n",
    "    objective_metric_name = objective_metric_name,\n",
    "    hyperparameter_ranges = hyperparameter_ranges,\n",
    "    objective_type = objective_type,\n",
    "    max_jobs=12,\n",
    "    max_parallel_jobs=4,\n",
    "    early_stopping_type=\"Auto\"\n",
    ")\n",
    "\n",
    "# Tune the model\n",
    "tuner.fit(\n",
    "    inputs = data_inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con este laboratorio, regrese a la <a href=\"#task3-4-continue\" target=\"_self\">Tarea 3.4</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-1\" id=\"task4-1\"></a>\n",
    "\n",
    "### Apéndice: crear un modelo (Tarea 4.1)\n",
    "\n",
    "Cree un modelo XGBoost, llamando **create_model** con el **model_name**, **role** y **container_def** que usted defina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model-configurations\n",
    "model_name = \"capstone-clarify-model\"\n",
    "model = xgb.create_model(name=model_name)\n",
    "container_def = model.prepare_container_def()\n",
    "sagemaker_session.create_model(model_name, role, container_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con este laboratorio, regrese a la <a href=\"#task4-1-continue\" target=\"_self\">Tarea 4.1</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-2\" id=\"task4-2\"></a>\n",
    "\n",
    "### Apéndice: crear una configuración del modelo de SageMaker Clarify (Tarea 4.2)\n",
    "\n",
    "Cree una configuración del modelo de SageMaker Clarify con **SageMakerClarifyProcessor**. Configure **instance_count** e **instance_type**. Utilice el **rol** y la **sesión** creados al comienzo del curso de culminación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define-clarify-processor\n",
    "clarify_processor = clarify.SageMakerClarifyProcessor(\n",
    "    role=role, \n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.m5.xlarge\", \n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con este laboratorio, regrese a la <a href=\"#task4-2-continue\" target=\"_self\">Tarea 4.2</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-3\" id=\"task4-3\"></a>\n",
    "\n",
    "### Apéndice: crear una configuración de sesgos de SageMaker Clarify (Tarea 4.3)\n",
    "\n",
    "Para crear una configuración de sesgos de SageMaker Clarify, seleccione una ruta de salida para los datos, configure la ruta de entrada para el trabajo de entrenamiento, además de **label **, **headers** y **dataset_type**.\n",
    "\n",
    "A continuación, cree **ModelConfig** y **ModelPredictedLabelConfig**.\n",
    "\n",
    "Finalmente, configure **BiasConfig** con los campos que quiere que SageMaker Clarify observe. Puede agregar o eliminar cualquier campo que le interese explorar en función de sus hallazgos iniciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define-data-config\n",
    "bias_report_output_path = \"s3://{}/{}/clarify-bias\".format(bucket, prefix)\n",
    "bias_data_config = clarify.DataConfig(\n",
    "    s3_data_input_path=train_path,\n",
    "    s3_output_path=bias_report_output_path,\n",
    "    label=\"fraud\",\n",
    "    headers=train_data.columns.to_list(),\n",
    "    dataset_type=\"text/csv\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define-model-config\n",
    "model_config = clarify.ModelConfig(\n",
    "    model_name=model_name,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    accept_type=\"text/csv\",\n",
    "    content_type=\"text/csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define-label-config\n",
    "predictions_config = clarify.ModelPredictedLabelConfig(probability_threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define-bias-config\n",
    "bias_config = clarify.BiasConfig(\n",
    "    label_values_or_threshold=[1], facet_name=\"customer_gender_female\", facet_values_or_threshold=[0], group_name=\"customer_age\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con este laboratorio, regrese a la <a href=\"#task4-3-continue\" target=\"_self\">Tarea 4.3</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-4\" id=\"task4-4\"></a>\n",
    "\n",
    "### Apéndice: ejecutar informes de sesgos, datos y modelos con SageMaker Clarify (Tarea 4.4)\n",
    "\n",
    "Ahora que su trabajo de SageMaker Clarify está configurado, ejecute el trabajo a través de una llamada a **run_bias**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run-bias-report\n",
    "clarify_processor.run_bias(\n",
    "    data_config=bias_data_config,\n",
    "    bias_config=bias_config,\n",
    "    model_config=model_config,\n",
    "    model_predicted_label_config=predictions_config,\n",
    "    pre_training_methods=\"all\",\n",
    "    post_training_methods=\"all\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con este laboratorio, regrese a la <a href=\"#task4-4-continue\" target=\"_self\">Tarea 4.4</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-5\" id=\"task4-5\"></a>\n",
    "\n",
    "### Apéndice: eliminar el desequilibrio (Tarea 4.5)\n",
    "\n",
    "En este ejemplo, está realizando un sobre muestreo de **customer_gender_female** para reducir el sesgo en el conjunto de datos. Si encuentra otras funciones que contienen sesgos, también puede eliminar los desequilibrios en esas funciones. El **random_state** se ha establecido en `42`, pero puede cambiarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display-summary\n",
    "gender = train_data[\"customer_gender_female\"]\n",
    "gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove-imbalance\n",
    "sm = SMOTE(random_state=42)\n",
    "train_data_upsampled, gender_res = sm.fit_resample(train_data, gender)\n",
    "train_data_upsampled[\"customer_gender_female\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con este laboratorio, regrese a la <a href=\"#task4-5-continue\" target=\"_self\">Tarea 4.5</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task4-6\" id=\"task4-6\"></a>\n",
    "\n",
    "### Apéndice: volver a entrenar el modelo (Tarea 4.6)\n",
    "\n",
    "Ha encontrado un desequilibrio y tiene un nuevo conjunto de datos de entrenamiento. Utilice este conjunto de datos y vuelva a entrenar el archivo. Para hacerlo, cargue el archivo nuevo y cree un nuevo estimador. A continuación, vuelva a entrenar los datos con **fit()**. En el siguiente código se incluyen varios hiperparámetros como muestra. Puede agregarlos, eliminarlos o ajustarlos según sea necesario durante el nuevo entrenamiento para hallar el mejor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload-upsampled-csv\n",
    "train_data_upsampled.to_csv(\"data/upsampled_train.csv\", index=False, header=False)\n",
    "retrain_path = S3Uploader.upload(\"data/upsampled_train.csv\", \"s3://{}/{}\".format(bucket, prefix))\n",
    "retrain_input = TrainingInput(retrain_path, content_type=\"text/csv\")\n",
    "\n",
    "retrain_data_inputs = {\n",
    "    \"train\": retrain_input,\n",
    "    \"validation\": validation_input\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create-estimator\n",
    "hyperparameters= {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.7\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": \"300\",\n",
    "}\n",
    "\n",
    "xgb_retrained = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role, \n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters=hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrain-upsampled-data\n",
    "xgb_retrained.fit(\n",
    "    inputs = retrain_data_inputs\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con este laboratorio, regrese a la <a href=\"#task4-6-continue\" target=\"_self\">Tarea 4.6</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task5-1\" id=\"task5-1\"></a>\n",
    "\n",
    "### Apéndice: crear un trabajo de transformación por lotes (Tarea 5.1)\n",
    "\n",
    "Utilice el estimador del modelo y cree un trabajo de transformación por lotes con **transformer** (transformador). Configure la estrategia en **MultiRecord** para incrementar la eficacia del procesamiento. A continuación, introduzca su **test_path** y aguarde que se ejecute la interferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create-batch-transformer\n",
    "# Use the retrained model if it exists, otherwise, use the original model\n",
    "try:\n",
    "    model = xgb_retrained\n",
    "except NameError:\n",
    "    model = xgb\n",
    "\n",
    "# Create the transformer\n",
    "transformer = model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    strategy=\"MultiRecord\",\n",
    "    assemble_with=\"Line\",\n",
    "    accept=\"text/csv\",\n",
    "    output_path=\"s3://{}/{}/batch-transform/\".format(bucket, prefix)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run-batch-transform-job\n",
    "test_data_batch = test_data.drop(\"fraud\", axis=1)\n",
    "test_data_batch.to_csv(\"test_data_batch.csv\", index=False, header=False)\n",
    "test_path_batch = S3Uploader.upload(\"test_data_batch.csv\", \"s3://{}/{}\".format(bucket, prefix))\n",
    "\n",
    "transformer.transform(test_path_batch, content_type=\"text/csv\", split_type=\"Line\", join_source=\"Input\")\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con este laboratorio, regrese a la <a href=\"#task5-1-continue\" target=\"_self\">Tarea 5.1</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task5-2\" id=\"task5-2\"></a>\n",
    "\n",
    "### Apéndice: ver los datos de predicción y exactitud de un trabajo de transformación por lotes (Tarea 5.2)\n",
    "\n",
    "Cuando finalice el trabajo de transformación por lotes, vea los datos de predicción almacenados en Amazon S3. Puede referenciar la ruta de salida que configuró en el **transformer** (transformador) hacer una muestra de los datos.\n",
    "\n",
    "En esta salida, la predicción **fraud** (fraude) se añade al final de cada registro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $transformer.output_path ./\n",
    "test_data = pd.read_csv(\"test_data_batch.csv.out\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con este laboratorio, regrese a la <a href=\"#task5-2-continue\" target=\"_self\">Tarea 5.2</a>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task5-3\" id=\"task5-3\"></a>\n",
    "\n",
    "### Apéndice: realizar una limpieza de las instancias de SageMaker en SageMaker Studio (Tarea 5.3)\n",
    "\n",
    "A medida que desarrolle modelos en SageMaker Studio, verifique de forma periódica si hay alguna instancia que quiera limpiar. En ese caso, puede apagar las instancias dentro de SageMaker Studio.\n",
    "\n",
    "1. En la barra de menú, seleccione el ícono **Running Terminals and Kernels** (Terminales y kernels en ejecución) (un círculo con un cuadrado en el medio).\n",
    "\n",
    "1. Si aún quedan instancias abiertas, a la derecha de cada tipo de instancia, seleccione el ícono **Shut down** (Apagar). \n",
    "\n",
    "Puede ver las aplicaciones que se están ejecutando en cada instancia para confirmar cuáles quiere cerrar.\n",
    "\n",
    "1. Si aparece una ventana emergente, seleccione **Shut down all** (Apagar todo).\n",
    "\n",
    "1. Seleccione el ícono **Refresh List** (Actualizar lista) de forma periódica hasta que la instancia ya no aparezca en la lista. Una instancia puede tardar entre 2 y 5 minutos para apagarse.\n",
    "\n",
    "No es necesario que apague la instancia que está usando el cuaderno**capstone.ipynb**.\n",
    "\n",
    "Para continuar con este laboratorio, regrese a la <a href=\"#task5-3-continue\" target=\"_self\">Tarea 5.3</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task6-1\" id=\"task6-1\"></a>\n",
    "\n",
    "### Apéndice: configurar una canalización (Tarea 6.1)\n",
    "\n",
    "Para crear una canalización, defina cada paso del proceso de canalización y luego ejecútelo.\n",
    "\n",
    "En este ejemplo, se crean los siguientes pasos:\n",
    "- **AutoModelProcess**: un paso de **Procesamiento** que extrae el archivo .csv y lo divide en conjuntos de datos de entrenamiento, prueba y validación.\n",
    "- **AutoHyperParameterTuning**: un paso de **Ajuste** que utiliza una amplia gama de hiperparámetros y ajusta el modelo.\n",
    "- **AutoEvalBestModel**: un paso de **Procesamiento** que crea un informe de evaluación para describir al mejor modelo.\n",
    "- **CheckAUCScoreAutoEvaluation**: un paso de **Condición** que evalúa los modelos basados en una métrica de evaluación. \n",
    "- **AutoCreateModel**: un paso de **Modelo** que crea el modelo.\n",
    "- **RegisterAutoModel-RegisterModel**: un paso de **Registro de modelo** que registra el modelo.\n",
    "- **AutoModelConfigFile**: un paso de **Procesamiento** que crea un informe de sesgos.\n",
    "- **AutoTransform**: un paso de **Transformación** que ejecuta un trabajo de transformación por lotes.\n",
    "- **ClarifyProcessingStep**: un paso de **Procesamiento** que ejecuta un trabajo de SageMaker Clarify.\n",
    "\n",
    "Si se traba en algún punto mientras crea la canalización, puede personalizar el siguiente código o utilizarlo como guía mientras crea su propia canalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run-pipeline\n",
    "# Set the variables\n",
    "model_name = \"Auto-model\"\n",
    "sklearn_processor_version=\"0.23-1\"\n",
    "model_package_group_name=\"AutoModelPackageGroup\"\n",
    "pipeline_name= \"AutoModelSMPipeline\"\n",
    "clarify_image = sagemaker.image_uris.retrieve(framework='sklearn',version=sklearn_processor_version,region=region)\n",
    "\n",
    "# Upload files to the default S3 bucket\n",
    "s3_client.put_object(Bucket=bucket,Key='data/')\n",
    "s3_client.put_object(Bucket=bucket,Key='input/code/')\n",
    "s3_client.upload_file(Filename=\"data/batch_data.csv\", Bucket=bucket, Key=\"data/batch_data.csv\")  #If you edit this, make sure to also edit the headers listed in generate_config to match your column names.\n",
    "s3_client.upload_file(Filename=\"data/claims_customer.csv\", Bucket=bucket, Key=\"data/claims_customer.csv\")  #If you edit this, make sure to also edit the headers listed in generate_config to match your column names.\n",
    "s3_client.upload_file(Filename=\"pipelines/evaluate.py\", Bucket=bucket, Key=\"input/code/evaluate.py\")\n",
    "s3_client.upload_file(Filename=\"pipelines/generate_config.py\", Bucket=bucket, Key=\"input/code/generate_config.py\")\n",
    "s3_client.upload_file(Filename=\"pipelines/preprocess.py\", Bucket=bucket, Key=\"input/code/preprocess.py\")\n",
    "\n",
    "# Configure important settings. Change the input_data if you want to\n",
    "# use a file other than the claims_customer.csv and batch_data.csv files.\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "processing_instance_type = ParameterString(\n",
    "        name=\"ProcessingInstanceType\",\n",
    "        default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "training_instance_type = ParameterString(\n",
    "        name=\"TrainingInstanceType\",\n",
    "        default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "input_data = ParameterString(\n",
    "        name=\"InputData\",\n",
    "        default_value=\"s3://{}/data/claims_customer.csv\".format(bucket), \n",
    ")\n",
    "batch_data = ParameterString(\n",
    "        name=\"BatchData\",\n",
    "        default_value=\"s3://{}/data/batch_data.csv\".format(bucket),\n",
    ")\n",
    "\n",
    "# Run a scikit-learn script to do data processing on SageMaker using \n",
    "# using the SKLearnProcessor class\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "        framework_version=sklearn_processor_version,\n",
    "        instance_type=processing_instance_type.default_value, \n",
    "        instance_count=processing_instance_count,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        role=role,\n",
    ")\n",
    "\n",
    "# Configure the processing step to pull in the input_data\n",
    "step_process = ProcessingStep(\n",
    "        name=\"AutoModelProcess\",\n",
    "        processor=sklearn_processor,\n",
    "        outputs=[\n",
    "            ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\",\\\n",
    "                             destination=f\"s3://{bucket}/output/train\" ),\n",
    "            ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\",\\\n",
    "                            destination=f\"s3://{bucket}/output/validation\"),\n",
    "            ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\",\\\n",
    "                            destination=f\"s3://{bucket}/output/test\"),\n",
    "            ProcessingOutput(output_name=\"batch\", source=\"/opt/ml/processing/batch\",\\\n",
    "                            destination=f\"s3://{bucket}/data/batch\"),\n",
    "            ProcessingOutput(output_name=\"baseline\", source=\"/opt/ml/processing/baseline\",\\\n",
    "                            destination=f\"s3://{bucket}/input/baseline\")\n",
    "        ],\n",
    "        code=f\"s3://{bucket}/input/code/preprocess.py\",\n",
    "        job_arguments=[\"--input-data\", input_data],\n",
    ")\n",
    "\n",
    "# Set up the model path, image uri, and hyperparameters for the estimator\n",
    "model_path = f\"s3://{bucket}/output\"\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.5-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=training_instance_type.default_value,\n",
    ")\n",
    "\n",
    "fixed_hyperparameters = {\n",
    "    \"eval_metric\":\"auc\",\n",
    "    \"objective\":\"binary:logistic\",\n",
    "    \"num_round\":\"100\",\n",
    "    \"rate_drop\":\"0.3\",\n",
    "    \"tweedie_variance_power\":\"1.4\"\n",
    "}\n",
    "\n",
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    hyperparameters=fixed_hyperparameters,\n",
    "    output_path=model_path,\n",
    "    base_job_name=f\"auto-train\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "# Set the hyperparameter ranges for the tuning step and configure the tuning step\n",
    "hyperparameter_ranges = {\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "    \"min_child_weight\": ContinuousParameter(1, 10),\n",
    "    \"alpha\": ContinuousParameter(0, 2),\n",
    "    \"max_depth\": IntegerParameter(1, 10),\n",
    "}\n",
    "objective_metric_name = \"validation:auc\"\n",
    "\n",
    "step_tuning = TuningStep(\n",
    "    name = \"AutoHyperParameterTuning\",\n",
    "    tuner = HyperparameterTuner(xgb_train, objective_metric_name, hyperparameter_ranges, max_jobs=2, max_parallel_jobs=2),\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    },\n",
    ")\n",
    "\n",
    "# Configure the processing step for evaluation\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"script-auto-eval\",\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"AutoEvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\",\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"AutoEvalBestModel\",\n",
    "    processor=script_eval,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_tuning.get_top_model_s3_uri(top_k=0,s3_bucket=bucket,prefix=\"output\"),\n",
    "            destination=\"/opt/ml/processing/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\",\\\n",
    "                            destination=f\"s3://{bucket}/output/evaluation\"),\n",
    "    ],\n",
    "    code=f\"s3://{bucket}/input/code/evaluate.py\",\n",
    "    property_files=[evaluation_report],\n",
    ")\n",
    "\n",
    "# Configure model creation\n",
    "model = Model(\n",
    "    image_uri=image_uri,        \n",
    "    model_data=step_tuning.get_top_model_s3_uri(top_k=0,s3_bucket=bucket,prefix=\"output\"),\n",
    "    name=model_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "inputs = CreateModelInput(\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    accelerator_type=\"ml.inf1.xlarge\",\n",
    ")\n",
    "\n",
    "step_create_model = CreateModelStep(\n",
    "    name=\"AutoCreateModel\",\n",
    "    model=model,\n",
    "    inputs=inputs,\n",
    ")\n",
    "\n",
    "script_processor = ScriptProcessor(\n",
    "    command=['python3'],\n",
    "    image_uri=clarify_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=processing_instance_type,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "bias_report_output_path = f\"s3://{bucket}/clarify-output/bias\"\n",
    "clarify_instance_type = 'ml.m5.xlarge'\n",
    "step_config_file = ProcessingStep(\n",
    "    name=\"AutoModelConfigFile\",\n",
    "    processor=script_processor,\n",
    "    code=f\"s3://{bucket}/input/code/generate_config.py\",\n",
    "    job_arguments=[\"--modelname\",step_create_model.properties.ModelName,\"--bias-report-output-path\",bias_report_output_path,\"--clarify-instance-type\",clarify_instance_type,\\\n",
    "                  \"--default-bucket\",bucket,\"--num-baseline-samples\",\"50\",\"--instance-count\",\"1\"],\n",
    "    depends_on= [step_create_model.name]\n",
    ")\n",
    "\n",
    "# Configure the step to perform a batch transform job\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    assemble_with=\"Line\",\n",
    "    accept=\"text/csv\",    \n",
    "    output_path=f\"s3://{bucket}/AutoTransform\"\n",
    ")\n",
    "\n",
    "step_transform = TransformStep(\n",
    "    name=\"AutoTransform\",\n",
    "    transformer=transformer,\n",
    "    inputs=TransformInput(data=batch_data,content_type=\"text/csv\",join_source=\"Input\",split_type=\"Line\")\n",
    ")\n",
    "\n",
    "# Configure the SageMaker Clarify processing step\n",
    "analysis_config_path = f\"s3://{bucket}/clarify-output/bias/analysis_config.json\"\n",
    "\n",
    "data_config = sagemaker.clarify.DataConfig(\n",
    "    s3_data_input_path=f's3://{bucket}/output/train/train.csv', \n",
    "    s3_output_path=bias_report_output_path,\n",
    "    label=0,\n",
    "    headers=list(pd.read_csv(\"./data/claims_customer.csv\", index_col=None).columns), #If you edit this, make sure to also edit the headers listed in generate_config to match your column names.\n",
    "    dataset_type=\"text/csv\",\n",
    ")\n",
    "\n",
    "clarify_processor = sagemaker.clarify.SageMakerClarifyProcessor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=clarify_instance_type,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "config_input = ProcessingInput(\n",
    "    input_name=\"analysis_config\",\n",
    "    source=analysis_config_path,\n",
    "    destination=\"/opt/ml/processing/input/analysis_config\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    s3_input_mode=\"File\",\n",
    "    s3_compression_type=\"None\",\n",
    ")\n",
    "\n",
    "data_input = ProcessingInput(\n",
    "    input_name=\"dataset\",\n",
    "    source=data_config.s3_data_input_path,\n",
    "    destination=\"/opt/ml/processing/input/data\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    s3_input_mode=\"File\",\n",
    "    s3_data_distribution_type=data_config.s3_data_distribution_type,\n",
    "    s3_compression_type=data_config.s3_compression_type,\n",
    ")\n",
    "\n",
    "result_output = ProcessingOutput(\n",
    "    source=\"/opt/ml/processing/output\",\n",
    "    destination=data_config.s3_output_path,\n",
    "    output_name=\"analysis_result\",\n",
    "    s3_upload_mode=\"EndOfJob\",\n",
    ")\n",
    "\n",
    "step_clarify = ProcessingStep(\n",
    "    name=\"ClarifyProcessingStep\",\n",
    "    processor=clarify_processor,\n",
    "    inputs= [data_input, config_input],\n",
    "    outputs=[result_output],\n",
    "    depends_on = [step_config_file.name]\n",
    ")\n",
    "\n",
    "# Configure the model registration step\n",
    "model_statistics = MetricsSource(\n",
    "    s3_uri=\"s3://{}/output/evaluation/evaluation.json\".format(bucket),\n",
    "    content_type=\"application/json\"\n",
    ")\n",
    "explainability = MetricsSource(\n",
    "    s3_uri=\"s3://{}/clarify-output/bias/analysis.json\".format(bucket),\n",
    "    content_type=\"application/json\"\n",
    ")\n",
    "\n",
    "bias = MetricsSource(\n",
    "    s3_uri=\"s3://{}/clarify-output/bias/analysis.json\".format(bucket),\n",
    "    content_type=\"application/json\"\n",
    ") \n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=model_statistics,\n",
    "    explainability=explainability,\n",
    "    bias=bias\n",
    ")\n",
    "\n",
    "step_register = RegisterModel(\n",
    "    name=\"RegisterAutoModel\",\n",
    "    estimator=xgb_train,\n",
    "    model_data=step_tuning.get_top_model_s3_uri(top_k=0,s3_bucket=bucket,prefix=\"output\"),\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    model_metrics=model_metrics,\n",
    ")\n",
    "\n",
    "# Create the model evaluation step\n",
    "cond_lte = ConditionGreaterThan(\n",
    "    left=JsonGet(\n",
    "        step=step_eval,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"binary_classification_metrics.auc.value\"\n",
    "    ),\n",
    "    right=0.75,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"CheckAUCScoreAutoEvaluation\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_create_model,step_config_file,step_transform,step_clarify,step_register],\n",
    "    else_steps=[],\n",
    ")\n",
    "\n",
    "# Define the pipeline\n",
    "def get_pipeline(\n",
    "    region,\n",
    "    role=None,\n",
    "    default_bucket=None,\n",
    "    model_package_group_name=\"AutoModelPackageGroup\",\n",
    "    pipeline_name=\"AutoModelPipeline\",\n",
    "    base_prefix = None,\n",
    "    custom_image_uri = None,\n",
    "    sklearn_processor_version=None\n",
    "    ):\n",
    "    \"\"\"Gets a SageMaker ML Pipeline instance working with auto data.\n",
    "    Args:\n",
    "        region: AWS region to create and run the pipeline.\n",
    "        role: IAM role to create and run steps and pipeline.\n",
    "        default_bucket: the bucket to use for storing the artifacts\n",
    "    Returns:\n",
    "        an instance of a pipeline\n",
    "    \"\"\"\n",
    "\n",
    "    # pipeline instance\n",
    "    pipeline = Pipeline(\n",
    "        name=pipeline_name,\n",
    "        parameters=[\n",
    "            processing_instance_type,\n",
    "            processing_instance_count,\n",
    "            training_instance_type,\n",
    "            input_data,\n",
    "            batch_data,\n",
    "        ],\n",
    "        steps=[step_process,step_tuning,step_eval,step_cond],\n",
    "        sagemaker_session=sagemaker_session\n",
    "    )\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = get_pipeline(\n",
    "    region = region,\n",
    "    role=role,\n",
    "    default_bucket=bucket,\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    pipeline_name=pipeline_name,\n",
    "    custom_image_uri=clarify_image,\n",
    "    sklearn_processor_version=sklearn_processor_version\n",
    ")\n",
    "\n",
    "pipeline.upsert(role_arn=role)\n",
    "\n",
    "# Run the pipeline\n",
    "RunPipeline = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con este laboratorio, regrese a la <a href=\"#task6-1-continue\" target=\"_self\">Tarea 6.1</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"task6-2\" id=\"task6-2\"></a>\n",
    "\n",
    "### Apéndice: supervisar la canalización (Tarea 6.2)\n",
    "\n",
    "Ahora que ya ha creado y ejecutado la canalización, supervísela. Puede ver el estado de la canalización en SageMaker Studio.\n",
    "\n",
    "Si desea eliminar la canalización, puede hacerlo con **delete_pipeline**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe-pipeline\n",
    "RunPipeline.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list-pipeline-steps\n",
    "RunPipeline.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove-pipeline\n",
    "response = sagemaker_session.boto_session.client(\"sagemaker\", region_name=region).delete_pipeline(PipelineName='AutoModelSMPipeline')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con este laboratorio, regrese a la <a href=\"#task6-2-continue\" target=\"_self\">Tarea 6.2</a>."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "741de909edea0d5644898c592544ed98bede62b404d20772e5c4abc3c2f12566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
