{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Use SageMaker Experiments\n",
    "\n",
    "In this lab, you set up an experiment using Amazon SageMaker Experiments. You train a machine learning (ML) model using XGBoost, perform hyperparameter tuning to test multiple hyperparameter settings and produce a more accurate model, and evaluate your model’s performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1: Environment setup\n",
    "\n",
    "Before you start training your model, install any necessary dependencies.\n",
    "\n",
    "\n",
    "Refer to [Manage Machine Learning with Amazon SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html#experiments-features) to learn more about the features of SageMaker Experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install-dependencies\n",
    "\n",
    "import boto3\n",
    "import io\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import sagemaker\n",
    "import sys\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Image\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.experiments.run import Run, load_run\n",
    "#from sagemaker.utils import unique_name_from_base  #could be used instead of the date-time append approach, to create a unique Experiment name.\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from time import gmtime, strftime\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sess = boto3.Session()\n",
    "sm = sess.client('sagemaker')\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = 'sagemaker/mlasms'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, import the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import-dataset\n",
    "lab_test_data = pd.read_csv('adult_data_processed.csv')\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "lab_test_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You split the dataset into training (70 percent), validation (20 percent), and test (10 percent) datasets. The training and validation datasets are during training. The test dataset is used in model evaluation after deployment.\n",
    "\n",
    "To train using the SageMaker you need to convert the datasets into either the libSVM or CSV format. This lab uses the CSV format for training. \n",
    "\n",
    "Refer to [XGBoost algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) for information about the XGBoost algorithm. \n",
    "Refer to [Input/Output Interface for the XGBoost Algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html#InputOutput-XGBoost) for more information about Input/Output Interface for the XGBoost Algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split-dataset\n",
    "train_data, validation_data, test_data = np.split(\n",
    "    lab_test_data.sample(frac=1, random_state=1729),\n",
    "    [int(0.7 * len(lab_test_data)), int(0.9 * len(lab_test_data))],\n",
    ")\n",
    "\n",
    "train_data.to_csv('train_data.csv', index=False, header=False)\n",
    "validation_data.to_csv('validation_data.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have created two dataset files, named *train_data.csv* and *validation_data.csv*. \n",
    "Upload these dataset files to Amazon Simple Storage Service (Amazon S3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload-dataset\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "train_path = S3Uploader.upload('train_data.csv', 's3://{}/{}'.format(bucket, prefix))\n",
    "validation_path = S3Uploader.upload('validation_data.csv', 's3://{}/{}'.format(bucket, prefix))\n",
    "\n",
    "train_input = TrainingInput(train_path, content_type='text/csv')\n",
    "validation_input = TrainingInput(validation_path, content_type='text/csv')\n",
    "\n",
    "data_inputs = {\n",
    "    'train': train_input,\n",
    "    'validation': validation_input\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2: Create an experiment and run an initial training job\n",
    "\n",
    "Use SageMaker Experiments to organize, track, compare, and evaluate ML model training experiments through various training components. Refer to [SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html) for more information about SageMaker Experiments. In SageMaker Experiments, these components include data sets, algorithms, hyperparameters, and metrics. \n",
    "\n",
    "In this task, you complete the following:\n",
    "- Create and track the experiment in Amazon SageMaker Studio.\n",
    "- Create a run to track inputs, parameters, and metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a name for the experiment and give it a description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create unique experiment name\n",
    "create_date = strftime(\"%m%d%H%M\")\n",
    "\n",
    "lab_6_experiment_name = \"lab-6-{}\".format(create_date)\n",
    "description = \"Using SageMaker Experiments with the Adult dataset.\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, define the optional values for a run name and tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create initial run_name\n",
    "run_name = \"lab-6-run-{}\".format(create_date)\n",
    "\n",
    "# define a run_tag\n",
    "run_tags = [{'Key': 'lab-6', 'Value': 'lab-6-run'}]\n",
    "\n",
    "print(f\"Experiment name - {lab_6_experiment_name},  run name - {run_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.3: Train and tune the model using the XGBoost algorithm\n",
    "\n",
    "The experiment is set up and ready for training. After training is complete, you can analyze the results in SageMaker Studio. In this task, you: \n",
    "\n",
    "- Train the XGBoost model.\n",
    "- Analyze the experiments in SageMaker Studio.\n",
    "- Tune the model with hyperparameters.\n",
    "- Analyze the tuning results in SageMaker Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3.1: Train the XGBoost Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the model using the XGBoost algorithm and the experiment that you created. \n",
    "\n",
    "The hyperparameters that you set are as follows:\n",
    "- **eta**: Step size shrinkage used in updates to prevent overfitting. After each boosting step, you can directly get the weights of new features. \n",
    "- **gamma**: Minimum loss reduction required to make a further partition on a leaf node of the tree. The larger, the more conservative the algorithm is.\n",
    "The eta parameter actually shrinks the feature weights to make the boosting process more conservative.\n",
    "- **max_depth**: Maximum depth of a tree. Increasing this value makes the model more complex and likely to be overfit.\n",
    "- **min_child_weight**: Minimum sum of instance weight (hessian) needed in a child. If the tree partition step results in a leaf node with the sum of instance weight less than min_child_weight, the building process gives up further partitioning. In linear regression models, this corresponds to a minimum number of instances needed in each node. The larger the algorithm, the more conservative it is.\n",
    "- **num_round**: The number of rounds (trees) used for boosting. Increasing the trees can increase the model accuracy but increases the risk of overfitting.\n",
    "- **objective**: Specifies the learning task and the corresponding learning objective.\n",
    "- **subsample**: Subsample ratio of the training instance. Setting it to 0.5 means that XGBoost randomly collects half of the data instances to grow trees. This prevents overfitting.\n",
    "- **verbosity**: Verbosity of printing messages. Valid values are 0 (silent), 1 (warning), 2 (info), and 3 (debug).\n",
    "\n",
    "The training takes approximately 3–4 minutes to run.\n",
    "\n",
    "Refer to [hyperparameters](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html) for more information about XGBoost hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "container = image_uris.retrieve(framework='xgboost',region=boto3.Session().region_name,version='1.5-1')\n",
    "\n",
    "# initialize hyperparameters\n",
    "eta=0.2\n",
    "gamma=4\n",
    "max_depth=5\n",
    "min_child_weight=6\n",
    "num_round=800\n",
    "objective='binary:logistic'\n",
    "subsample=0.8\n",
    "verbosity=0\n",
    "\n",
    "hyperparameters = {\n",
    "        \"max_depth\":max_depth,\n",
    "        \"eta\":eta,\n",
    "        \"gamma\":gamma,\n",
    "        \"min_child_weight\":min_child_weight,\n",
    "        \"subsample\":subsample,\n",
    "        \"verbosity\":verbosity,\n",
    "        \"objective\":objective,\n",
    "        \"num_round\":num_round\n",
    "}\n",
    "\n",
    "# Set up the estimator\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role, \n",
    "    instance_count=1, \n",
    "    instance_type='ml.m5.xlarge',\n",
    "    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    EnableSageMakerMetricsTimeSeries=True,\n",
    "    hyperparameters=hyperparameters,\n",
    "    tags = run_tags\n",
    ")\n",
    "\n",
    "\n",
    "#Run the training job link to Experiment.\n",
    "with Run(\n",
    "    experiment_name=lab_6_experiment_name,\n",
    "    run_name=run_name,\n",
    "    tags=run_tags,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "\n",
    "    run.log_parameters({\n",
    "                        \"eta\": eta, \n",
    "                        \"gamma\": gamma, \n",
    "                        \"max_depth\": max_depth,\n",
    "                        \"min_child_weight\": min_child_weight,\n",
    "                        \"num_round\": num_round,\n",
    "                        \"objective\": objective,\n",
    "                        \"subsample\": subsample,\n",
    "                        \"verbosity\": verbosity\n",
    "                       })\n",
    "    \n",
    "#    you may also specify metrics to log\n",
    "#    run.log_metric(name=\"\", value=x)\n",
    "\n",
    "# Train the model associating the training run with the current \"experiment\"\n",
    "    xgb.fit(\n",
    "        inputs = data_inputs\n",
    "    ) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3.2: Evaluate model performance pre-tuning\n",
    "\n",
    "In SageMaker Studio, you may create charts to evaluate your training jobs. For example, after running lab-6 experiments, you can review the validation:logloss_max value in a chart format.\n",
    "\n",
    "In this lab, you can plot additional metrics right inline in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize-training-results-table\n",
    "run_component_analytics = ExperimentAnalytics(\n",
    "    experiment_name=lab_6_experiment_name,\n",
    "    search_expression={\n",
    "                        \"Filters\": [{\n",
    "                                    \"Name\":\"TrialComponentName\",\n",
    "                                    \"Operator\":\"Contains\",\n",
    "                                    \"Value\":\"sagemaker\"\n",
    "                                    }]},\n",
    "    sagemaker_session=Session(sess, sm),\n",
    ")\n",
    "run_component_analytics.dataframe()[\"validation:logloss - Last\"].plot(kind=\"bar\", title=\"validation:logloss - Max\", xlabel=\"training job\", ylabel=\"logloss_max\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3.3 Tune the model with hyperparameters\n",
    "\n",
    "You have successfully performed model training using SageMaker Experiments. While training, you can also configure SageMaker to use hyperparameters to significantly affect trained model performance. SageMaker Studio includes various common hyperparameter tuning options for model training. While testing numerous parameters can vary in effectiveness depending on the dataset used, it can also take a significant amount of time and effort to create the best model.\n",
    "\n",
    "SageMaker automatic model tuning automates the selection of hyperparameters to optimize training. Refer to [automatic model tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html) for more information about automatic model tuning. To use it, you specify a range, or a list of possible values, for each hyperparameter that you choose to tune. SageMaker automatic model tuning automatically runs multiple training jobs with various hyperparameter settings. It then evaluates the results of each job based on a specified objective metric and select the hyperparameter settings for future attempts based on previous results. For each tuning job, you specify a maximum number of training jobs and the tuning completes when that number has been reached.\n",
    "\n",
    "The hyperparameter ranges that you need set are as follows:\n",
    "- **alpha**: L1 regularization term on weights. Increasing this value makes models more conservative.\n",
    "- **eta**: Step size shrinkage used in updates to prevent overfitting. After each boosting step, you can directly get the weights of new features. The eta parameter actually shrinks the feature weights to make the boosting process more conservative.\n",
    "- **max_depth**: Maximum depth of a tree. Increasing this value makes the model more complex and likely to be overfit.\n",
    "- **min_child_weight**: Minimum sum of instance weight (hessian) needed in a child. If the tree partition step results in a leaf node with the sum of instance weight less than min_child_weight, the building process gives up further partitioning. In linear regression models, this corresponds to a minimum number of instances needed in each node. The larger the algorithm, the more conservative it is.\n",
    "- **num_round**: The number of rounds (trees) used for boosting. Increasing the trees can increase the model accuracy but increases the risk of overfitting.\n",
    "\n",
    "Tuning takes approximately 5 minutes to complete.\n",
    "\n",
    "Refer to [hyperparameter ranges](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html) for more information about xgboost hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune-model\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "# Setup the hyperparameter ranges\n",
    "hyperparameter_ranges = {\n",
    "    'alpha': ContinuousParameter(0, 2),\n",
    "    'eta': ContinuousParameter(0, 1),\n",
    "    'max_depth': IntegerParameter(1, 10),\n",
    "    'min_child_weight': ContinuousParameter(1, 10),\n",
    "    'num_round': IntegerParameter(100, 1000)\n",
    "}\n",
    "# Define the target metric and the objective type (max/min)\n",
    "objective_metric_name = 'validation:auc'\n",
    "objective_type='Maximize'\n",
    "# Define the HyperparameterTuner\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator = xgb,\n",
    "    objective_metric_name = objective_metric_name,\n",
    "    hyperparameter_ranges = hyperparameter_ranges,\n",
    "    objective_type = objective_type,\n",
    "    max_jobs=12,\n",
    "    max_parallel_jobs=4,\n",
    "    early_stopping_type='Auto',\n",
    ")\n",
    "\n",
    "with load_run(sagemaker_session=sagemaker_session, experiment_name=lab_6_experiment_name, run_name=run_name) as run:\n",
    "# Tune the model\n",
    "    tuner.fit(\n",
    "        inputs = data_inputs,\n",
    "        job_name = lab_6_experiment_name,\n",
    "    )\n",
    "    run_component_analytics = ExperimentAnalytics(\n",
    "    experiment_name=lab_6_experiment_name,\n",
    "    search_expression={\n",
    "                        \"Filters\": [{\n",
    "                                    \"Name\":\"TrialComponentName\",\n",
    "                                    \"Operator\":\"Contains\",\n",
    "                                    \"Value\":\"sagemaker\"\n",
    "                                    }]},\n",
    "    sagemaker_session=Session(sess, sm),\n",
    ")\n",
    "run_component_analytics.dataframe()[\"validation:logloss - Last\"].plot(kind=\"bar\", title=\"validation:logloss - Max\", xlabel=\"training job\", ylabel=\"logloss_max\")\n",
    " \n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3.4: Evaluate model performance post-tuning\n",
    "\n",
    "In SageMaker Studio, you can also create charts to evaluate your tuning jobs. For example, after running your lab-6-trial training job, you can look at your objective value, the **validation:auc_max**, in a chart format.\n",
    "\n",
    "![An image of the validation:error_max charts in SageMaker Studio.](Task_2_3_4.png)\n",
    "\n",
    "In this lab, view the results from the best tuning job and visualize them using charts in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_experiment_analytics \n",
    "run_component_analytics = ExperimentAnalytics(\n",
    "    experiment_name=lab_6_experiment_name,\n",
    "    sagemaker_session=Session(sess, sm),\n",
    ")\n",
    "\n",
    "run_component_analytics.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize-tuning-results-auc-max\n",
    "if run_component_analytics.dataframe()[\"validation:auc - Max\"].iloc[1] != 0:\n",
    "    run_component_analytics.dataframe()[\"validation:auc - Max\"].plot(kind=\"bar\", title=\"validation:auc - Max\", xlabel=\"training job\", ylabel=\"auc_max\").set_ylim([0.8, 1]);\n",
    "else:\n",
    "    run_component_analytics.dataframe()[\"validation:auc - Last\"].plot(kind=\"bar\", title=\"validation:auc - Max\", xlabel=\"training job\", ylabel=\"auc_max\").set_ylim([0.8, 1]);\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize-tuning-results-auc-max-scatter\n",
    "N = 12\n",
    "if run_component_analytics.dataframe()[\"validation:auc - Max\"].iloc[1] != 0:\n",
    "    x = run_component_analytics.dataframe().sort_values(by=['TrialComponentName'])[\"validation:auc - Max\"];\n",
    "else:\n",
    "    x = run_component_analytics.dataframe().sort_values(by=['TrialComponentName'])[\"validation:auc - Last\"];\n",
    "y = run_component_analytics.dataframe().sort_values(by=['TrialComponentName'])[\"num_round\"]\n",
    "\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "plt.title(\"auc_max by num_round\")\n",
    "plt.xlabel(\"validation:auc - Max\")\n",
    "plt.ylabel(\"num_round\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, can you print the best tuning, job based on your objective metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print-best\n",
    "tuner.best_training_job()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3.5: Graph experiment metrics with SageMaker Studio using built-in features\n",
    "\n",
    "The previously mentioned method creates charts from experiment metrics using in-line notebook cells. An additional option is to plot some of the experiment metrics using features within SageMaker Studio. Now that the experiment has run at least once, create a new bar chart in SageMaker Studio.\n",
    "\n",
    "The next task opens a new tab in SageMaker Studio. To follow these directions, use one of the following options:\n",
    "- **Option 1:** View the tabs side by side. To create a split screen view from the main SageMaker Studio window, either drag the **lab_6.ipynb** tab to the side or choose (right-click) the **lab_6.ipynb** tab and choose **New View for Notebook**. You can now have the directions displayed as you explore the artifacts.\n",
    "- **Option 2:** Switch between the SageMaker Studio tabs to follow these instructions. When you are finished exploring the artifacts, return to the notebook by choosing the **lab_6.ipynb** tab.\n",
    "\n",
    "1. Choose the **SageMaker Home** icon.\n",
    "1. Choose **Experiments**.\n",
    "\n",
    "SageMaker Studio displays the **Experiments** tab.\n",
    "\n",
    "1. Select the experiment which starts with *lab-6-*.\n",
    "\n",
    "SageMaker Studio displays the list of **Runs** included in that experiment.\n",
    "\n",
    "1. Select the option in the **Name** column next to all of the available runs which are associated with the hyperparameter tuning job.\n",
    "1. Clear the \n",
    "1. Choose <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">Analyze</span>.\n",
    "\n",
    "SageMaker Studio displays the **Run Analyze Chart** tab.\n",
    "\n",
    "1. On the lower half of the tab, in the chart section, choose <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">+ Add Chart</span>.\n",
    "1. Choose **Bar**.\n",
    "\n",
    "SageMaker Studio displays the **Add Chart** window.\n",
    "\n",
    "1. For **Y-axis**, choose **min_child_weight**.\n",
    "1. Choose <span style=\"background-color:#73cdf9; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-radius:2px; border-width:3px; margin-right:5px; white-space:nowrap\">Create</span>.\n",
    "\n",
    "A bar chart showing *min_child_weight* per *run* in the experiment is now saved to the charts section.\n",
    "\n",
    "1. Repeat this process and create a new bar chart for the **train:auc** metric.\n",
    "1. Repeat this process and create a new bar chart for the **validation:auc** metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Congratulations! You have used SageMaker Experiments to train and tune models. In the next lab, you use SageMaker Debugger to get insights on potential issues while training a model.\n",
    "\n",
    "### Cleanup\n",
    "\n",
    "You have completed this notebook. To move to the next part of the lab, do the following:\n",
    "\n",
    "- Close this notebook file.\n",
    "- Return to the lab session and continue with the **Conclusion**."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "741de909edea0d5644898c592544ed98bede62b404d20772e5c4abc3c2f12566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
