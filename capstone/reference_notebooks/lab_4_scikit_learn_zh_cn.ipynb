{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务 3：使用 SageMaker Processing 和内置的 scikit-learn 容器执行数据处理\n",
    "\n",
    "在此笔记本中，您将使用由 SageMaker Processing 提供和维护的 Docker 映像设置运行 scikit-learn 脚本所需的环境。\n",
    "\n",
    "然后，您将使用 SageMaker Python SDK 中的 **SKLearnProcessor** 类来定义和运行 scikit-learn 处理作业。\n",
    "\n",
    "最后，您将验证保存在 Amazon Simple Storage Service (Amazon S3) 中的数据处理结果。\n",
    "\n",
    "**注意**：处理脚本会执行一些基本的数据处理，例如删除重复项、将目标列转换为包含两个标签的列、独热编码和以 80-20 分割率生成训练和测试数据集。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务 3.1：环境设置\n",
    "\n",
    "在此任务中，您将安装所需的程序包和依赖项。\n",
    "\n",
    "您将设置 Amazon S3 存储桶来存储处理作业的输出，并让执行角色运行 SageMaker 处理作业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install-dependencies\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "sagemaker_logger = logging.getLogger(\"sagemaker\")\n",
    "sagemaker_logger.setLevel(logging.INFO)\n",
    "sagemaker_logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "#Execution role to run the SageMaker Processing job\n",
    "role = sagemaker.get_execution_role()\n",
    "print(\"SageMaker Execution Role: \", role)\n",
    "\n",
    "#S3 bucket to read the SKLearn processing script and writing processing job outputs\n",
    "s3 = boto3.resource('s3')\n",
    "for buckets in s3.buckets.all():\n",
    "    if 'labdatabucket' in buckets.name:\n",
    "        bucket = buckets.name\n",
    "print(\"Bucket: \", bucket)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务 3.2：运行 SageMaker 处理作业\n",
    "\n",
    "在此任务中，您将导入并查看预处理数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import-data\n",
    "prefix = 'data/input'\n",
    "\n",
    "S3Downloader.download(s3_uri=f\"s3://{bucket}/{prefix}/adult_data.csv\", local_path= 'data/')\n",
    "\n",
    "shape=pd.read_csv(\"data/adult_data.csv\", header=None)\n",
    "shape.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于本实验，您将执行一些数据转换，例如删除重复项、将目标列转换为包含两个标签的列，以及对分类特征进行独热编码。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，您将使用 SKLearnProcessor 类来定义一个 scikit-learn 处理脚本并将其作为处理作业运行。有关此类的更多信息，请参阅 [SageMaker scikit-learn SKLearnProcessor](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html#sagemaker.sklearn.processing.SKLearnProcessor)。\n",
    "\n",
    "要创建 SKLearnProcessor 类，请配置以下参数：\n",
    "- **base_job_name**：处理作业名称的前缀\n",
    "- **framework_version**：scikit-learn 版本\n",
    "- **role**：SageMaker 执行角色\n",
    "- **instance_count**：要运行处理作业的实例的数量\n",
    "- **instance_type**：用于处理作业的 Amazon Elastic Compute Cloud (Amazon EC2) 实例的类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scikit-learn-processor\n",
    "import os\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "# create a SKLearnProcessor\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    base_job_name=\"sklearn-preprocessor\",\n",
    "    framework_version=\"0.20.0\", \n",
    "    role=role, \n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "接着，使用 **SKLearnProcessor.run()** 方法将 **sklearn_preprocessing.py** 脚本作为处理作业运行。\n",
    "\n",
    "要运行处理作业，请配置以下参数：\n",
    "- **code**：预处理脚本的路径 \n",
    "- **inputs and outputs**：预处理脚本的输入和输出路径（Amazon S3 输入和输出位置）\n",
    "- **arguments**：预处理脚本的命令行参数（如训练和测试分割率）\n",
    "\n",
    "完成处理作业大约需要 4–5 分钟。在作业运行时，您可以通过从文件浏览器打开 **sklearn_preprocessing.py** 文件来查看预处理脚本（已作为本实验的一部分进行预先配置）的源代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing-job\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "# Amazon S3 path prefix\n",
    "input_raw_data_prefix = \"data/input\"\n",
    "output_preprocessed_data_prefix = \"data/output\"\n",
    "scripts_prefix = \"scripts/smstudiofiles\"\n",
    "logs_prefix = \"logs\"\n",
    "\n",
    "# Run the processing job\n",
    "sklearn_processor.run(\n",
    "    code=\"s3://\" + os.path.join(bucket, scripts_prefix, \"sklearn_preprocessing.py\"),\n",
    "    inputs=[ProcessingInput(source=\"s3://\" + os.path.join(bucket, input_raw_data_prefix, \"adult_data.csv\"),\n",
    "                            destination=\"/opt/ml/processing/input\")],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train_data\", \n",
    "                         source=\"/opt/ml/processing/train\",\n",
    "                         destination=\"s3://\" + os.path.join(bucket, output_preprocessed_data_prefix, \"train\")),\n",
    "        ProcessingOutput(output_name=\"test_data\", \n",
    "                         source=\"/opt/ml/processing/test\",\n",
    "                         destination=\"s3://\" + os.path.join(bucket, output_preprocessed_data_prefix, \"test\")),\n",
    "    ],\n",
    "    arguments=[\"--train-test-split-ratio\", \"0.2\"],\n",
    ")\n",
    "\n",
    "print(\"SKLearn Processing Job Completed.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务 3.3：验证数据处理结果\n",
    "\n",
    "在此任务中，您将通过查看训练和测试输出数据集的前五行，验证您运行的处理作业的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view-train-dataset\n",
    "print(\"Top 5 rows from s3://{}/{}/train/\".format(bucket, output_preprocessed_data_prefix))\n",
    "!aws s3 cp --quiet s3://$bucket/$output_preprocessed_data_prefix/train/train_features.csv - | head -n5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view-validation-dataset\n",
    "print(\"Top 5 rows from s3://{}/{}/validation/\".format(bucket, output_preprocessed_data_prefix))\n",
    "!aws s3 cp --quiet s3://$bucket/$output_preprocessed_data_prefix/test/test_features.csv - | head -n5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总结\n",
    "\n",
    "恭喜！ 您已借助 SageMaker Processing 成功使用 SageMaker Python SDK 创建了 scikit-learn 处理作业并运行了该处理作业。\n",
    "\n",
    "本实验的下一项任务侧重于使用 SageMaker Processing 和您自己的处理容器执行数据处理。\n",
    "\n",
    "### 清理\n",
    "\n",
    "您已完成此笔记本。要进入本实验的下一部分，请执行以下操作：\n",
    "\n",
    "- 关闭此笔记本文件。\n",
    "- 返回至实验会话，继续执行**任务 4：使用您自己的容器执行数据处理**。"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "741de909edea0d5644898c592544ed98bede62b404d20772e5c4abc3c2f12566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}