{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2: utilizar SageMaker Experiments\n",
    "\n",
    "En este laboratorio, configure un experimento con Amazon SageMaker Experiments. Entrene un modelo de machine learning (ML) con XGBoost, adapte los hiperparámetros para probar varias configuraciones de hiperparámetros y producir un modelo más exacto, y evalúe el rendimiento de su modelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 2.1: configuración del entorno\n",
    "\n",
    "Antes de empezar a entrenar su modelo, instale todas las dependencias necesarias.\n",
    "\n",
    "\n",
    "Consulte [Administre el machine learning con Amazon SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html#experiments-features) para obtener más información sobre las funciones de SageMaker Experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install-dependencies\n",
    "\n",
    "import boto3\n",
    "import io\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import sagemaker\n",
    "import sys\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Image\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.experiments.run import Run, load_run\n",
    "#from sagemaker.utils import unique_name_from_base  #could be used instead of the date-time append approach, to create a unique Experiment name.\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from time import gmtime, strftime\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sess = boto3.Session()\n",
    "sm = sess.client('sagemaker')\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = 'sagemaker/mlasms'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, importe el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import-dataset\n",
    "lab_test_data = pd.read_csv('adult_data_processed.csv')\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "lab_test_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divida el conjunto de datos en conjuntos de datos de entrenamiento (70 %), validación (20 %) y prueba (10 %). Los conjuntos de datos de entrenamiento y validación se usan durante el entrenamiento. El conjunto de datos de prueba se usa en la evaluación del modelo después de la implementación.\n",
    "\n",
    "Para realizar el entrenamiento con SageMaker, debe convertir los conjuntos de datos al formato libSVM o CSV. En este laboratorio, se usa el formato CSV para realizar el entrenamiento. \n",
    "\n",
    "Consulte [Algoritmo XGBoost](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) para obtener información sobre el algoritmo XGBoost. \n",
    "Consulte [Interfaz de entrada/salida para el algoritmo XGBoost](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html#InputOutput-XGBoost) para obtener más información sobre la interfaz de entrada/salida para el algoritmo XGBoost.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split-dataset\n",
    "train_data, validation_data, test_data = np.split(\n",
    "    lab_test_data.sample(frac=1, random_state=1729),\n",
    "    [int(0.7 * len(lab_test_data)), int(0.9 * len(lab_test_data))],\n",
    ")\n",
    "\n",
    "train_data.to_csv('train_data.csv', index=False, header=False)\n",
    "validation_data.to_csv('validation_data.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creó dos archivos de conjuntos de datos llamados *train_data.csv* y *validation_data.csv*. \n",
    "Cargue estos dos archivos a Amazon Simple Storage Service (Amazon S3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload-dataset\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "train_path = S3Uploader.upload('train_data.csv', 's3://{}/{}'.format(bucket, prefix))\n",
    "validation_path = S3Uploader.upload('validation_data.csv', 's3://{}/{}'.format(bucket, prefix))\n",
    "\n",
    "train_input = TrainingInput(train_path, content_type='text/csv')\n",
    "validation_input = TrainingInput(validation_path, content_type='text/csv')\n",
    "\n",
    "data_inputs = {\n",
    "    'train': train_input,\n",
    "    'validation': validation_input\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 2.2: crear un experimento y ejecutar un trabajo de entrenamiento inicial\n",
    "\n",
    "Use SageMaker Experiments para organizar, comparar y evaluar los experimentos del entrenamiento de modelos de ML, y para hacerles un seguimiento, a través de diversos componentes de entrenamiento. Consulte [SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html) para obtener más información sobre SageMaker Experiments. En SageMaker Experiments, estos componentes incluyen conjuntos de datos, algoritmos, hiperparámetros y métricas. \n",
    "\n",
    "En esta tarea, complete lo siguiente:\n",
    "- Cree el experimento en Amazon SageMaker Studio y hágale un seguimiento.\n",
    "- Cree una ejecución para hacer un seguimiento de las entradas, los parámetros y las métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, cree un nombre para el experimento y asígnele una descripción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create unique experiment name\n",
    "create_date = strftime(\"%m%d%H%M\")\n",
    "\n",
    "lab_6_experiment_name = \"lab-6-{}\".format(create_date)\n",
    "description = \"Using SageMaker Experiments with the Adult dataset.\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, defina los valores opcionales para el nombre de una ejecución y las etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create initial run_name\n",
    "run_name = \"lab-6-run-{}\".format(create_date)\n",
    "\n",
    "# define a run_tag\n",
    "run_tags = [{'Key': 'lab-6', 'Value': 'lab-6-run'}]\n",
    "\n",
    "print(f\"Experiment name - {lab_6_experiment_name},  run name - {run_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 2.3: entrenar y adaptar el modelo con el algoritmo XGBoost\n",
    "\n",
    "El experimento está configurado y listo para el entrenamiento. Tras completar el entrenamiento, puede analizar los resultados en SageMaker Studio. En esta tarea, haga lo siguiente: \n",
    "\n",
    "- Entrene el modelo de XGBoost.\n",
    "- Analice los experimentos en SageMaker Studio.\n",
    "- Adapte el modelo con hiperparámetros.\n",
    "- Analice los resultados del ajuste en SageMaker Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.3.1 entrenar el modelo de XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, entrene el modelo con el algoritmo XGBoost y el experimento que creó. \n",
    "\n",
    "Los hiperparámetros que configurará serán los siguientes:\n",
    "- **eta**: disminución del tamaño del paso que se usa en las actualizaciones para evitar el sobreajuste. Después de cada paso de potenciación, puede obtener las ponderaciones de las nuevas funciones directamente. \n",
    "- **gamma**: se requiere la reducción de la pérdida mínima para crear una partición más en un nodo hoja del árbol. Cuanto más grande es, más conservador es el algoritmo.\n",
    "El parámetro eta disminuye las ponderaciones de las funciones para que el proceso de potenciación sea más conservador.\n",
    "- **max_depth**: profundidad máxima de un árbol. Si se aumenta este valor, el modelo es más complejo y, es probable que, se sobreajuste.\n",
    "- **min_child_weight**: suma mínima de la ponderación de instancias (hessiana) que se necesita en un proceso secundario. Si el paso de partición del árbol genera un nodo hoja cuya suma de la ponderación de la instancia es inferior a min_child_weight, el proceso de compilación deja de crear más particiones. En los modelos de regresión lineal, esto corresponde a un número mínimo de instancias que se necesitan en cada nodo. Cuanto más grande es el algoritmo, más conservador es.\n",
    "- **num_round**: la cantidad de rondas (árboles) que se usan para la potenciación. Aumentar los árboles puede aumentar la exactitud del modelo, pero también el riesgo de sobreajustes.\n",
    "- **objective**: especifica la tarea de aprendizaje y el objetivo de aprendizaje correspondiente.\n",
    "- **subsample**: relación de submuestras de la instancia de entrenamiento. Cuando se establece en 0,5 XGBoost recopila de forma aleatoria la mitad de las instancias de datos para crear arboles. Esto evita el sobreajuste.\n",
    "- **verbosity**: verbosidad de los mensajes impresos. Los valores válidos son 0 (silencioso), 1 (advertencia), 2 (información) y 3 (depuración).\n",
    "\n",
    "La ejecución de este entrenamiento tarda aproximadamente entre 3 y 4 minutos.\n",
    "\n",
    "Consulte [hiperparámetros](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html) para obtener más información sobre los hiperparámetros de XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "container = image_uris.retrieve(framework='xgboost',region=boto3.Session().region_name,version='1.5-1')\n",
    "\n",
    "# initialize hyperparameters\n",
    "eta=0.2\n",
    "gamma=4\n",
    "max_depth=5\n",
    "min_child_weight=6\n",
    "num_round=800\n",
    "objective='binary:logistic'\n",
    "subsample=0.8\n",
    "verbosity=0\n",
    "\n",
    "hyperparameters = {\n",
    "        \"max_depth\":max_depth,\n",
    "        \"eta\":eta,\n",
    "        \"gamma\":gamma,\n",
    "        \"min_child_weight\":min_child_weight,\n",
    "        \"subsample\":subsample,\n",
    "        \"verbosity\":verbosity,\n",
    "        \"objective\":objective,\n",
    "        \"num_round\":num_round\n",
    "}\n",
    "\n",
    "# Set up the estimator\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role, \n",
    "    instance_count=1, \n",
    "    instance_type='ml.m5.xlarge',\n",
    "    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    EnableSageMakerMetricsTimeSeries=True,\n",
    "    hyperparameters=hyperparameters,\n",
    "    tags = run_tags\n",
    ")\n",
    "\n",
    "\n",
    "#Run the training job link to Experiment.\n",
    "with Run(\n",
    "    experiment_name=lab_6_experiment_name,\n",
    "    run_name=run_name,\n",
    "    tags=run_tags,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "\n",
    "    run.log_parameters({\n",
    "                        \"eta\": eta, \n",
    "                        \"gamma\": gamma, \n",
    "                        \"max_depth\": max_depth,\n",
    "                        \"min_child_weight\": min_child_weight,\n",
    "                        \"num_round\": num_round,\n",
    "                        \"objective\": objective,\n",
    "                        \"subsample\": subsample,\n",
    "                        \"verbosity\": verbosity\n",
    "                       })\n",
    "    \n",
    "#    you may also specify metrics to log\n",
    "#    run.log_metric(name=\"\", value=x)\n",
    "\n",
    "# Train the model associating the training run with the current \"experiment\"\n",
    "    xgb.fit(\n",
    "        inputs = data_inputs\n",
    "    ) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.3.2: evaluar el rendimiento del modelo antes del ajuste\n",
    "\n",
    "En SageMaker Studio, puede crear gráficos para evaluar sus trabajos de entrenamiento. Por ejemplo, después de ejecutar experimentos en el laboratorio 6, puede revisar el valor validation:logloss_max en formato de gráfico.\n",
    "\n",
    "En este laboratorio, puede trazar métricas adicionales insertadas justo en el cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize-training-results-table\n",
    "run_component_analytics = ExperimentAnalytics(\n",
    "    experiment_name=lab_6_experiment_name,\n",
    "    search_expression={\n",
    "                        \"Filters\": [{\n",
    "                                    \"Name\":\"TrialComponentName\",\n",
    "                                    \"Operator\":\"Contains\",\n",
    "                                    \"Value\":\"sagemaker\"\n",
    "                                    }]},\n",
    "    sagemaker_session=Session(sess, sm),\n",
    ")\n",
    "run_component_analytics.dataframe()[\"validation:logloss - Last\"].plot(kind=\"bar\", title=\"validation:logloss - Max\", xlabel=\"training job\", ylabel=\"logloss_max\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.3: ajustar el modelo con hiperparámetros\n",
    "\n",
    "Realizó correctamente el entrenamiento del modelo con SageMaker Experiments. Mientras realiza el entrenamiento, también puede configurar SageMaker a fin de usar hiperparámetros para influir significativamente en el rendimiento del modelo entrenado. SageMaker Studio incluye varias opciones de ajuste de hiperparámetros comunes para el entrenamiento de modelos. Si bien la eficacia de las pruebas de numerosos parámetros puede variar según el conjunto de datos que se use, es posible que también se necesite mucho tiempo y esfuerzo para crear el mejor modelo.\n",
    "\n",
    "El ajuste de modelos automáticos de SageMaker automatiza la selección de hiperparámetros para optimizar el entrenamiento. Consulte [ajuste automático de modelos](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html) para obtener más información sobre el ajuste automático de modelos. Para usarlo, especifique un rango o una lista de posibles valores para cada hiperparámetro que desee ajustar. El ajuste automático de modelos de SageMaker ejecuta automáticamente varios trabajos de entrenamiento con diversas configuraciones de hiperparámetros. Luego, evalúa los resultados de cada trabajo según una métrica objetiva especificada y selecciona las configuraciones de hiperparámetros para intentos futuros basados en resultados previos. Para cada trabajo de ajuste, usted especifica un número máximo de trabajos de entrenamiento, y el ajuste se completa cuando se alcance ese número.\n",
    "\n",
    "Los rangos de hiperparámetros que debe configurar serán los siguientes:\n",
    "- **alpha**: duración de la regularización de nivel 1 en ponderaciones. Si se aumenta este valor, los modelos son más conservadores.\n",
    "- **eta**: disminución del tamaño del paso que se usa en las actualizaciones para evitar el sobreajuste. Después de cada paso de potenciación, puede obtener las ponderaciones de las nuevas funciones directamente. El parámetro eta disminuye las ponderaciones de las funciones para que el proceso de potenciación sea más conservador.\n",
    "- **max_depth**: profundidad máxima de un árbol. Si se aumenta este valor, el modelo es más complejo y, es probable que, se sobreajuste.\n",
    "- **min_child_weight**: suma mínima de la ponderación de instancias (hessiana) que se necesita en un proceso secundario. Si el paso de partición del árbol genera un nodo hoja cuya suma de la ponderación de la instancia es inferior a min_child_weight, el proceso de compilación deja de crear más particiones. En los modelos de regresión lineal, esto corresponde a un número mínimo de instancias que se necesitan en cada nodo. Cuanto más grande es el algoritmo, más conservador es.\n",
    "- **num_round**: la cantidad de rondas (árboles) que se usan para la potenciación. Aumentar los árboles puede aumentar la exactitud del modelo, pero también el riesgo de sobreajustes.\n",
    "\n",
    "El ajuste demora aproximadamente 5 minutos en completarse.\n",
    "\n",
    "Consulte [rangos de hiperparámetros](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html) para obtener más información sobre los hiperparámetros de xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune-model\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "# Setup the hyperparameter ranges\n",
    "hyperparameter_ranges = {\n",
    "    'alpha': ContinuousParameter(0, 2),\n",
    "    'eta': ContinuousParameter(0, 1),\n",
    "    'max_depth': IntegerParameter(1, 10),\n",
    "    'min_child_weight': ContinuousParameter(1, 10),\n",
    "    'num_round': IntegerParameter(100, 1000)\n",
    "}\n",
    "# Define the target metric and the objective type (max/min)\n",
    "objective_metric_name = 'validation:auc'\n",
    "objective_type='Maximize'\n",
    "# Define the HyperparameterTuner\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator = xgb,\n",
    "    objective_metric_name = objective_metric_name,\n",
    "    hyperparameter_ranges = hyperparameter_ranges,\n",
    "    objective_type = objective_type,\n",
    "    max_jobs=12,\n",
    "    max_parallel_jobs=4,\n",
    "    early_stopping_type='Auto',\n",
    ")\n",
    "\n",
    "with load_run(sagemaker_session=sagemaker_session, experiment_name=lab_6_experiment_name, run_name=run_name) as run:\n",
    "# Tune the model\n",
    "    tuner.fit(\n",
    "        inputs = data_inputs,\n",
    "        job_name = lab_6_experiment_name,\n",
    "    )\n",
    "    run_component_analytics = ExperimentAnalytics(\n",
    "    experiment_name=lab_6_experiment_name,\n",
    "    search_expression={\n",
    "                        \"Filters\": [{\n",
    "                                    \"Name\":\"TrialComponentName\",\n",
    "                                    \"Operator\":\"Contains\",\n",
    "                                    \"Value\":\"sagemaker\"\n",
    "                                    }]},\n",
    "    sagemaker_session=Session(sess, sm),\n",
    ")\n",
    "run_component_analytics.dataframe()[\"validation:logloss - Last\"].plot(kind=\"bar\", title=\"validation:logloss - Max\", xlabel=\"training job\", ylabel=\"logloss_max\")\n",
    " \n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.3.4: evaluar el rendimiento del modelo después del ajuste\n",
    "\n",
    "En SageMaker Studio, también puede crear gráficos para evaluar sus trabajos de ajuste. Por ejemplo, después de ejecutar el trabajo de entrenamiento de pruebas del laboratorio 6, puede observar su valor objetivo, **validation:auc_max**, en forma de gráfico.\n",
    "\n",
    "![Una imagen de los gráficos de validation:error_max en SageMaker Studio.](Task_2_3_4.png)\n",
    "\n",
    "En este laboratorio, visualice los resultados del mejor trabajo de ajuste usando gráficos en el cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_experiment_analytics \n",
    "run_component_analytics = ExperimentAnalytics(\n",
    "    experiment_name=lab_6_experiment_name,\n",
    "    sagemaker_session=Session(sess, sm),\n",
    ")\n",
    "\n",
    "run_component_analytics.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize-tuning-results-auc-max\n",
    "if run_component_analytics.dataframe()[\"validation:auc - Max\"].iloc[1] != 0:\n",
    "    run_component_analytics.dataframe()[\"validation:auc - Max\"].plot(kind=\"bar\", title=\"validation:auc - Max\", xlabel=\"training job\", ylabel=\"auc_max\").set_ylim([0.8, 1]);\n",
    "else:\n",
    "    run_component_analytics.dataframe()[\"validation:auc - Last\"].plot(kind=\"bar\", title=\"validation:auc - Max\", xlabel=\"training job\", ylabel=\"auc_max\").set_ylim([0.8, 1]);\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize-tuning-results-auc-max-scatter\n",
    "N = 12\n",
    "if run_component_analytics.dataframe()[\"validation:auc - Max\"].iloc[1] != 0:\n",
    "    x = run_component_analytics.dataframe().sort_values(by=['TrialComponentName'])[\"validation:auc - Max\"];\n",
    "else:\n",
    "    x = run_component_analytics.dataframe().sort_values(by=['TrialComponentName'])[\"validation:auc - Last\"];\n",
    "y = run_component_analytics.dataframe().sort_values(by=['TrialComponentName'])[\"num_round\"]\n",
    "\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "plt.title(\"auc_max by num_round\")\n",
    "plt.xlabel(\"validation:auc - Max\")\n",
    "plt.ylabel(\"num_round\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, puede imprimir el mejor trabajo de ajuste según su métrica objetiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print-best\n",
    "tuner.best_training_job()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.3.5: graficar las métricas del experimento con funciones incorporadas de SageMaker Studio\n",
    "\n",
    "El método mencionado anteriormente crea gráficos a partir de métricas del experimento mediante el uso de celdas insertadas del cuaderno. Una opción diferente es trazar algunas de las métricas del experimento usando funciones dentro de SageMaker Studio. Ahora que el experimento se ejecutó al menos una vez, cree un nuevo gráfico de barras en SageMaker Studio.\n",
    "\n",
    "La próxima tarea abre una nueva pestaña en SageMaker Studio. Para seguir esas instrucciones, utilice las siguientes opciones:\n",
    "- **Opción 1**: ver las pestañas una al lado de la otra. Para crear una vista de pantalla dividida de la ventana principal de SageMaker Studio, arrastre la pestaña **lab_6.ipynb** hacia el lado o seleccione (con el botón derecho del mouse) la pestaña **lab_6.ipynb** y elija **New View for Notebook** (Nueva vista para el cuaderno). Ahora, puede ver las instrucciones mientras explora los artefactos.\n",
    "- **Opción 2**: alternar entre las pestañas de SageMaker Studio para seguir estas instrucciones. Cuando termine de explorar los artefactos, seleccione la pestaña **lab_6.ipynb** para volver al cuaderno.\n",
    "\n",
    "1. Seleccione el ícono de **SageMaker Home** (Inicio de SageMaker).\n",
    "1. Ejecute **Experiments** (Experimentos).\n",
    "\n",
    "Verá la pestaña **Experiments** (Experimentos) en SageMaker Studio.\n",
    "\n",
    "1. Seleccione el experimento que comienza con *lab-6-*.\n",
    "\n",
    "SageMaker Studio muestra la lista de **ejecuciones** incluidas en ese experimento.\n",
    "\n",
    "1. Seleccione la opción en la columna **Name** (Nombre) junto a todas las ejecuciones disponibles que están asociadas con el trabajo de ajuste de hiperparámetros.\n",
    "1. Desactive la \n",
    "1. Elija <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">Analyze</span> (Analizar).\n",
    "\n",
    "En SageMaker Studio, verá la pestaña **Run Analyze Chart** (Ejecutar gráfico de análisis).\n",
    "\n",
    "1. En la mitad inferior de la pestaña, seleccione <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">+ Add Chart</span> (+ Agregar gráfico) en la sección de gráficos.\n",
    "1. Elija **Bar** (Barras).\n",
    "\n",
    "Verá la pestaña **Add Chart** (Agregar gráfico) en SageMaker Studio.\n",
    "\n",
    "1. Para **Y-axis** (eje Y), seleccione **min_child_weight**.\n",
    "1. Elija <span style=\"background-color:#73cdf9; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-radius:2px; border-width:3px; margin-right:5px; white-space:nowrap\">Create</span> (Crear).\n",
    "\n",
    "En la sección de gráficos, se guardará un gráfico de barras que muestra *min_child_weight* por *ejecución* en el experimento.\n",
    "\n",
    "1. Repita este proceso y cree un nuevo gráfico de barras para la métrica **train:auc**.\n",
    "1. Repita este proceso y cree un nuevo gráfico de barras para la métrica **validation:auc**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "\n",
    "¡Felicitaciones! Usó SageMaker Experiments para entrenar y ajustar modelos. En el siguiente laboratorio, use SageMaker Debugger para obtener información sobre posibles problemas durante el entrenamiento de un modelo.\n",
    "\n",
    "### Limpieza\n",
    "\n",
    "Ha completado este cuaderno. Para ir a la siguiente parte del laboratorio, complete estos pasos:\n",
    "\n",
    "- Cierre este archivo de cuaderno.\n",
    "- Regrese a la sesión de laboratorio y continúe con la **Conclusión**."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "741de909edea0d5644898c592544ed98bede62b404d20772e5c4abc3c2f12566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
