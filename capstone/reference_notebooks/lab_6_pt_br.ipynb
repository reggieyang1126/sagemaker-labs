{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 2: Usar o SageMaker Experiments\n",
    "\n",
    "Neste laboratório, você vai configurar um experimento usando o Amazon SageMaker Experiments. Você vai treinar um modelo de machine learning (ML) usando o XGBoost, executar o ajuste de hiperparâmetro para testar várias configurações de hiperparâmetros e produzir um modelo mais preciso, bem como avaliar o desempenho do modelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 2.1: Configuração do ambiente\n",
    "\n",
    "Antes de iniciar o treinamento do modelo, instale todas as dependências necessárias.\n",
    "\n",
    "\n",
    "Consulte [Gerenciar o machine learning com o Amazon SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html#experiments-features) para saber mais sobre os recursos do SageMaker Experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install-dependencies\n",
    "\n",
    "import boto3\n",
    "import io\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import sagemaker\n",
    "import sys\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Image\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.experiments.run import Run, load_run\n",
    "#from sagemaker.utils import unique_name_from_base  #could be used instead of the date-time append approach, to create a unique Experiment name.\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from time import gmtime, strftime\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sess = boto3.Session()\n",
    "sm = sess.client('sagemaker')\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = 'sagemaker/mlasms'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois, importe os conjuntos de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import-dataset\n",
    "lab_test_data = pd.read_csv('adult_data_processed.csv')\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "lab_test_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você vai dividir o conjunto de dados nos seguintes conjuntos de dados: treinamento (70%), validação (20%) e teste (10%). Os conjuntos de dados de treinamento e validação são usados durante o treinamento. O conjunto de dados de teste é usado na avaliação do modelo após a implantação.\n",
    "\n",
    "Para fazer o treinamento usando o SageMaker, você precisa converter os conjuntos de dados no formato libSVM ou CSV. Este laboratório usa o formato CSV para o treinamento. \n",
    "\n",
    "Consulte [Algoritmo XGBoost](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) para saber mais sobre o algoritmo XGBoost. \n",
    "Consulte [Interface de entrada/saída do algoritmo XGBoost](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html#InputOutput-XGBoost) para saber mais sobre a interface de entrada/saída do algoritmo XGBoost.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split-dataset\n",
    "train_data, validation_data, test_data = np.split(\n",
    "    lab_test_data.sample(frac=1, random_state=1729),\n",
    "    [int(0.7 * len(lab_test_data)), int(0.9 * len(lab_test_data))],\n",
    ")\n",
    "\n",
    "train_data.to_csv('train_data.csv', index=False, header=False)\n",
    "validation_data.to_csv('validation_data.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você criou dois arquivos de conjuntos de dados, chamados *train_data.csv* e *validation_data.csv*. \n",
    "Carregue esses arquivos de conjunto de dados no Amazon Simple Storage Service (Amazon S3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload-dataset\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "train_path = S3Uploader.upload('train_data.csv', 's3://{}/{}'.format(bucket, prefix))\n",
    "validation_path = S3Uploader.upload('validation_data.csv', 's3://{}/{}'.format(bucket, prefix))\n",
    "\n",
    "train_input = TrainingInput(train_path, content_type='text/csv')\n",
    "validation_input = TrainingInput(validation_path, content_type='text/csv')\n",
    "\n",
    "data_inputs = {\n",
    "    'train': train_input,\n",
    "    'validation': validation_input\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 2.2: Criar um experimento e executar um trabalho de treinamento inicial\n",
    "\n",
    "Use o SageMaker Experiments para organizar, monitorar, comparar e avaliar os experimentos de treinamento do modelo de ML com vários componentes de treinamento. Consulte [SageMaker Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html) para saber mais sobre o SageMaker Experiments. No SageMaker Experiments, esses componentes incluem conjuntos de dados, algoritmos, hiperparâmetros e métricas. \n",
    "\n",
    "Nesta tarefa, você vai:\n",
    "- Criar e monitorar o experimento no Amazon SageMaker Studio.\n",
    "- Criar uma execução para monitorar entradas, parâmetros e métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, crie um nome para o experimento e escreva uma descrição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create unique experiment name\n",
    "create_date = strftime(\"%m%d%H%M\")\n",
    "\n",
    "lab_6_experiment_name = \"lab-6-{}\".format(create_date)\n",
    "description = \"Using SageMaker Experiments with the Adult dataset.\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois, defina os valores opcionais de um nome de execução e tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create initial run_name\n",
    "run_name = \"lab-6-run-{}\".format(create_date)\n",
    "\n",
    "# define a run_tag\n",
    "run_tags = [{'Key': 'lab-6', 'Value': 'lab-6-run'}]\n",
    "\n",
    "print(f\"Experiment name - {lab_6_experiment_name},  run name - {run_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 2.3: Treinar e ajustar o modelo usando o algoritmo XGBoost\n",
    "\n",
    "O experimento está configurado e pronto para o treinamento. Quando o treinamento for concluído, você poderá analisar os resultados no SageMaker Studio. Nesta tarefa, você vai: \n",
    "\n",
    "- Treinar o modelo do XGBoost.\n",
    "- Analisar os experimentos no SageMaker Studio.\n",
    "- Ajustar o modelo com hiperparâmetros.\n",
    "- Analisar os resultados do ajuste no SageMaker Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.3.1: Treinar o modelo do XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, treine o modelo usando o algoritmo XGBoost e o experimento que você criou. \n",
    "\n",
    "Os hiperparâmetros que você define são os seguintes:\n",
    "- **eta**: redução do tamanho da etapa usado em atualizações para evitar sobreajuste. Após cada etapa de aumento, você pode obter diretamente os pesos dos novos recursos. \n",
    "- **gamma**: redução de perda mínima necessária para criar uma partição adicional em um nó de folha da árvore. Quanto maior, mais conservador é o algoritmo.\n",
    "O parâmetro eta reduz os pesos do recurso para deixar o processo de aumento mais conservador.\n",
    "- **max_depth**: profundidade máxima de uma árvore. O aumento desse valor aumenta a complexidade do modelo e a probabilidade de sobreajuste.\n",
    "- **min_child_weight**: soma mínima do peso da instância (hessiano) necessária em um filho. Se a etapa de partição em árvore resultar em um nó folha com a soma do peso da instância menos min_child_weight, o processo de build não fará mais nenhum particionamento. Em modelos de regressão linear, isso corresponde a um número mínimo de instâncias necessárias em cada nó. Quanto maior o algoritmo, mais conservador ele é.\n",
    "- **num_round**: o número de rodadas (árvores) usadas para o aumento. O aumento das árvores pode aumentar a precisão do modelo, mas também aumenta o risco de sobreajuste.\n",
    "- **objective**: especifica a tarefa de aprendizado e o objetivo de aprendizado correspondente.\n",
    "- **subsample**: taxa de subamostragem da instância de treinamento. A configuração da taxa como 0,5 significa que o XGBoost coleta aleatoriamente metade das instâncias de dados para aumentar as árvores. Isso evita o sobreajuste.\n",
    "- **verbosity**: o detalhamento das mensagens de impressão. Os valores válidos são 0 (silencioso), 1 (aviso), 2 (informativo) e 3 (depuração).\n",
    "\n",
    "O treinamento exige cerca de três a quatro minutos para ser executado.\n",
    "\n",
    "Consulte [Hiperparâmetros](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html) para saber mais sobre os hiperparâmetros do XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "container = image_uris.retrieve(framework='xgboost',region=boto3.Session().region_name,version='1.5-1')\n",
    "\n",
    "# initialize hyperparameters\n",
    "eta=0.2\n",
    "gamma=4\n",
    "max_depth=5\n",
    "min_child_weight=6\n",
    "num_round=800\n",
    "objective='binary:logistic'\n",
    "subsample=0.8\n",
    "verbosity=0\n",
    "\n",
    "hyperparameters = {\n",
    "        \"max_depth\":max_depth,\n",
    "        \"eta\":eta,\n",
    "        \"gamma\":gamma,\n",
    "        \"min_child_weight\":min_child_weight,\n",
    "        \"subsample\":subsample,\n",
    "        \"verbosity\":verbosity,\n",
    "        \"objective\":objective,\n",
    "        \"num_round\":num_round\n",
    "}\n",
    "\n",
    "# Set up the estimator\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role, \n",
    "    instance_count=1, \n",
    "    instance_type='ml.m5.xlarge',\n",
    "    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    EnableSageMakerMetricsTimeSeries=True,\n",
    "    hyperparameters=hyperparameters,\n",
    "    tags = run_tags\n",
    ")\n",
    "\n",
    "\n",
    "#Run the training job link to Experiment.\n",
    "with Run(\n",
    "    experiment_name=lab_6_experiment_name,\n",
    "    run_name=run_name,\n",
    "    tags=run_tags,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "\n",
    "    run.log_parameters({\n",
    "                        \"eta\": eta, \n",
    "                        \"gamma\": gamma, \n",
    "                        \"max_depth\": max_depth,\n",
    "                        \"min_child_weight\": min_child_weight,\n",
    "                        \"num_round\": num_round,\n",
    "                        \"objective\": objective,\n",
    "                        \"subsample\": subsample,\n",
    "                        \"verbosity\": verbosity\n",
    "                       })\n",
    "    \n",
    "#    you may also specify metrics to log\n",
    "#    run.log_metric(name=\"\", value=x)\n",
    "\n",
    "# Train the model associating the training run with the current \"experiment\"\n",
    "    xgb.fit(\n",
    "        inputs = data_inputs\n",
    "    ) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.3.2: Avaliar o desempenho do modelo antes do ajuste\n",
    "\n",
    "No SageMaker Studio, você pode criar gráficos para avaliar os trabalhos de treinamento. Por exemplo, depois de executar os experimentos do laboratório 6, você pode examinar o valor de validation:logloss_max em um formato de gráfico.\n",
    "\n",
    "Neste laboratório, você pode criar gráficos de métricas adicionais diretamente na linha do notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize-training-results-table\n",
    "run_component_analytics = ExperimentAnalytics(\n",
    "    experiment_name=lab_6_experiment_name,\n",
    "    search_expression={\n",
    "                        \"Filters\": [{\n",
    "                                    \"Name\":\"TrialComponentName\",\n",
    "                                    \"Operator\":\"Contains\",\n",
    "                                    \"Value\":\"sagemaker\"\n",
    "                                    }]},\n",
    "    sagemaker_session=Session(sess, sm),\n",
    ")\n",
    "run_component_analytics.dataframe()[\"validation:logloss - Last\"].plot(kind=\"bar\", title=\"validation:logloss - Max\", xlabel=\"training job\", ylabel=\"logloss_max\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.3.3 Ajustar o modelo com hiperparâmetros\n",
    "\n",
    "Você realizou o treinamento do modelo usando o SageMaker Experiments com sucesso. Durante o treinamento, você também pode configurar o SageMaker para usar hiperparâmetros a fim de afetar o desempenho do modelo treinado de maneira significativa. O SageMaker Studio inclui várias opções de ajuste de hiperparâmetros comuns para o treinamento do modelo. Embora o teste de inúmeros parâmetros possa variar em eficácia dependendo do conjunto de dados usado, ele também pode exigir uma quantia significativa de tempo e esforço para criar o melhor modelo.\n",
    "\n",
    "O ajuste automático de modelo do SageMaker automatiza a seleção de hiperparâmetros para otimizar o treinamento. Consulte [ajuste automático de modelo](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html) para saber mais sobre o ajuste automático de modelo. Para usá-lo, especifique um intervalo ou uma lista de valores possíveis para cada hiperparâmetro escolhido para o ajuste. O ajuste automático de modelo do SageMaker executa vários trabalhos de treinamento com várias configurações de hiperparâmetro. Depois, ele avalia os resultados de cada trabalho com base em uma métrica de objetivo especificada e seleciona as configurações de hiperparâmetro para novas tentativas com base nos resultados anteriores. Para cada trabalho de ajuste, você especifica um número máximo de trabalhos de treinamento e o ajuste é concluído quando esse número é atingido.\n",
    "\n",
    "Os intervalos de hiperparâmetros que você precisa definir são os seguintes:\n",
    "- **alpha**: termo de regularização L1 em pesos. O aumento desse valor deixa o modelo mais conservador.\n",
    "- **eta**: redução do tamanho da etapa usado em atualizações para evitar sobreajuste. Após cada etapa de aumento, você pode obter diretamente os pesos dos novos recursos. O parâmetro eta reduz os pesos do recurso para deixar o processo de aumento mais conservador.\n",
    "- **max_depth**: profundidade máxima de uma árvore. O aumento desse valor aumenta a complexidade do modelo e a probabilidade de sobreajuste.\n",
    "- **min_child_weight**: soma mínima do peso da instância (hessiano) necessária em um filho. Se a etapa de partição em árvore resultar em um nó folha com a soma do peso da instância menos min_child_weight, o processo de build não fará mais nenhum particionamento. Em modelos de regressão linear, isso corresponde a um número mínimo de instâncias necessárias em cada nó. Quanto maior o algoritmo, mais conservador ele é.\n",
    "- **num_round**: o número de rodadas (árvores) usadas para o aumento. O aumento das árvores pode aumentar a precisão do modelo, mas também aumenta o risco de sobreajuste.\n",
    "\n",
    "O ajuste exige cerca de cinco minutos para ser concluído.\n",
    "\n",
    "Consulte [intervalos de hiperparâmetros](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html) para saber mais sobre os hiperparâmetros do XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune-model\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "# Setup the hyperparameter ranges\n",
    "hyperparameter_ranges = {\n",
    "    'alpha': ContinuousParameter(0, 2),\n",
    "    'eta': ContinuousParameter(0, 1),\n",
    "    'max_depth': IntegerParameter(1, 10),\n",
    "    'min_child_weight': ContinuousParameter(1, 10),\n",
    "    'num_round': IntegerParameter(100, 1000)\n",
    "}\n",
    "# Define the target metric and the objective type (max/min)\n",
    "objective_metric_name = 'validation:auc'\n",
    "objective_type='Maximize'\n",
    "# Define the HyperparameterTuner\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator = xgb,\n",
    "    objective_metric_name = objective_metric_name,\n",
    "    hyperparameter_ranges = hyperparameter_ranges,\n",
    "    objective_type = objective_type,\n",
    "    max_jobs=12,\n",
    "    max_parallel_jobs=4,\n",
    "    early_stopping_type='Auto',\n",
    ")\n",
    "\n",
    "with load_run(sagemaker_session=sagemaker_session, experiment_name=lab_6_experiment_name, run_name=run_name) as run:\n",
    "# Tune the model\n",
    "    tuner.fit(\n",
    "        inputs = data_inputs,\n",
    "        job_name = lab_6_experiment_name,\n",
    "    )\n",
    "    run_component_analytics = ExperimentAnalytics(\n",
    "    experiment_name=lab_6_experiment_name,\n",
    "    search_expression={\n",
    "                        \"Filters\": [{\n",
    "                                    \"Name\":\"TrialComponentName\",\n",
    "                                    \"Operator\":\"Contains\",\n",
    "                                    \"Value\":\"sagemaker\"\n",
    "                                    }]},\n",
    "    sagemaker_session=Session(sess, sm),\n",
    ")\n",
    "run_component_analytics.dataframe()[\"validation:logloss - Last\"].plot(kind=\"bar\", title=\"validation:logloss - Max\", xlabel=\"training job\", ylabel=\"logloss_max\")\n",
    " \n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.3.4: Avaliar o desempenho do modelo após o ajuste\n",
    "\n",
    "No SageMaker Studio, você também pode criar gráficos para avaliar os trabalhos de ajuste. Por exemplo, depois de executar o trabalho de treinamento lab-6-trial, você poderá consultar o valor de objetivo, o **validation:auc_max**, em formato de gráfico.\n",
    "\n",
    "![Uma imagem dos gráficos validation:error_max no SageMaker Studio.](Task_2_3_4.png)\n",
    "\n",
    "Neste laboratório, você vai exibir os resultados do melhor trabalho de ajuste e visualizá-los usando gráficos no notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_experiment_analytics \n",
    "run_component_analytics = ExperimentAnalytics(\n",
    "    experiment_name=lab_6_experiment_name,\n",
    "    sagemaker_session=Session(sess, sm),\n",
    ")\n",
    "\n",
    "run_component_analytics.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize-tuning-results-auc-max\n",
    "if run_component_analytics.dataframe()[\"validation:auc - Max\"].iloc[1] != 0:\n",
    "    run_component_analytics.dataframe()[\"validation:auc - Max\"].plot(kind=\"bar\", title=\"validation:auc - Max\", xlabel=\"training job\", ylabel=\"auc_max\").set_ylim([0.8, 1]);\n",
    "else:\n",
    "    run_component_analytics.dataframe()[\"validation:auc - Last\"].plot(kind=\"bar\", title=\"validation:auc - Max\", xlabel=\"training job\", ylabel=\"auc_max\").set_ylim([0.8, 1]);\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize-tuning-results-auc-max-scatter\n",
    "N = 12\n",
    "if run_component_analytics.dataframe()[\"validation:auc - Max\"].iloc[1] != 0:\n",
    "    x = run_component_analytics.dataframe().sort_values(by=['TrialComponentName'])[\"validation:auc - Max\"];\n",
    "else:\n",
    "    x = run_component_analytics.dataframe().sort_values(by=['TrialComponentName'])[\"validation:auc - Last\"];\n",
    "y = run_component_analytics.dataframe().sort_values(by=['TrialComponentName'])[\"num_round\"]\n",
    "\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "plt.title(\"auc_max by num_round\")\n",
    "plt.xlabel(\"validation:auc - Max\")\n",
    "plt.ylabel(\"num_round\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, você poderá imprimir o melhor trabalho de ajuste com base na métrica de objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print-best\n",
    "tuner.best_training_job()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.3.5: Métricas de experimento do gráfico com o SageMaker Studio usando recursos integrados\n",
    "\n",
    "O método mencionado cria gráficos por meio de métricas de experimento usando células na linha do notebook. Uma opção adicional é criar gráficos de algumas métricas de experimento usando recursos no SageMaker Studio. Agora que o experimento já foi executado pelo menos uma vez, crie um novo gráfico de barras no SageMaker Studio.\n",
    "\n",
    "A próxima tarefa abre uma nova aba no SageMaker Studio. Para seguir essas orientações, escolha uma das seguintes opções:\n",
    "- **Opção 1:** visualizar as abas lado a lado. Para criar uma visualização de tela dividida por meio da janela principal do SageMaker Studio, arraste a aba **lab_6.ipynb** para a lateral ou escolha (clique com o botão direito) a aba **lab_6.ipynb** e selecione **New View for Notebook** (Nova visualização do notebook). Agora, as orientações ficam visíveis enquanto você explora os artefatos.\n",
    "- **Opção 2:** alternar entre as abas do SageMaker Studio para seguir essas instruções. Ao terminar de explorar os artefatos, retorne ao notebook selecionando a aba **lab_6.ipynb**.\n",
    "\n",
    "1. Selecione o ícone **Página inicial do SageMaker**.\n",
    "1. Escolha **Experiments** (Experimentos).\n",
    "\n",
    "O SageMaker Studio exibe a aba **Experiments** (Experimentos).\n",
    "\n",
    "1. Selecione o experimento que começa com *lab-6-*.\n",
    "\n",
    "O SageMaker Studio exibe a lista de **Runs** (Execuções) incluída nesse experimento.\n",
    "\n",
    "1. Selecione a opção na coluna **Name** (Nome) ao lado de todas as execuções disponíveis associadas ao trabalho de ajuste de hiperparâmetro.\n",
    "1. Desmarque \n",
    "1. Escolha <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">Analisar</span>.\n",
    "\n",
    "O SageMaker Studio exibe a aba **Run Analyze Chart** (Executar gráfico de análise).\n",
    "\n",
    "1. Na metade inferior da aba, na seção de gráfico, escolha <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">+ Add Chart (Adicionar gráfico)</span>.\n",
    "1. Escolha **Bar** (Barras).\n",
    "\n",
    "O SageMaker Studio exibe a janela **Add Chart** (Adicionar gráfico).\n",
    "\n",
    "1. Para o **Y-axis** (Eixo Y), escolha **min_child_weight**.\n",
    "1. Selecione <span style=\"background-color:#73cdf9; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-radius:2px; border-width:3px; margin-right:5px; white-space:nowrap\">Criar</span>.\n",
    "\n",
    "Agora, um gráfico de barras mostrando *min_child_weight* por *run* no experimento está salvo na seção de gráficos.\n",
    "\n",
    "1. Repita esse processo e crie um novo gráfico de barras para a métrica **train:auc**.\n",
    "1. Repita esse processo e crie um novo gráfico de barras para a métrica **validation:auc**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão\n",
    "\n",
    "Parabéns! Você usou o SageMaker Experiments para treinar e ajustar modelos. No próximo laboratório, você vai usar o SageMaker Debugger para obter informações sobre possíveis problemas ao treinar um modelo.\n",
    "\n",
    "## Limpeza\n",
    "\n",
    "Você concluiu este notebook. Passe para a próxima parte do laboratório da seguinte forma:\n",
    "\n",
    "- Feche este arquivo de notebook.\n",
    "- Retorne à sessão do laboratório e continue com a **Conclusão**."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "741de909edea0d5644898c592544ed98bede62b404d20772e5c4abc3c2f12566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
