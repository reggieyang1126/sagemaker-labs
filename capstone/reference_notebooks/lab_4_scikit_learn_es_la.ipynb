{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 3: realizar el procesamiento de datos con SageMaker Processing y el contenedor scikit-learn integrado\n",
    "\n",
    "En este cuaderno, configure el entorno necesario para ejecutar un script de scikit-learn usando una imagen de Docker proporcionada y mantenida por SageMaker Processing. \n",
    "\n",
    "Luego, use la clase **SKLearnProcessor** del SDK para Python de SageMaker para definir y ejecutar un trabajo de procesamiento de scikit-learn.\n",
    "\n",
    "Por último, valide los resultados del procesamiento de datos guardados en Amazon Simple Storage Service (Amazon S3).\n",
    "\n",
    "**Nota:** El script de procesamiento realiza un procesamiento de datos básico, como quitar duplicados, transformar la columna objetivo en una que contiene dos etiquetas y hacer una codificación one-hot y una división 80-20 para producir conjuntos de datos de entrenamiento y pruebas. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 3.1: configuración del entorno\n",
    "\n",
    "En esta tarea, instale los paquetes y las dependencias necesarios. \n",
    "\n",
    "Configure un bucket de Amazon S3 para almacenar las salidas del trabajo de procesamiento y obtenga el rol de ejecución para ejecutar el trabajo de SageMaker Processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install-dependencies\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "sagemaker_logger = logging.getLogger(\"sagemaker\")\n",
    "sagemaker_logger.setLevel(logging.INFO)\n",
    "sagemaker_logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "#Execution role to run the SageMaker Processing job\n",
    "role = sagemaker.get_execution_role()\n",
    "print(\"SageMaker Execution Role: \", role)\n",
    "\n",
    "#S3 bucket to read the SKLearn processing script and writing processing job outputs\n",
    "s3 = boto3.resource('s3')\n",
    "for buckets in s3.buckets.all():\n",
    "    if 'labdatabucket' in buckets.name:\n",
    "        bucket = buckets.name\n",
    "print(\"Bucket: \", bucket)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 3.2: ejecutar el trabajo de SageMaker Processing\n",
    "\n",
    "En esta tarea, importe y revise el conjunto de datos preprocesado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import-data\n",
    "prefix = 'data/input'\n",
    "\n",
    "S3Downloader.download(s3_uri=f\"s3://{bucket}/{prefix}/adult_data.csv\", local_path= 'data/')\n",
    "\n",
    "shape=pd.read_csv(\"data/adult_data.csv\", header=None)\n",
    "shape.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este laboratorio, se realizarán las transformaciones de datos, como eliminar los duplicados, transformar la columna objetivo en una columna que contiene dos etiquetas y hacer la codificación one-hot de las funciones categóricas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, cree una clase SKLearnProcessor para definir y ejecutar un script de procesamiento de scikit-learn como un trabajo de procesamiento. Consulte [SKLearnProcessor para scikit-learn Sagemaker](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html#sagemaker.sklearn.processing.SKLearnProcessor) para obtener más información sobre esta clase.\n",
    "\n",
    "Para crear la clase SKLearnProcessor, configure los siguientes parámetros:\n",
    "- **base_job_name**: prefijo para el nombre del trabajo de procesamiento\n",
    "- **framework_version**: versión de scikit-learn\n",
    "- **role**: rol de ejecución de SageMaker\n",
    "- **instance_count**: cantidad de instancias para ejecutar el trabajo de procesamiento\n",
    "- **instance_type**: tipo de instancia de Amazon Elastic Compute Cloud (Amazon EC2) usada para el trabajo de procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scikit-learn-processor\n",
    "import os\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "# create a SKLearnProcessor\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    base_job_name=\"sklearn-preprocessor\",\n",
    "    framework_version=\"0.20.0\", \n",
    "    role=role, \n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A continuación, use el método **SKLearnProcessor.run()** para ejecutar un script **sklearn_preprocessing.py** como trabajo de procesamiento. \n",
    "\n",
    "Para ejecutar el trabajo de procesamiento, configure los siguientes parámetros:\n",
    "- **code**: ruta del script de preprocesamiento \n",
    "- **inputs and outputs**: ruta de entradas y salidas para el script de preprocesamiento (ubicaciones de entradas y salidas de Amazon S3)\n",
    "- **arguments**: argumentos de línea de comandos para el script de preprocesamiento (como una relación de división para entrenamiento y prueba)\n",
    "\n",
    "El tiempo para completar este trabajo de procesamiento es de aproximadamente 4 a 5 minutos. Mientras se ejecuta el trabajo, puede revisar la fuente para el script del preprocesamiento (que se configuró como parte de este laboratorio) abriendo el archivo **sklearn_preprocessing.py** desde el navegador de archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing-job\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "# Amazon S3 path prefix\n",
    "input_raw_data_prefix = \"data/input\"\n",
    "output_preprocessed_data_prefix = \"data/output\"\n",
    "scripts_prefix = \"scripts/smstudiofiles\"\n",
    "logs_prefix = \"logs\"\n",
    "\n",
    "# Run the processing job\n",
    "sklearn_processor.run(\n",
    "    code=\"s3://\" + os.path.join(bucket, scripts_prefix, \"sklearn_preprocessing.py\"),\n",
    "    inputs=[ProcessingInput(source=\"s3://\" + os.path.join(bucket, input_raw_data_prefix, \"adult_data.csv\"),\n",
    "                            destination=\"/opt/ml/processing/input\")],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train_data\", \n",
    "                         source=\"/opt/ml/processing/train\",\n",
    "                         destination=\"s3://\" + os.path.join(bucket, output_preprocessed_data_prefix, \"train\")),\n",
    "        ProcessingOutput(output_name=\"test_data\", \n",
    "                         source=\"/opt/ml/processing/test\",\n",
    "                         destination=\"s3://\" + os.path.join(bucket, output_preprocessed_data_prefix, \"test\")),\n",
    "    ],\n",
    "    arguments=[\"--train-test-split-ratio\", \"0.2\"],\n",
    ")\n",
    "\n",
    "print(\"SKLearn Processing Job Completed.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 3.3: validar los resultados del procesamiento de datos\n",
    "\n",
    "En esta tarea, debe validar la salida del trabajo de procesamiento que ejecutó mediante la revisión de las primeras cinco filas de los conjuntos de datos de salida de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view-train-dataset\n",
    "print(\"Top 5 rows from s3://{}/{}/train/\".format(bucket, output_preprocessed_data_prefix))\n",
    "!aws s3 cp --quiet s3://$bucket/$output_preprocessed_data_prefix/train/train_features.csv - | head -n5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view-validation-dataset\n",
    "print(\"Top 5 rows from s3://{}/{}/validation/\".format(bucket, output_preprocessed_data_prefix))\n",
    "!aws s3 cp --quiet s3://$bucket/$output_preprocessed_data_prefix/test/test_features.csv - | head -n5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "\n",
    "¡Felicitaciones! Usó SageMaker Processing para crear correctamente un trabajo de procesamiento de scikit-learn usando el SDK para Python de SageMaker y ejecutó el trabajo de procesamiento.\n",
    "\n",
    "La siguiente tarea del laboratorio se enfoca en el procesamiento de datos usando SageMaker Processing con su contenedor de procesamiento.\n",
    "\n",
    "### Limpieza\n",
    "\n",
    "Ha completado este cuaderno. Para ir a la siguiente parte del laboratorio, complete estos pasos:\n",
    "\n",
    "- Cierre este archivo de cuaderno.\n",
    "- Regrese a la sesión de laboratorio y continúe con la **Tarea 4: realizar el procesamiento de datos con su propio contenedor**."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "741de909edea0d5644898c592544ed98bede62b404d20772e5c4abc3c2f12566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
