{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 3: Implantar um modelo para inferência sem servidor\n",
    "\n",
    "## Tarefa 3.1: Configuração do ambiente\n",
    "\n",
    "Instale os pacotes e as dependências."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install-dependencies\n",
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker_datawrangler\n",
    "import sys\n",
    "import time\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sess = boto3.Session()\n",
    "sm = sess.client('sagemaker')\n",
    "prefix = 'sagemaker/mlasms'\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "s3_client = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salve o modelo do laboratório de treinamento e ajuste no bucket-padrão do Amazon Simple Storage Service (Amazon S3). Configure um modelo usando **create_model** e configure **ModelDataUrl** para referenciar o modelo treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set-up-model\n",
    "# Upload the model to your Amazon S3 bucket\n",
    "s3_client.upload_file(\n",
    "    Filename=\"model.tar.gz\", Bucket=bucket, Key=f\"{prefix}/models/model.tar.gz\"\n",
    ")\n",
    "\n",
    "# Set a date to use in the model name\n",
    "create_date = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "model_name = 'income-model-{}'.format(create_date)\n",
    "\n",
    "# Retrieve the container image\n",
    "container = sagemaker.image_uris.retrieve(\n",
    "    region=boto3.Session().region_name, \n",
    "    framework='xgboost', \n",
    "    version='1.5-1'\n",
    ")\n",
    "\n",
    "# Set up the model\n",
    "income_model = sm.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = {\n",
    "        'Image': container,\n",
    "        'ModelDataUrl': f's3://{bucket}/{prefix}/models/model.tar.gz',\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 3.2: Criar um endpoint por meio do modelo retreinado e sintetizado fornecido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Amazon SageMaker Serverless Inference é uma opção de inferência com propósito definido que ajuda a implantar e dimensionar modelos de machine learning (ML). O Serverless Inference é ideal para cargas de trabalho que apresentam períodos de ociosidade entre os picos de tráfego e que podem tolerar inicialização a frio. Os endpoints sem servidor iniciam recursos de computação automaticamente e aumentam ou reduzem a quantidade dependendo do tráfego. Portanto, você não precisa escolher os tipos de instância nem gerenciar as políticas de scaling. Isso elimina o trabalho pesado de selecionar e gerenciar servidores. O Serverless Inference se integra ao AWS Lambda para oferecer alta disponibilidade, tolerância a falhas integrada e auto scaling.\n",
    "\n",
    "Há três etapas para criar um endpoint sem servidor usando o SDK Python do Amazon SageMaker. Estas etapas são as mesmas usadas para os endpoints em tempo real, mas apresentam configurações diferentes:\n",
    "1. Criar um modelo do SageMaker no SageMaker.\n",
    "2. Criar uma configuração de endpoint para um endpoint HTTPS.\n",
    "3. Criar um endpoint HTTPS.\n",
    "\n",
    "Você já criou um modelo. Agora você já pode criar uma configuração de endpoint e um endpoint. \n",
    "\n",
    "Primeiro, defina o nome da configuração de endpoint e o tamanho da memória que deseja usar. Depois, chame a API CreateEndpointConfig.\n",
    "\n",
    "Para criar uma configuração de endpoint, você precisa definir as seguintes opções:\n",
    "- **VariantName**: o nome da variante de produção (um ou mais modelos em produção).\n",
    "- **ModelName**: o nome do modelo que você deseja hospedar. Esse é o nome que você especificou quando criou o modelo.\n",
    "- **ServerlessConfig**: é nessa opção que o endpoint é definido como sem servidor. Configure o valores de **MemorySizeInMB** e **MaxConcurrency**.\n",
    "    - **MemorySizeInMB**: o tamanho de memória alocado (1024, 2048, 3072, 4096, 5120 ou 6144 MB).\n",
    "    - **MaxConcurrency**: o número de invocações simultâneas (1 a 200)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create-endpoint-configuration \n",
    "# Create an endpoint config name. Here you create one based on the date so you can search endpoints based on creation time.\n",
    "endpoint_config_name = 'income-model-serverless-endpoint-{}'.format(create_date)                              \n",
    "\n",
    "endpoint_config_response = sm.create_endpoint_config(\n",
    "   EndpointConfigName=endpoint_config_name,\n",
    "   ProductionVariants=[\n",
    "        {\n",
    "            \"ModelName\": model_name,\n",
    "            \"VariantName\": \"variant1\", # The name of the production variant\n",
    "            \"ServerlessConfig\": {\n",
    "                \"MemorySizeInMB\": 2048, # The memory size\n",
    "                \"MaxConcurrency\": 20 # Number of concurrent invocations\n",
    "            }\n",
    "        } \n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Created EndpointConfig: {endpoint_config_response['EndpointConfigArn']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, crie um endpoint. Quando você cria um endpoint sem servidor, o SageMaker provisiona e gerencia os recursos de computação. Depois, você pode fazer solicitações de inferência para o endpoint e receber previsões de modelo em resposta. O SageMaker aumenta e reduz a quantidade de recursos de computação conforme a necessidade para lidar com o tráfego da solicitação e você só para pelo que usa.\n",
    "\n",
    "Você pode escolher um contêiner fornecido pelo SageMaker ou usar o seu. Um endpoint sem servidor tem o tamanho mínimo de RAM de 1024 MB e máximo de 6144 MB. O Serverless Inference atribui automaticamente os recursos de computação proporcionais à memória selecionada.\n",
    "\n",
    "Quando o endpoint está em serviço, a função auxiliar imprime o Amazon Resource Name (ARN) do endpoint. A criação do endpoint pode exigir até sete minutos para ser executada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create-endpoint\n",
    "# The name of the endpoint. The name must be unique within an AWS Region in your AWS account.\n",
    "endpoint_name = '{}-name'.format(endpoint_config_name)\n",
    "\n",
    "create_endpoint_response = sm.create_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    EndpointConfigName=endpoint_config_name\n",
    ") \n",
    "\n",
    "def wait_for_endpoint_creation_complete(endpoint):\n",
    "    \"\"\"Helper function to wait for the completion of creating an endpoint\"\"\"\n",
    "    response = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = response.get(\"EndpointStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for Endpoint Creation\")\n",
    "        time.sleep(15)\n",
    "        response = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "        status = response.get(\"EndpointStatus\")\n",
    "\n",
    "    if status != \"InService\":\n",
    "        print(f\"Failed to create endpoint, response: {response}\")\n",
    "        failureReason = response.get(\"FailureReason\", \"\")\n",
    "        raise SystemExit(\n",
    "            f\"Failed to create endpoint {create_endpoint_response['EndpointArn']}, status: {status}, reason: {failureReason}\"\n",
    "        )\n",
    "    print(f\"Endpoint {create_endpoint_response['EndpointArn']} successfully created.\")\n",
    "\n",
    "wait_for_endpoint_creation_complete(endpoint=create_endpoint_response)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No SageMaker Studio, você pode visualizar os detalhes do endpoint na aba **Endpoints**.\n",
    "\n",
    "A próxima etapa abre uma nova aba no SageMaker Studio. Para seguir essas orientações, escolha uma das seguintes opções:\n",
    "- **Opção 1:** visualizar as abas lado a lado. Para criar uma visualização de tela dividida por meio da janela principal do SageMaker Studio, arraste a aba **serverless_inference.ipynb** para a lateral ou selecione (clique com o botão direito) a aba **serverless_inference.ipynb** e escolha **New View for Notebook** (Nova visualização do notebook). Agora, as orientações ficam visíveis enquanto você explora o endpoint.\n",
    "- **Opção 2:** alternar entre as abas do SageMaker Studio para seguir essas instruções. Ao terminar de explorar o endpoint, retorne ao notebook selecionando a aba **serverless_inference.ipynb**.\n",
    "\n",
    "1. Selecione o ícone **Página inicial do SageMaker**.\n",
    "2. Escolha **Deployments** (Implantações).\n",
    "3. Escolha **Endpoints**.\n",
    "\n",
    "O SageMaker Studio exibe a aba **Endpoints**.\n",
    "\n",
    "4. Selecione o endpoint que tem **income-model-serverless-** na coluna **Name** (Nome).\n",
    "\n",
    "Se o endpoint não aparecer, selecione o ícone de atualização até que o endpoint apareça.\n",
    "\n",
    "O SageMaker Studio exibe a aba **ENDPOINT DETAILS** (DETALHES DO ENDPOINT).\n",
    "\n",
    "5. Selecione a aba **AWS settings** (Configurações da AWS).\n",
    "\n",
    "Se você abriu o endpoint antes que a criação fosse concluída, selecione o ícone de atualização até que o **Endpoint status** (Status do endpoint) seja alterado de *Creating* para *InService*.\n",
    "\n",
    "O **Endpoint type** (Tipo de endpoint) está listado como **Serverless** (Sem servidor). A seção **Endpoint runtime settings** (Configurações de runtime do endpoint) mostra as configurações que você já escolheu no notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 3.3: Invocar um endpoint para uma inferência sem servidor com registros de clientes\n",
    "\n",
    "Depois de implantar o modelo usando os serviços de host do SageMaker, você poderá testar o modelo nesse endpoint enviando dados a ele.\n",
    "\n",
    "Se o endpoint não receber tráfego durante um tempo e de repente passar a receber novas solicitações, poderá demorar um pouco até que o endpoint ative os recursos de computação para processar as solicitações. Isto é chamado de inicialização a frio. Como os endpoints sem servidor provisionam recursos de computação sob demanda, o endpoint poderá passar por inicializações a frio. Uma inicialização a frio também pode ocorrer quando as solicitações simultâneas excedem o uso de solicitação simultânea atual. O tempo de inicialização a frio depende do tamanho do modelo, da duração do download do modelo e do tempo de inicialização do contêiner.\n",
    "\n",
    "Consulte [Serverless Inference](https://docs.aws.amazon.com/sagemaker/latest/dg/serverless-endpoints.html) para saber como funciona a inferência sem servidor e a inicialização a frio.\n",
    "\n",
    "Você recebeu vários registros de cliente adicionais. Confirme se o endpoint está funcionando invocando-o com um conjunto de registros que tenham valor de receita igual a 1 e registros com valor de receita igual a 0. Uma lista de pontuações de previsão para cada registro é gerada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoke-endpoint-serverless-records\n",
    "sagemaker_runtime = boto3.client(\"sagemaker-runtime\", region_name=region)\n",
    "\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    ContentType='text/csv',\n",
    "    EndpointName=endpoint_name, \n",
    "    Body=bytes('47,0,4,9,0,3,4,0,1,0,1902,60\\n' +\n",
    "                '53,0,0,0,0,2,4,0,1,0,0,40\\n' +\n",
    "                '44,0,0,0,2,0,1,0,1,14344,0,40\\n', 'utf-8')\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n",
    "print('\\nTesting with records that have an income value of 1:')\n",
    "print('The returned scores are: {}'.format(response['Body'].read().decode('utf-8')))\n",
    "\n",
    "start_time = time.time()\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    ContentType='text/csv',\n",
    "    EndpointName=endpoint_name, \n",
    "    Body=bytes('19,0,1,1,1,1,2,1,0,0,0,35\\n' +\n",
    "                '56,2,1,1,0,1,0,0,0,0,0,50\\n' +\n",
    "                '61,2,0,0,0,0,0,0,0,0,0,40\\n', 'utf-8')\n",
    ")\n",
    "\n",
    "print('\\nTesting with records that have an income value of 0:')\n",
    "print('The returned scores are: {}'.format(response['Body'].read().decode('utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 3.4: Excluir o endpoint\n",
    "\n",
    "A limpeza do endpoint pode ser realizada em três etapas. Primeiro, exclua o endpoint. Depois, exclua a configuração do endpoint. Por fim, se você não precisar mais do modelo implantado, exclua-o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete-resources\n",
    "# Delete endpoint\n",
    "sm.delete_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "# Delete endpoint configuration\n",
    "sm.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "                   \n",
    "# Delete model\n",
    "sm.delete_model(ModelName=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão\n",
    "\n",
    "Parabéns! Você usou o SageMaker para criar um endpoint sem servidor usando o SDK Python do SageMaker e para invocar o endpoint com sucesso.\n",
    "\n",
    "A próxima tarefa do laboratório se concentra na implantação de um modelo para inferência usando a inferência assíncrona.\n",
    "\n",
    "## Limpeza\n",
    "\n",
    "Você concluiu este notebook. Passe para a próxima parte do laboratório da seguinte forma:\n",
    "\n",
    "- Feche este arquivo de notebook.\n",
    "- Retorne à sessão do laboratório e continue na **Tarefa 4: Implantar um modelo para inferência assíncrona**."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.xlarge",
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "2e45558c452cedcb26631315a9b3b77e80a9c32d662ed25df58964b99bc5b9b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
