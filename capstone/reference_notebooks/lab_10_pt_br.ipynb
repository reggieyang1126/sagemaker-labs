{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratório 10: Usar o SageMaker Pipelines e o SageMaker Model Registry com o SageMaker Studio\n",
    "\n",
    "Neste laboratório, você vai criar e executar um Amazon SageMaker Pipeline e monitorar o progresso do pipeline. Você também vai localizar e explorar alguns artefatos que o processo de machine learning (ML) usa ou gera.\n",
    "\n",
    "Se houver tempo, você também poderá examinar os detalhes de linhagem do modelo que o pipeline gerou."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 2.1 Configuração do ambiente\n",
    "\n",
    "Antes de criar o pipeline do SageMaker, você precisa preparar o ambiente instalando os pacotes necessários, importando módulos e preparando os arquivos de suporte. Este pipeline foi projetado para usar um grupo de recursos, portanto, você também vai criar um grupo de recursos no Amazon SageMaker Feature Store e executar um fluxo do Data Wrangler para preparar o ambiente. \n",
    "\n",
    "Execute as células nesta tarefa para fazer o seguinte:\n",
    "- Instalar as dependências.\n",
    "- Importar os módulos necessários.\n",
    "- Copiar os dados e o código no Amazon Simple Storage Service (Amazon S3).\n",
    "- Criar um grupo de recursos.\n",
    "- Fazer a ingestão dos recursos no grupo de recursos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.1.1: Instalar dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install dependencies\n",
    "%pip install --upgrade pip \n",
    "%pip install pytest-astropy ==  0.7.0\n",
    "%pip install rsa == 4.7.2\n",
    "%pip install PyYAML\n",
    "!apt update && apt install -y git\n",
    "%pip install git+https://github.com/aws-samples/ml-lineage-helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.1.2 Importar módulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import-modules\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker_datawrangler\n",
    "import sagemaker.session\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import uuid\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.model_metrics import (\n",
    "    MetricsSource,\n",
    "    ModelMetrics,\n",
    ")\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    "    ScriptProcessor,\n",
    ")\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThan\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep,\n",
    "    TrainingStep,\n",
    ")\n",
    "from sagemaker.workflow.condition_step import (\n",
    "    ConditionStep,\n",
    "    JsonGet,\n",
    ")\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "from ml_lineage_helper import *\n",
    "from sagemaker.feature_store.feature_definition import FeatureDefinition\n",
    "from sagemaker.feature_store.feature_definition import FeatureTypeEnum\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import FeatureStoreOutput\n",
    "from sagemaker.processing import Processor\n",
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.dataset_definition.inputs import AthenaDatasetDefinition, DatasetDefinition, RedshiftDatasetDefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sessions\n",
    "boto_session  =  boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create clients\n",
    "s3_client = boto3.client('s3')\n",
    "featurestore_runtime = boto3.client('sagemaker-featurestore-runtime')\n",
    "sagemaker_client = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature store session\n",
    "feature_store_session = Session(\n",
    "    boto_session = boto_session,\n",
    "    sagemaker_client = sagemaker_client,\n",
    "    sagemaker_featurestore_runtime_client = featurestore_runtime\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set global variables\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "region = boto_session.region_name\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.1.3 Copiar arquivos de laboratório no Amazon S3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload files to default bucket\n",
    "s3_client.put_object(Bucket = default_bucket, Key = 'data/')\n",
    "s3_client.put_object(Bucket = default_bucket, Key = 'input/code/')\n",
    "s3_client.upload_file('pipelines/data/storedata_total.csv', default_bucket, 'data/storedata_total.csv')\n",
    "s3_client.upload_file('pipelines/input/code/evaluate.py', default_bucket, 'input/code/evaluate.py')\n",
    "s3_client.upload_file('pipelines/input/code/generate_config.py', default_bucket, 'input/code/generate_config.py')\n",
    "s3_client.upload_file('pipelines/input/code/processfeaturestore.py', default_bucket, 'input/code/processfeaturestore.py')\n",
    "\n",
    "# Preview the dataset\n",
    "print('Dataset preview:')\n",
    "customer_data = pd.read_csv('pipelines/data/storedata_total.csv')\n",
    "customer_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.1.4 Criar o grupo de recursos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta tarefa, você vai criar um grupo de recursos para os dados. Primeiro, crie um esquema dos dados. Neste laboratório, o esquema deve ocorrer pelas colunas **name** e depois pelo **type** de variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set-up-feature-store-variables\n",
    "record_identifier_feature_name = 'FS_ID'\n",
    "event_time_feature_name = 'FS_time'\n",
    "\n",
    "column_schemas = [\n",
    "    {\n",
    "        \"name\": \"retained\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"esent\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"eopenrate\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"eclickrate\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"avgorder\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ordfreq\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"paperless\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"refill\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"doorstep\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"first_last_days_diff\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"created_first_days_diff\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Friday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Monday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Saturday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Sunday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Thursday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Tuesday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Wednesday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"city_BLR\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"city_BOM\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"city_DEL\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"city_MAA\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"FS_ID\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"FS_time\",\n",
    "        \"type\": \"float\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, crie o grupo de recursos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow name and a unique ID for this export (used later as the processing job name for the export)\n",
    "flow_name = 'featureengineer'\n",
    "flow_export_id = f\"{strftime('%d-%H-%M-%S', gmtime())}-{str(uuid.uuid4())[:8]}\"\n",
    "flow_export_name = f\"flow-{flow_export_id}\"\n",
    "\n",
    "# Feature group name, with flow_name and a unique id. You can give it a customized name\n",
    "feature_group_name = f\"FG-{flow_name}-{str(uuid.uuid4())[:8]}\"\n",
    "\n",
    "# SageMaker Feature Store writes the data in the offline store of a Feature Group to a \n",
    "# Amazon S3 location owned by you.\n",
    "feature_store_offline_s3_uri = 's3://' + default_bucket\n",
    "\n",
    "# Controls if online store is enabled. Enabling the online store allows quick access to \n",
    "# the latest value for a record by using the GetRecord API.\n",
    "enable_online_store = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create-feature-group\n",
    "default_feature_type = FeatureTypeEnum.STRING\n",
    "column_to_feature_type_mapping = {\n",
    "    \"float\": FeatureTypeEnum.FRACTIONAL,\n",
    "    \"long\": FeatureTypeEnum.INTEGRAL\n",
    "}\n",
    "\n",
    "feature_definitions = [\n",
    "    FeatureDefinition(\n",
    "        feature_name = column_schema['name'], \n",
    "        feature_type = column_to_feature_type_mapping.get(column_schema['type'], default_feature_type)\n",
    "    ) for column_schema in column_schemas\n",
    "]\n",
    "\n",
    "\n",
    "print(f\"Feature Group Name: {feature_group_name}\")\n",
    "\n",
    "# Confirm the Athena settings are configured\n",
    "try:\n",
    "    boto3.client('athena').update_work_group(\n",
    "        WorkGroup = 'primary',\n",
    "        ConfigurationUpdates = {\n",
    "            'EnforceWorkGroupConfiguration':False\n",
    "        }\n",
    "    )\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "feature_group = FeatureGroup(\n",
    "    name = feature_group_name, sagemaker_session = feature_store_session, feature_definitions = feature_definitions)\n",
    "\n",
    "feature_group.create(\n",
    "    s3_uri = feature_store_offline_s3_uri,\n",
    "    record_identifier_name = record_identifier_feature_name,\n",
    "    event_time_feature_name = event_time_feature_name,\n",
    "    role_arn = role,\n",
    "    enable_online_store = enable_online_store\n",
    ")\n",
    "\n",
    "def wait_for_feature_group_creation_complete(feature_group):\n",
    "    \"\"\"Helper function to wait for the completions of creating a feature group\"\"\"\n",
    "    response = feature_group.describe()\n",
    "    status = response.get(\"FeatureGroupStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for feature group creation\")\n",
    "        time.sleep(5)\n",
    "        response = feature_group.describe()\n",
    "        status = response.get(\"FeatureGroupStatus\")\n",
    "\n",
    "    if status != \"Created\":\n",
    "        print(f\"Failed to create feature group, response: {response}\")\n",
    "        failureReason = response.get(\"FailureReason\", \"\")\n",
    "        raise SystemExit(\n",
    "            f\"Failed to create feature group {feature_group.name}, status: {status}, reason: {failureReason}\"\n",
    "        )\n",
    "    print(f\"Feature Group {feature_group.name} successfully created.\")\n",
    "\n",
    "wait_for_feature_group_creation_complete(feature_group = feature_group)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.1.5 Ingerir recursos\n",
    "\n",
    "Este processo exige cerca de cinco minutos para ser concluído."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate-feature-store\n",
    "column_list = ['retained','esent','eopenrate','eclickrate','avgorder','ordfreq','paperless','refill','doorstep','first_last_days_diff','created_first_days_diff','favday_Friday','favday_Monday', 'favday_Saturday','favday_Sunday','favday_Thursday','favday_Tuesday','favday_Wednesday','city_BLR','city_BOM','city_DEL','city_MAA','FS_ID','FS_time']\n",
    "lab_test_data = pd.read_csv('featureengineer_data/store_data_processed.csv', names = (column_list), header = 1)\n",
    "feature_group.ingest(data_frame = lab_test_data, wait = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 2.2 Criar e executar um pipeline do SageMaker\n",
    "\n",
    "Agora que o ambiente está definido, você pode configurar, criar e iniciar um pipeline do SageMaker. \n",
    "\n",
    "Um pipeline do SageMaker é um fluxo de trabalho que executa uma série de etapas dependentes. As etapas podem aceitar entradas e enviar saídas, para que dados e outros ativos possam ser passados entre elas. \n",
    "\n",
    "Execute as seguintes células para:\n",
    "- Definir as variáveis necessárias para configurar o pipeline.\n",
    "- Configurar uma sessão do SageMaker.\n",
    "- Definir as etapas do pipeline.\n",
    "- Configurar o pipeline.\n",
    "- Criar o pipeline.\n",
    "- Iniciar o pipeline.\n",
    "- Descrever o pipeline.\n",
    "- Criar um evento de espera para que o notebook não continue até que a execução do pipeline termine."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.2.1 Configurar as variáveis que o pipeline usa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pipeline-variables\n",
    "feature_group_name = feature_group.name\n",
    "model_name = \"Churn-model\"\n",
    "\n",
    "sklearn_processor_version = \"0.23-1\"\n",
    "model_package_group_name = \"ChurnModelPackageGroup\"\n",
    "pipeline_name = \"ChurnModelSMPipeline\"\n",
    "\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name = \"ProcessingInstanceCount\",\n",
    "    default_value = 1\n",
    "    )\n",
    "\n",
    "processing_instance_type = ParameterString(\n",
    "        name = \"ProcessingInstanceType\",\n",
    "        default_value = \"ml.m5.xlarge\"\n",
    "    )\n",
    "\n",
    "training_instance_type = ParameterString(\n",
    "        name = \"TrainingInstanceType\",\n",
    "        default_value = \"ml.m5.xlarge\"\n",
    "    )\n",
    "\n",
    "input_data = ParameterString(\n",
    "        name = \"InputData\",\n",
    "        default_value = \"s3://{}/data/storedata_total.csv\".format(default_bucket), \n",
    "    )\n",
    "\n",
    "batch_data = ParameterString(\n",
    "        name = \"BatchData\",\n",
    "        default_value = \"s3://{}/data/batch/batch.csv\".format(default_bucket),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.2.2 Configurar o pipeline\n",
    "\n",
    "Defina um pipeline chamado **ChurnModelPipeline** para produzir um modelo que avalie a probabilidade de reter ou manter clientes. Este pipeline tem nove etapas. \n",
    "\n",
    "Cada etapa em um pipeline executa um tipo de trabalho específico. As entradas necessárias para um trabalho variam de acordo com o tipo de trabalho. Consulte [Tipos de etapa](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#build-and-manage-steps-types) para saber mais sobre os tipos de etapa de pipeline do SageMaker.\n",
    "\n",
    "Examine o código nas seguintes células para entender como cada etapa foi definida:\n",
    "\n",
    "A etapa **ChurnModelProcess** é definida na variável chamada **step_process**. \n",
    "\n",
    "A configuração de etapa inclui o seguinte:\n",
    "- **Type** (Tipo): processamento – os trabalhos de processamento são definidos usando a classe ProcessingStep().\n",
    "- **Processor** (Processador: SKLearnProcessor.\n",
    "- **Destination** (Destino): a saída será enviada às pastas no bucket do S3 padrão.\n",
    "- **Job Arguments** (Argumentos do trabalho): esta etapa usará o Feature Store para processar o conjunto de dados.\n",
    "- **Code** (Código): **processfeaturestore.py**, que reside no bucket do S3 padrão.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-processing-step\n",
    "# Run a scikit-learn script to do data processing on SageMaker \n",
    "# using the SKLearnProcessor class\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "        framework_version = sklearn_processor_version,\n",
    "        instance_type = processing_instance_type.default_value, \n",
    "        instance_count = processing_instance_count,\n",
    "        sagemaker_session = sagemaker_session,\n",
    "        role = role,\n",
    "    )\n",
    "\n",
    "# Inputs, outputs, and code are parameters to the processor\n",
    "# step_* will become the pipeline steps toward the end of the cell\n",
    "# in this case, use the feature store as input, so there is no externalinput\n",
    "step_process = ProcessingStep(\n",
    "        name = \"ChurnModelProcess\",\n",
    "        processor = sklearn_processor,\n",
    "        outputs = [\n",
    "            ProcessingOutput(output_name = \"train\", source = \"/opt/ml/processing/train\",\\\n",
    "                             destination = f\"s3://{default_bucket}/output/train\" ),\n",
    "            ProcessingOutput(output_name = \"validation\", source = \"/opt/ml/processing/validation\",\\\n",
    "                            destination = f\"s3://{default_bucket}/output/validation\"),\n",
    "            ProcessingOutput(output_name = \"test\", source = \"/opt/ml/processing/test\",\\\n",
    "                            destination = f\"s3://{default_bucket}/output/test\"),\n",
    "            ProcessingOutput(output_name = \"batch\", source = \"/opt/ml/processing/batch\",\\\n",
    "                            destination = f\"s3://{default_bucket}/data/batch\"),\n",
    "            ProcessingOutput(output_name = \"baseline\", source = \"/opt/ml/processing/baseline\",\\\n",
    "                            destination = f\"s3://{default_bucket}/input/baseline\")\n",
    "        ],\n",
    "        job_arguments = [\"--featuregroupname\",feature_group_name,\"--default-bucket\",default_bucket,\"--region\",region],\n",
    "        code = f\"s3://{default_bucket}/input/code/processfeaturestore.py\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A etapa **ChurnHyperParameterTuning** é definida na variável chamada **step_tuning**. \n",
    "\n",
    "A configuração de etapa inclui o seguinte:\n",
    "- **Type** (Tipo): ajuste – os trabalhos de ajuste são definidos usando a classe TuningStep().\n",
    "- **Tuner** (Ajustador): este trabalho usa o framework XGBoost.\n",
    "- **Entradas:** observe que este trabalho usa os dados de treinamento e validação produzidos pela etapa ChurnModelProcess, **step_process**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-churn-hyperparameter-tuning\n",
    "# Training/tuning step for generating model artifacts\n",
    "model_path = f\"s3://{default_bucket}/output\"\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework = \"xgboost\",\n",
    "    region = region,\n",
    "    version = \"1.5-1\",\n",
    "    py_version = \"py3\",\n",
    "    instance_type = training_instance_type.default_value,\n",
    ")\n",
    "\n",
    "fixed_hyperparameters = {\n",
    "    \"eval_metric\":\"auc\",\n",
    "    \"objective\":\"binary:logistic\",\n",
    "    \"num_round\":\"100\",\n",
    "    \"rate_drop\":\"0.3\",\n",
    "    \"tweedie_variance_power\":\"1.4\"\n",
    "    }\n",
    "\n",
    "xgb_train = Estimator(\n",
    "    image_uri = image_uri,\n",
    "    instance_type = training_instance_type,\n",
    "    instance_count = 1,\n",
    "    hyperparameters = fixed_hyperparameters,\n",
    "    output_path = model_path,\n",
    "    base_job_name = f\"churn-train\",\n",
    "    sagemaker_session = sagemaker_session,\n",
    "    role = role\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning steps\n",
    "hyperparameter_ranges = {\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "    \"min_child_weight\": ContinuousParameter(1, 10),\n",
    "    \"alpha\": ContinuousParameter(0, 2),\n",
    "    \"max_depth\": IntegerParameter(1, 10),\n",
    "    }\n",
    "objective_metric_name = \"validation:auc\"\n",
    "\n",
    "step_tuning = TuningStep(\n",
    "    name = \"ChurnHyperParameterTuning\",\n",
    "    tuner = HyperparameterTuner(xgb_train, objective_metric_name, hyperparameter_ranges, max_jobs = 2, max_parallel_jobs = 2),\n",
    "    inputs = {\n",
    "            \"train\": TrainingInput(\n",
    "                s3_data = step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"train\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type = \"text/csv\",\n",
    "            ),\n",
    "            \"validation\": TrainingInput(\n",
    "                s3_data = step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"validation\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type = \"text/csv\",\n",
    "            ),\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A etapa **ChurnEvalBestModel** é definida na variável chamada **step_eval**. \n",
    "\n",
    "A configuração de etapa inclui o seguinte:\n",
    "- **Type** (Tipo): processamento.\n",
    "- **Processor** (Processador): ScriptProcessor.\n",
    "- **Inputs** (Entradas): observe que este trabalho usa o modelo principal de ChurnHyperParameterTuning (**step_tuning**) e a saída de teste de ChurnModelProcess (**step_process**).\n",
    "- **Outputs** (Saídas): a saída é gravada no bucket do S3 padrão.\n",
    "- **Code** (Código): um script chamado **evaluate.py**, que reside no Amazon S3, é usado para avaliação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-churn-best-model\n",
    "evaluation_report = PropertyFile(\n",
    "    name = \"ChurnEvaluationReport\",\n",
    "    output_name = \"evaluation\",\n",
    "    path = \"evaluation.json\",\n",
    ")\n",
    "\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri = image_uri,\n",
    "    command = [\"python3\"],\n",
    "    instance_type = processing_instance_type,\n",
    "    instance_count = 1,\n",
    "    base_job_name = \"script-churn-eval\",\n",
    "    role = role,\n",
    "    sagemaker_session = sagemaker_session,\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name = \"ChurnEvalBestModel\",\n",
    "    processor = script_eval,\n",
    "    inputs = [\n",
    "        ProcessingInput(\n",
    "            source = step_tuning.get_top_model_s3_uri(top_k = 0, s3_bucket = default_bucket, prefix = \"output\"),\n",
    "            destination = \"/opt/ml/processing/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source = step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri,\n",
    "            destination = \"/opt/ml/processing/test\"\n",
    "        )\n",
    "    ],\n",
    "    outputs = [\n",
    "        ProcessingOutput(output_name = \"evaluation\", source = \"/opt/ml/processing/evaluation\",\\\n",
    "                            destination = f\"s3://{default_bucket}/output/evaluation\"),\n",
    "    ],\n",
    "    code = f\"s3://{default_bucket}/input/code/evaluate.py\",\n",
    "    property_files = [evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A etapa **ChurnCreateModel** é definida na variável chamada **step_create_model**. \n",
    "\n",
    "A configuração de etapa inclui o seguinte:\n",
    "- **Type** (Tipo): modelo – os trabalhos de modelo são definidos usando a classe Model().\n",
    "- **Model** (Modelo): o modelo usado pela etapa é definido na variável já definida chamada **model**. Observe que a variável **model** usa o modelo principal que foi criado por ChurnHyperParameterTuning (**step_tuning**).\n",
    "- **Inputs** (Entradas): as entradas incluem um tipo de instância e um tipo de acelerador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-model-creation\n",
    "model = Model(\n",
    "    image_uri = image_uri,        \n",
    "    model_data = step_tuning.get_top_model_s3_uri(top_k = 0,s3_bucket = default_bucket,prefix = \"output\"),\n",
    "    name = model_name,\n",
    "    sagemaker_session = sagemaker_session,\n",
    "    role = role,\n",
    ")\n",
    "\n",
    "inputs = CreateModelInput(\n",
    "    instance_type = \"ml.m5.large\",\n",
    "    accelerator_type = \"ml.inf1.xlarge\",\n",
    ")\n",
    "\n",
    "step_create_model = CreateModelStep(\n",
    "    name = \"ChurnCreateModel\",\n",
    "    model = model,\n",
    "    inputs = inputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A etapa **ChurnModelConfigFile** é definida na variável chamada **step_config_file**. \n",
    "\n",
    "A configuração de etapa inclui o seguinte:\n",
    "- **Type** (Tipo): processamento.\n",
    "- **Processor** (Processador): ScriptProcessor.\n",
    "- **Code** (Código): **generate_config.py**, que reside no bucket do S3 padrão.\n",
    "- **Job Arguments** (Argumentos do trabalho): os argumentos do trabalho incluem o modelo que foi gerado por **ChurnCreateModel**, o caminho para o relatório de viés, o bucket padrão, o número de amostras e o número de instâncias usadas no processamento.\n",
    "- **Depends On** (Depende de): observe que este trabalho só pode ser executado quando a criação do modelo é concluída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#configure-script-processing\n",
    "bias_report_output_path = f\"s3://{default_bucket}/clarify-output/bias\"\n",
    "clarify_instance_type = 'ml.m5.xlarge'\n",
    "analysis_config_path = f\"s3://{default_bucket}/clarify-output/bias/analysis_config.json\"\n",
    "clarify_image = sagemaker.image_uris.retrieve(framework = 'sklearn', version = sklearn_processor_version, region = region)\n",
    "\n",
    "#custom_image_uri = None\n",
    "script_processor = ScriptProcessor(\n",
    "    command = ['python3'],\n",
    "    image_uri = clarify_image,\n",
    "    role = role,\n",
    "    instance_count = 1,\n",
    "    instance_type = processing_instance_type,\n",
    "    sagemaker_session = sagemaker_session,\n",
    ")\n",
    "\n",
    "step_config_file = ProcessingStep(\n",
    "    name = \"ChurnModelConfigFile\",\n",
    "    processor = script_processor,\n",
    "    code = f\"s3://{default_bucket}/input/code/generate_config.py\",\n",
    "    job_arguments = [\"--modelname\", step_create_model.properties.ModelName, \"--bias-report-output-path\", bias_report_output_path, \"--clarify-instance-type\", clarify_instance_type,\\\n",
    "                  \"--default-bucket\", default_bucket, \"--num-baseline-samples\", \"50\", \"--instance-count\", \"1\"],\n",
    "    depends_on = [step_create_model.name]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A etapa **ChurnTransform** é definida na variável chamada **step_transform**. \n",
    "\n",
    "A configuração de etapa inclui o seguinte:\n",
    "- **Type** (Tipo): transformação – os trabalhos de transformação são definidos usando a classe TransformStep().\n",
    "- **Transformer** (Transformador): os detalhes do transformador são definidos na variável já definida chamada **transformer**. Observe que essa variável está usando o modelo que foi criado em ChurnCreateModel (**step_create_model**).\n",
    "- **Inputs** (Entradas): os dados que serão transformados, batch.csv, que já foram definidos no notebook. A entrada também inclui o tipo de arquivo e como ele deve ser dividido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-inference\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type = \"ml.m5.xlarge\",\n",
    "    instance_count = 1,\n",
    "    assemble_with = \"Line\",\n",
    "    accept = \"text/csv\",    \n",
    "    output_path = f\"s3://{default_bucket}/ChurnTransform\"\n",
    "    )\n",
    "\n",
    "step_transform = TransformStep(\n",
    "    name = \"ChurnTransform\",\n",
    "    transformer = transformer,\n",
    "    inputs = TransformInput(data = batch_data, content_type = \"text/csv\", join_source = \"Input\", split_type = \"Line\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A etapa **ClarifyProcessingStep** é definida na variável chamada **step_clarify**. \n",
    "\n",
    "A configuração de etapa inclui o seguinte:\n",
    "- **Type** (Tipo): processamento.\n",
    "- **Processor** (Processador): este trabalho usa SageMakerClarifyProcessor. É possível examinar a configuração do processador na variável chamada **clarify_processor**.\n",
    "- **Inputs** (Entradas): as entradas são definidas nas variáveis **data_input** e **congif_input**.\n",
    "- **Outputs** (Saídas): a saída é gravada em uma pasta no bucket padrão. \n",
    "- **Depends On** (Depende de): observe que este trabalho só pode ser executado depois que o arquivo de configuração exigido pelo Amazon SageMaker Clarify é criado por **ChurnModelConfigFile**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-clarify-processing\n",
    "data_config = sagemaker.clarify.DataConfig(\n",
    "s3_data_input_path = f's3://{default_bucket}/output/train/train.csv',\n",
    "s3_output_path = bias_report_output_path,\n",
    "    label = 0,\n",
    "    headers = ['target','esent','eopenrate','eclickrate','avgorder','ordfreq','paperless','refill','doorstep','first_last_days_diff','created_first_days_diff','favday_Friday','favday_Monday','favday_Saturday','favday_Sunday','favday_Thursday','favday_Tuesday','favday_Wednesday','city_BLR','city_BOM','city_DEL','city_MAA'],\n",
    "    dataset_type = \"text/csv\",\n",
    ")\n",
    "\n",
    "clarify_processor = sagemaker.clarify.SageMakerClarifyProcessor(\n",
    "    role = role,\n",
    "    instance_count = 1,\n",
    "    instance_type = clarify_instance_type,\n",
    "    sagemaker_session = sagemaker_session,\n",
    ")\n",
    "\n",
    "config_input = ProcessingInput(\n",
    "    input_name = \"analysis_config\",\n",
    "    source=analysis_config_path,\n",
    "    destination = \"/opt/ml/processing/input/analysis_config\",\n",
    "    s3_data_type = \"S3Prefix\",\n",
    "    s3_input_mode = \"File\",\n",
    "    s3_compression_type = \"None\",\n",
    "    )\n",
    "\n",
    "data_input = ProcessingInput(\n",
    "    input_name = \"dataset\",\n",
    "    source = data_config.s3_data_input_path,\n",
    "    destination = \"/opt/ml/processing/input/data\",\n",
    "    s3_data_type = \"S3Prefix\",\n",
    "    s3_input_mode = \"File\",\n",
    "    s3_data_distribution_type = data_config.s3_data_distribution_type,\n",
    "    s3_compression_type = data_config.s3_compression_type,\n",
    ")\n",
    "\n",
    "result_output = ProcessingOutput( \n",
    "    source = \"/opt/ml/processing/output\",\n",
    "    destination = data_config.s3_output_path,\n",
    "    output_name = \"analysis_result\",\n",
    "    s3_upload_mode = \"EndOfJob\",\n",
    ")\n",
    "\n",
    "step_clarify = ProcessingStep(\n",
    "    name = \"ClarifyProcessingStep\",\n",
    "    processor = clarify_processor,\n",
    "    inputs = [data_input, config_input],\n",
    "    outputs = [result_output],\n",
    "    depends_on = [step_config_file.name]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A etapa **RegisterChurnModel** é definida na variável chamada **step_register**. \n",
    "\n",
    "A configuração de etapa inclui o seguinte:\n",
    "- **Type** (Tipo): registro de modelo – os trabalhos de registro são definidos usando a classe RegisterMode().\n",
    "- **Estimator** (Estimador): o estimador é definido na variável **xgbtrain** no início na célula.\n",
    "- **Model Data** (Dados do modelo): este é o URI do modelo que é retornado por **ChurnHyperParameterTuning**.\n",
    "- **Content Types** (Tipos de conteúdo): texto/csv\n",
    "- **Response Types** (Tipos de resposta) texto/csv\n",
    "- **Inference Instance** (Instância de inferência): esse é o tipo de instância que será usado no processamento de inferência.\n",
    "- **Transform Instance** (Instância de transformação): esse é o tipo de instância que será usado para processar transformações.\n",
    "- **Model Package Group Name** (Nome do grupo de pacotes do modelo): esse é o nome do grupo que armazenará o grupo de versões do modelo.\n",
    "- **Model Metrics** (Métricas do modelo): define o local das métricas do modelo. Os arquivos incluídos são o relatório de viés do SageMaker Clarify, o relatório de explicabilidade do SageMaker Clarify e a avaliação do modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-model-registry\n",
    "model_statistics = MetricsSource(\n",
    "    s3_uri = \"s3://{}/output/evaluation/evaluation.json\".format(default_bucket),\n",
    "    content_type = \"application/json\"\n",
    "    )\n",
    "explainability = MetricsSource(\n",
    "    s3_uri = \"s3://{}/clarify-output/bias/analysis.json\".format(default_bucket),\n",
    "    content_type = \"application/json\"\n",
    "    )\n",
    "\n",
    "bias = MetricsSource(\n",
    "    s3_uri = \"s3://{}/clarify-output/bias/analysis.json\".format(default_bucket),\n",
    "    content_type = \"application/json\"\n",
    "    ) \n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics = model_statistics,\n",
    "    explainability = explainability,\n",
    "    bias = bias\n",
    ")\n",
    "\n",
    "step_register = RegisterModel(\n",
    "    name = \"RegisterChurnModel\",\n",
    "    estimator = xgb_train,\n",
    "    model_data = step_tuning.get_top_model_s3_uri(top_k = 0, s3_bucket = default_bucket, prefix = \"output\"),\n",
    "    content_types = [\"text/csv\"],\n",
    "    response_types = [\"text/csv\"],\n",
    "    inference_instances = [\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "    transform_instances = [\"ml.m5.large\"],\n",
    "    model_package_group_name = model_package_group_name,\n",
    "    model_metrics = model_metrics,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A etapa **CheckAUCScoreChurnEvaluation** é definida na variável chamada **step_cond**. \n",
    "\n",
    "A configuração de etapa inclui o seguinte:\n",
    "- **Type** (Tipo): condição – os trabalhos de condição são definidos usando a classe ConditionStep().\n",
    "- **Conditions** (Condições): essa condição é avaliada como True quando a saída de **ChurnEvalBestModel** é superior a 0,75.\n",
    "- **If Steps** (Etapas if): essa é a lista de etapas que são executadas quando a condição é avaliada como True.\n",
    "- **Else Steps** (Etapas else): essa é a lista de etapas que são executadas quando a condição é avaliada como False. Observe que esta lista está vazia, o que significa que o processamento do pipeline é interrompido quando a condição não é atendida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "cond_lte = ConditionGreaterThan(\n",
    "    left = JsonGet(\n",
    "        step = step_eval,\n",
    "        property_file = evaluation_report,\n",
    "        json_path = \"binary_classification_metrics.auc.value\"\n",
    "    ),\n",
    "    right = 0.75,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name = \"CheckAUCScoreChurnEvaluation\",\n",
    "    conditions = [cond_lte],\n",
    "    if_steps = [step_create_model, step_config_file, step_transform, step_clarify, step_register],\n",
    "    else_steps = [],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.2.3 Definir o pipeline\n",
    "\n",
    "Depois de definir as etapas, você vai configurar o pipeline na variável chamada **pipeline**. Observe como as etapas já definidas são passadas para a definição de pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #define pipeline function\n",
    "def get_pipeline(\n",
    "    region,\n",
    "    role = None,\n",
    "    default_bucket = None,\n",
    "    model_package_group_name = \"ChurnModelPackageGroup\",\n",
    "    pipeline_name = \"ChurnModelPipeline\",\n",
    "    base_prefix = None,\n",
    "    custom_image_uri = None,\n",
    "    sklearn_processor_version = None\n",
    "    ):\n",
    "\n",
    "    #configure pipeline instance\n",
    "    pipeline = Pipeline(\n",
    "        name = pipeline_name,\n",
    "        parameters = [\n",
    "            processing_instance_type,\n",
    "            processing_instance_count,\n",
    "            training_instance_type,\n",
    "            input_data,\n",
    "            batch_data,\n",
    "        ],\n",
    "        steps = [step_process, step_tuning, step_eval, step_cond],\n",
    "        sagemaker_session = sagemaker_session\n",
    "    )\n",
    "    return pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.2.4 Criar o pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #create pipeline using function\n",
    "pipeline = get_pipeline(\n",
    "  region = region,\n",
    "    role = role,\n",
    "    default_bucket = default_bucket,\n",
    "    model_package_group_name = model_package_group_name,\n",
    "    pipeline_name = pipeline_name,\n",
    "    custom_image_uri = clarify_image,\n",
    "    sklearn_processor_version = sklearn_processor_version\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.2.5 Atualizar o pipeline para usar o perfil do IAM correto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set-iam-role\n",
    "pipeline.upsert(role_arn = role)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observe:** se aparecer o aviso a seguir após a execução da célula, você poderá ignorá-lo com segurança.\n",
    "\n",
    "\"Não foi encontrado nenhum trabalho de treinamento concluído associado a este estimador. Verifique se este estimador é usado apenas para criar a configuração do fluxo de trabalho\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.2.6 Iniciar o pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start-pipeline\n",
    "RunPipeline = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.2.7 Descrever o pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe-pipeline\n",
    "RunPipeline.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A execução deste pipeline exige cerca de 35 minutos.\n",
    "\n",
    "Enquanto o pipeline estiver em execução, continue na próxima tarefa para explorar o pipeline no console do Amazon SageMaker Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 2.3 Monitorar e aprovar o pipeline\n",
    "\n",
    "Nesta tarefa, explore o pipeline usando o console do Amazon SageMaker Studio.\n",
    "\n",
    "### Tarefa 2.3.1 Monitorar o pipeline no SageMaker Studio\n",
    "\n",
    "A próxima tarefa abre uma nova aba no SageMaker Studio. Para seguir essas orientações, escolha uma das seguintes opções:\n",
    "- **Opção 1:** visualizar as abas lado a lado. Para criar uma visualização de tela dividida por meio da janela principal do SageMaker Studio, arraste a aba **lab_10.ipynb** para a lateral ou escolha (clique com o botão direito) a aba **lab_10.ipynb** e selecione **New View for Notebook** (Nova visualização do notebook). Agora, as orientações ficam visíveis enquanto você explora as etapas do pipeline.\n",
    "- **Opção 2:** alternar entre as abas do SageMaker Studio para seguir essas instruções. Ao terminar de explorar as etapas do pipeline, retorne ao notebook selecionando a aba **lab_10.ipynb**.\n",
    "\n",
    "1. No SageMaker Studio, selecione o ícone **Página inicial do SageMaker**.\n",
    "1. Escolha **Pipelines**.\n",
    "\n",
    "O SageMaker Studio abre a aba **Pipelines**.\n",
    "\n",
    "1. Selecione o pipeline chamado **ChurnModelSMPipeline**. \n",
    "\n",
    "O SageMaker Studio abre a aba **ChurnModelSMPipeline**.\n",
    "\n",
    "1. Na aba **ChurnModelSMPipeline**, em **Executions** (Execuções), abra (clique com o botão direito) o status do pipeline e selecione **Open execution details** (Abrir detalhes da execução). \n",
    "\n",
    "O SageMaker Studio abre a página **Grafo acíclico dirigido** (DAG).\n",
    "\n",
    "O Grafo acíclico dirigido (DAG) mostra o fluxo de trabalho e o progresso do pipeline. As cores são usadas para indicar o status de uma etapa. Os indicadores de cor da etapa são:\n",
    "- **cinza:** aguardando execução.\n",
    "- **azul:** em execução.\n",
    "- **verde:** concluído com sucesso.\n",
    "- **vermelho:** erro.\n",
    "\n",
    "Cada etapa explorada tem as mesmas quatro abas no painel de detalhes da etapa. Embora os títulos das abas sejam os mesmos, o conteúdo de cada uma varia de acordo com o tipo e a configuração do trabalho:\n",
    "\n",
    "- **Input** (Entrada): essa aba contém as entradas que foram passadas para o trabalho. Exemplos de entradas são os parâmetros que especificam os tipos de instância, as funções do AWS Identity and Access Management (IAM) ou os argumentos necessários para executar o trabalho. Outros exemplos de entrada incluem arquivos, como código, conjuntos de dados e imagens do Docker.\n",
    "- **Output** (Saída): essa aba mostra a saída que o trabalho criou. Alguns exemplos de saída são métricas, gráficos, arquivos e resultados de avaliação.\n",
    "- **Logs:** essa aba contém uma lista de logs associados ao trabalho. Se o usuário tiver privilégios suficientes para os logs do Amazon CloudWatch, ele poderá clicar no link dos logs e visualizar as mensagem do log no CloudWatch. Alguns tipos de trabalho não geram logs.\n",
    "- **Information** (Informações): essa aba contém informações básicas sobre um trabalho, como o tipo de trabalho, o nome do trabalho e quando ele foi executado.\n",
    "\n",
    "1. Escolha a etapa chamada **ChurnModelProcess**. Um novo painel chamado **ChurnModelProcess** é exibido.\n",
    "1. No painel **ChurnModelProcess**, examine as abas associadas a essa etapa do pipeline: \n",
    "    - Escolha a aba **Input** (Entrada). Essa aba contém informações úteis sobre os parâmetros e os arquivos que a etapa de processamento usa. Na lista de parâmetros, há detalhes, como o tipo de instância e a imagem que o trabalho usa, o local do conjunto de dados, o local do código e os destinos das diferentes saídas que são geradas. Role o painel até o final para encontrar as entradas de arquivo que foram passadas ao trabalho.\n",
    "    - Escolha a aba **Output** (Saída). Essa aba mostra os diferentes arquivos que a etapa do pipeline gera e local em que eles são colocados. Este pipeline coloca todas as saídas no bucket padrão do SageMaker Studio.\n",
    "    - Escolha a aba **Logs**. Essa aba mostra os logs que o trabalho gerou. A presença dos logs disponíveis dentro do SageMaker Studio acelera a investigação e a solução de problemas quando uma etapa do pipeline não é executada com sucesso.\n",
    "    - Escolha a aba **Information** (Informações). Essa aba oferece uma visão geral abrangente da etapa do pipeline. Ela inclui informações, como o tipo de etapa, o nome da etapa e um link para log do trabalho. Ela também contém detalhes sobre quando o trabalho foi executado e a duração da execução.\n",
    "        - Observe que o **Step Type** (Tipo de etapa) é **Processing** (Processamento).\n",
    "\n",
    "### Tarefa 2.3.2 Descobrir os detalhes da etapa do pipeline\n",
    "\n",
    "Nas próximas etapas, você vai escolher o nó apropriado do grafo acíclico dirigido (DAG) para encontrar informações sobre uma determinada etapa do pipeline. Se precisar de ajuda para encontrar as respostas, veja no final deste notebook Python as resposta e as dicas incluídas.\n",
    "\n",
    "1. Para a etapa chamada **ChurnHyperParameterTuning**, localize os seguintes detalhes:\n",
    "    - Qual é o **Tipo de etapa** desta etapa?\n",
    "    - Qual foi o **Melhor trabalho de treinamento em geral** gerado por esta etapa?\n",
    "1. Para a etapa chamada **ChurnEvalBestModel**, localize os seguintes detalhes:\n",
    "    - Qual é o **Tipo de etapa** desta etapa?\n",
    "    - Qual é o nome do script do Python usado para avaliar o principal modelo que foi identificado na etapa anterior?\n",
    "    - Em que local este arquivo está?\n",
    "    - Em que local os resultados desta etapa foram gravados?\n",
    "1. Para a etapa chamada **CheckAUCScoreChurnEvaluation**, localize os seguintes detalhes:\n",
    "    - Qual é o **Tipo de etapa** desta etapa?\n",
    "    - Qual foi o **Resultado da avaliação**?\n",
    "1. Para a etapa chamada **ChurnCreateModel**, localize os seguintes detalhes:\n",
    "    - Qual é o **Tipo de etapa** desta etapa?\n",
    "    - Este trabalho gerou logs?\n",
    "1. Para a etapa chamada **RegisterChurnModel**, localize os seguintes detalhes:\n",
    "    - Qual é o **Tipo de etapa** desta etapa?\n",
    "    - Qual é o valor da métrica área dentro da curva (AUC)?\n",
    "1. Para a etapa chamada **ChurnTransform**, localize os seguintes detalhes:\n",
    "    - Qual é o **Tipo de etapa** desta etapa?\n",
    "    - Este trabalho gerou logs?\n",
    "    - Quais arquivos foram as entradas desta etapa?\n",
    "1. Para a etapa chamada **ChurnModelConfigFile**, localize os seguintes detalhes: \n",
    "    - Qual ProcessingInstanceType foi usado para executar esse trabalho?\n",
    "    - Qual é o **Tipo de etapa** desta etapa?\n",
    "1. Para a etapa chamada **ClarifyProcessingStep**, localize os seguintes detalhes:\n",
    "    - Qual foi a saída do arquivo desta etapa?\n",
    "    - Em que local a saída foi gravada?\n",
    "\n",
    "### 2.3.3 Aprovar o modelo no pipeline\n",
    "\n",
    "1. Quando a execução do pipeline for concluída, visualize o modelo criado pelo pipeline no **Registro de modelo**:\n",
    "    - No SageMaker Studio, selecione o ícone **Página inicial do SageMaker**.\n",
    "    - Expanda a lista **Models** (Modelos).\n",
    "    - Escolha **Model registry** (Registro de modelo).\n",
    "    - Abra o Grupo de modelo chamado **ChurnModelPackageGroup**.\n",
    "    - Na aba **ChurnModelPackageGroup**, abra (clique com o botão direito) a lista na tabela **Versions** (Versões) e escolha **Open model version** (Abrir versão do modelo). Observe que o status do modelo é **Pending** (Pendente). Observe também que o valor de **Execution** (Execução) é o nome da execução de pipeline que acabou de ser concluída.\n",
    "\n",
    "    Há mais detalhes sobre o pipeline em cada aba:\n",
    "    - **Activity** (Atividade): essa aba mostra a atividade do modelo. Ela contém informações do evento e o tempo decorrido desde que o modelo foi modificado.\n",
    "    - **Model quality** (Qualidade do modelo): essa aba mostra as métricas de precisão do modelo.\n",
    "    - **Explainability** (Explicabilidade): essa aba mostra a importância dos recursos do modelo em termos de valores Shapley (SHAP).\n",
    "    - **Bias report** (Relatório de viés): essa guia mostra o possível viés do modelo.\n",
    "    - **Inference recommender** (Recomendação de inferência): essa aba oferece recomendações para melhorar a relação preço/desempenho do modelo. Essa aba não contém dados porque esse recurso não é compatível com este pacote de modelos.\n",
    "    - **Load test** (Teste de carga): nessa aba, é possível iniciar testes de carga para experimentar diferentes tipos de instância e avaliá-las em relação às métricas de throughput e latência necessárias para uma implantação de produção.\n",
    "    - **Settings** (Configurações): essa aba mostra informações, como quando o modelo foi criado, qual pipeline gerou o modelo, o local em que o modelo está e o componente de teste associado ao modelo.\n",
    "\n",
    "1. Aprovar o modelo. Esse processo é projetado para revisão manual antes da aprovação do modelo. No entanto, é possível automatizar a aprovação do modelo no pipeline:\n",
    "    - Escolha <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">**Update status** (Atualizar status)</span>.\n",
    "    - Abra a lista suspensa e escolha <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">**Approved** (Aprovado)</span>.\n",
    "    - Escolha <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">**Update status** (Atualizar status)</span>.\n",
    "1. Feche a aba **ChurnModelPackageGroup**.\n",
    "\n",
    "### Tarefa 2.3.4 Visualizar as etapas do pipeline usando o AWS SDK\n",
    "\n",
    "Além de usar a IU do SageMaker Studio para visualizar detalhes do pipeline, você também pode usar comandos do AWS SDK. Por exemplo, o comando a seguir retorna uma lista das etapas do pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list-steps\n",
    "RunPipeline.list_steps()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 2.4 Examinar os artefatos\n",
    "\n",
    "A próxima tarefa abre uma nova aba no SageMaker Studio. Para seguir essas orientações, escolha uma das seguintes opções:\n",
    "- **Opção 1:** visualizar as abas lado a lado. Para criar uma visualização de tela dividida por meio da janela principal do SageMaker Studio, arraste a aba **lab_10.ipynb** para a lateral ou escolha (clique com o botão direito) a aba **lab_10.ipynb** e escolha **New View for Notebook** (Nova visualização do notebook). Agora, as orientações ficam visíveis enquanto você explora os artefatos.\n",
    "- **Opção 2:** alternar entre as abas do SageMaker Studio para seguir essas instruções. Ao terminar de explorar os artefatos, retorne ao notebook selecionando a aba **lab_10.ipynb**.\n",
    "\n",
    "### Tarefa 2.4.1 Examinar os artefatos no SageMaker Studio\n",
    "\n",
    "Conforme o pipeline foi executado, cada etapa gerou artefatos, como arquivos, parâmetros treinados e modelos. É possível identificar os artefatos que o pipeline criou no SageMaker Studio.\n",
    "1. Retorne à aba chamada **ChurnModelSMPipeline**.\n",
    "1. Escolha a aba **Executions** (Execuções).\n",
    "1. Abra (clique com o botão direito) a execução listada e escolha **View trial components generated by execution** (Visualizar os componentes de teste gerados pela execução). \n",
    "\n",
    "O SageMaker Studio abre uma nova aba chamada **Trial Component List** (Lista de componentes de teste). \n",
    "\n",
    "Uma lista de todos os trabalhos que o pipeline executou é exibida.\n",
    "\n",
    "Observe que cada componente de teste tem um **Trial Component Type** (Tipo de componente de teste). As informações disponíveis nas várias abas no detalhe do teste associado dependem do tipo de componente de teste. Nem todas as abas no detalhe do teste são preenchidas com os dados de todos os tipos de componente.\n",
    "\n",
    "1. Abra (clique com o botão direito) na primeira linha na lista de trabalhos e escolha **Open in trial details** (Abrir nos detalhes do teste). \n",
    "\n",
    "O SageMaker Studio abre uma nova aba chamada **Describe Trial Component** (Descrever componente de teste). \n",
    "\n",
    "Em **Trial Components** (Componentes de teste), há várias abas disponíveis. Dependendo do que uma etapa do pipeline fez, algumas abas podem estar vazias. \n",
    "\n",
    "1. Escolha a aba **Artifacts** (Artefatos). Os detalhes da entrada e da saída usados na etapa.\n",
    "1. Escolha a aba **Explainability** (Explicabilidade). Essa aba mostra o relatório de explicabilidade que o SageMaker Clarify gerou.\n",
    "1. Escolha a aba **Bias Report** (Relatório de viés). Essa aba mostra o relatório de viés que o SageMaker Clarify gerou.\n",
    "\n",
    "### Tarefa 2.4.2 Localizar os artefatos no bucket do S3 padrão\n",
    "**Atenção:** use o console de gerenciamento da AWS nesta tarefa. Depois de explorar o bucket do S3, retorne à aba do navegador em que o SageMaker Studio está aberto e escolha a aba **lab_10.ipynb**.\n",
    "\n",
    "1. Na guia do navegador em que o console está aberto, navegue até o Amazon S3.\n",
    "1. Escolha o nome do bucket que começa com **sagemaker-** e a região da AWS. Por exemplo: **sagemaker-us-west-2-123456789**.\n",
    "1. Explore as pastas e os arquivos nesse bucket. Esse bucket contém o conjunto de dados, as entradas e as saídas do processamento, os resultados do SageMaker Clarify e outros arquivos que contribuíram para o modelo resultante.\n",
    "1. Retorne à aba do navegador em que o SageMaker Studio está aberto e escolha a aba **lab_10.ipynb**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 2.5 (opcional) Criar e examinar a linhagem do pipeline\n",
    "\n",
    "Você aprendeu a usar o SageMaker Clarify para explicar como um modelo faz previsões e entender o possível viés de um modelo. Você também pode usar o SageMaker Clarify para descobrir as etapas usadas para gerar o modelo, que geralmente são necessárias para a auditoria do modelo. Nesta tarefa, você aproveita o módulo MLLineageHelper para criar a linhagem da execução de pipeline atual. Consulte [MLLineageHelper](https://github.com/aws-samples/ml-lineage-helper) para saber mais sobre o ML Lineage Helper.\n",
    "\n",
    "O Amazon SageMaker ML Lineage Tracking cria e armazena informações sobre as etapas de um fluxo de trabalho de ML desde a preparação dos dados até a implantação do modelo. Com as informações de monitoramento, é possível reproduzir as etapas do fluxo de trabalho, monitorar a linhagem do modelo e do conjunto de dados e estabelecer os padrões de governança e auditoria do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.5.1 Configurar a sessão e as variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set-variables\n",
    "fs_query = feature_group.athena_query()\n",
    "fs_table = fs_query.table_name\n",
    "query_string = 'SELECT * FROM \"'+fs_table+'\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.5.2 Mostrar os valores que serão usados para criar a linhagem do modelo\n",
    "\n",
    "As configurações incluem o seguinte:\n",
    "- **query_string:** essa é a consulta do SageMaker Feature Store que será passada para o módulo MLLineageHelper.\n",
    "- **model_ref:** esse é o nome do modelo que está sendo avaliado.\n",
    "- **processing_job:** esse é o nome do trabalho de processamento que gerou o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print-values\n",
    "print ('query_string:',query_string)\n",
    "\n",
    "model_ref = sagemaker_client.list_models(SortBy = 'CreationTime', SortOrder = 'Descending')['Models'][0]['ModelName']\n",
    "print ('model_ref:',model_ref)\n",
    "\n",
    "processing_job = sagemaker_client.list_processing_jobs(SortBy = 'CreationTime', SortOrder = 'Descending', NameContains = 'ChurnModelProcess')['ProcessingJobSummaries'][0]['ProcessingJobName']\n",
    "print ('processing_job:',processing_job)\n",
    "\n",
    "processing_job_description = sagemaker_client.describe_processing_job(\n",
    "    ProcessingJobName = processing_job\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.5.3 Descrever o trabalho de processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe-processing-job\n",
    "processing_job_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.5.4 Mostrar o nome do trabalho de treinamento usado para criar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print-training-job\n",
    "training_job_name  =  sagemaker_client.list_training_jobs(SortBy = 'CreationTime', SortOrder = 'Descending')['TrainingJobSummaries'][0]['TrainingJobName']\n",
    "print (training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.5.5 Criar a linhagem do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ocorrer o erro a seguir, execute a célula novamente.\n",
    "- **ClientError: ocorreu um erro (ThrottlingException) ao chamar a operação UpdateArtifact (máximo de novas tentativas atingido: 4): Taxa excedida**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build-lineage\n",
    "ml_lineage = MLLineageHelper()\n",
    "lineage = ml_lineage.create_ml_lineage(training_job_name, model_name = model_ref,\n",
    "                                       query = query_string, sagemaker_processing_job_description = processing_job_description,\n",
    "                                       feature_group_names = [feature_group_name])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.5.6 Limitar a linhagem para incluir somente o teste atual e o grupo de recursos\n",
    "\n",
    "Um pipeline pode ser executado várias vezes. Para garantir que sejam recuperados os detalhes do trabalho de treinamento mais recentes, filtre a chamada de linhagem usando o nome do teste atual e o grupo de recursos que o teste usa. \n",
    "\n",
    "Após a execução dessa célula, as etapas usadas para criar o modelo, a ordem em que as etapas foram executadas e quais trabalhos contribuíram para outros trabalhos no pipeline são exibidos como uma tabela. Essas mesmas informações também são gravadas em um arquivo chamado **lineage_FS.csv**. Você pode baixar esse arquivo para salvar a saída e compartilhá-la com outros membros da equipe, como os auditores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit-lineage\n",
    "trial_name = RunPipeline.describe()['PipelineExperimentConfig']['TrialName']\n",
    "pat = str(trial_name)+'|'+'fg-FG'\n",
    "df1 = lineage[lineage.apply(lambda x: any(x.str.contains(pat)),axis = 1)]\n",
    "pd.set_option('display.max_colwidth', 120)\n",
    "df1.to_csv('lineage_FS.csv') \n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 2.5.7 Gerar uma visualização da linhagem do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize-lineage\n",
    "plt.figure(3, figsize = (20, 14))\n",
    "graph = nx.DiGraph()\n",
    "graph.add_edges_from([(each[0], each[2]) for each in df1.values])\n",
    "fig, ax = plt.subplots()\n",
    "nx.draw_networkx(\n",
    "    graph,\n",
    "    node_size = 300,\n",
    "    node_color = \"orange\",\n",
    "    alpha = 0.65,\n",
    "    font_size = 8,\n",
    "    pos = nx.spring_layout(graph)\n",
    ")\n",
    "ax.set_facecolor('deepskyblue')\n",
    "ax.axis('off')\n",
    "fig.set_facecolor('deepskyblue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 2.6 Remover o pipeline\n",
    "\n",
    "Para excluir o pipeline, execute a seguinte célula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete-pipeline\n",
    "response = sagemaker_client.delete_pipeline(PipelineName = 'ChurnModelSMPipeline')\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão \n",
    "\n",
    "Parabéns! Você usou o SageMaker Pipelines para automatizar a criação e o registro de um modelo. Você aprendeu a fazer uma busca detalhada em cada etapa do pipeline para identificar os parâmetros, os arquivos e os logs associados. Você sabe como identificar os ativos que o pipeline usou para gerar o modelo, como encontrar o modelo no registro de modelo e como encontrar e visualizar os relatórios de explicabilidade e viés que um pipeline pode gerar.\n",
    "\n",
    "## Limpeza\n",
    "\n",
    "Você concluiu este notebook. Passe para a próxima parte do laboratório da seguinte forma:\n",
    "\n",
    "- Feche este arquivo de notebook.\n",
    "- Retorne à sessão do laboratório e continue com a **Conclusão**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicas e respostas da Tarefa 2.3.1.1\n",
    "Dica geral: o **Step type** (Tipo de etapa) se encontra na aba **Information** (Informações).\n",
    "\n",
    "1. Para a etapa chamada **ChurnHyperParameterTuning**, localize os seguintes detalhes:\n",
    "    - Qual é o **Tipo de etapa** desta etapa?</br>\n",
    "    **Resposta:** ajuste</br>\n",
    "    - Qual foi o **Melhor trabalho de treinamento em geral** gerado por esta etapa? </br>\n",
    "    **Dica:** essa informação se encontra na aba **Output** (Saída).</br>\n",
    "    **Resposta:** o nome do modelo é gerado e será diferente para cada aluno. O nome deve ser semelhante a este exemplo: 056vhzs2vkxc-ChurnHy-TCAtUr16oV-001-17d5bd01\n",
    "1. Para a etapa **ChurnEvalBestModel**, localize os seguintes detalhes:\n",
    "    - Qual é o **Tipo de etapa** desta etapa?\n",
    "    **Resposta:** processamento</br>\n",
    "    - Qual é o nome do script do Python usado para avaliar o principal modelo que foi identificado na etapa anterior?</br>\n",
    "    **Dica:** essa informação se encontra na aba **Input** (Entrada).</br>\n",
    "    **Resposta:** evaluate.py</br>\n",
    "    - Em que local este arquivo está?</br>\n",
    "    **Dica:** essa informação se encontra na aba **Input** (Entrada).</br>\n",
    "    **Resposta:** o arquivo reside em um bucket do S3. O caminho é semelhante a este exemplo: s3://sagemaker-us-west-2-1234567890/input/code/evaluate.py</br>\n",
    "    - Em que local os resultados desta etapa foram gravados?</br>\n",
    "    **Dica:** essa informação se encontra na aba **Output** (Saída).</br>\n",
    "    **Resposta:** os resultados da avaliação foram gravados em um bucket do S3. O caminho para o arquivo deve ser semelhante ao seguinte exemplo: s3://sagemaker-us-west-2-1234567890/output/evaluation</br>\n",
    "1. Para a etapa **CheckAUCScoreChurnEvaluation**, localize os seguintes detalhes:\n",
    "    - Qual é o **Tipo de etapa** desta etapa?</br>\n",
    "    **Resposta:** condição</br>\n",
    "    - Qual foi o **Resultado da avaliação**?</br>\n",
    "    **Dica:** essa informação se encontra na aba **Output** (Saída).</br>\n",
    "    **Resposta:** verdadeiro\n",
    "1. Para a etapa **ChurnCreateModel**, localize os seguintes detalhes:\n",
    "    - Qual é o **Tipo de etapa** desta etapa?</br>\n",
    "    **Resposta:** modelo</br>\n",
    "    - Este trabalho gerou logs?</br>\n",
    "    **Resposta:** não\n",
    "1. Para a etapa **RegisterChurnModel**, localize os seguintes detalhes:\n",
    "    - Qual é o **Tipo de etapa** desta etapa?</br>\n",
    "    **Resposta:** RegisterModel</br>\n",
    "    - Qual é o valor da métrica AUC?</br>\n",
    "    **Dica:** essa informação se encontra na aba **Output** (Saída).</br>\n",
    "    **Resposta:** o valor vai variar, mas deverá ser próximo de 0,98.\n",
    "1. Para a etapa **ChurnTransform**, localize os seguintes detalhes:\n",
    "    - Qual é o **Tipo de etapa** desta etapa?</br>\n",
    "    **Resposta:** transformação</br>\n",
    "    - Este trabalho gerou logs?</br>\n",
    "    **Resposta:** sim</br>\n",
    "    - Quais arquivos foram as entradas desta etapa?</br>\n",
    "    **Dica:** essa informação se encontra na aba **Input** (Entrada). Talvez seja necessário rolar o painel até o final para encontrar os nomes de arquivo.</br>\n",
    "    **Resposta:** model.tar.gz, sagemaker-xgboost:1.5-1-cpu-py3, batch.csv\n",
    "1. Para a etapa **ChurnModelConfigFile**, localize os seguintes detalhes: \n",
    "    - Qual ProcessingInstanceType foi usado para executar esse trabalho?</br>\n",
    "    **Dica:** essa informação se encontra na aba **Input** (Entrada).</br>\n",
    "    **Resposta:** ml.m5.xlarge\n",
    "    - Qual é o **Tipo de etapa** desta etapa?</br>\n",
    "    **Resposta:** processamento\n",
    "1. Para a **ClarifyProcessingStep**, localize os seguintes detalhes:\n",
    "    - Qual foi a saída do arquivo desta etapa?\n",
    "    **Dica:** essa informação se encontra na aba **Output** (Saída).</br>\n",
    "    **Resposta:** a saída foi dados de viés.\n",
    "    - Em que local a saída foi gravada?\n",
    "    **Resposta:** a saída foi gravada no bucket do S3. O caminho deve ser semelhante a este exemplo: s3://sagemaker-us-west-2-1234567890/clarify-output/bias"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "741de909edea0d5644898c592544ed98bede62b404d20772e5c4abc3c2f12566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
