{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务 5：使用批量转换从大型数据集获取推理\n",
    "\n",
    "## 任务 5.1：环境设置\n",
    "\n",
    "安装程序包和依赖项。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install-dependencies\n",
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker_datawrangler\n",
    "import time\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.transformer import Transformer\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sess = boto3.Session()\n",
    "sm = sess.client('sagemaker')\n",
    "prefix = 'sagemaker/mlasms'\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "s3_client = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将来自训练和优化实验的模型保存在默认 Amazon Simple Storage Service (Amazon S3) 存储桶中。使用 **create_model** 设置模型，并配置 **ModelDataUrl** 以引用经过训练的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set-up-model\n",
    "# Upload the model and dataset to your Amazon S3 bucket\n",
    "s3_client.upload_file(Filename=\"model.tar.gz\", Bucket=bucket, Key=f\"{prefix}/models/model.tar.gz\")\n",
    "\n",
    "# Set a date to use in the model name\n",
    "create_date = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "model_name = 'income-model-{}'.format(create_date)\n",
    "\n",
    "# Retrieve the container image\n",
    "container = sagemaker.image_uris.retrieve(\n",
    "    region=boto3.Session().region_name, \n",
    "    framework='xgboost', \n",
    "    version='1.5-1'\n",
    ")\n",
    "\n",
    "# Set up the model\n",
    "income_model = sm.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = {\n",
    "        'Image': container,\n",
    "        'ModelDataUrl': f's3://{bucket}/{prefix}/models/model.tar.gz',\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将批量记录上传到默认 Amazon S3 存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload-dataset\n",
    "s3_client.upload_file(Filename=\"batch_data.csv\", Bucket=bucket, Key=f\"{prefix}/batch_data.csv\", ExtraArgs={\"ContentType\": \"text/csv;charset=utf-8\"})\n",
    "batch_path = f\"s3://{bucket}/{prefix}/batch_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务 5.2：创建批量转换任务\n",
    "\n",
    "批量转换会在指定参数的限制内自动管理大型数据集的处理。批量转换任务启动时，SageMaker 会初始化计算实例，并在这些实例之间分配推理或预处理工作负载。批量转换按键对输入中的 Amazon S3 对象进行分区，并将 Amazon S3 对象映射到实例。\n",
    "\n",
    "如果您需要从大型数据集获取推理或不需要持久性终端节点，请使用批量转换。\n",
    "\n",
    "要创建批量转换任务，您需要设置以下选项：\n",
    "- **model_name**：模型的名称。\n",
    "- **instance_type**：要使用的 Amazon Elastic Compute Cloud (Amazon EC2) 实例的类型；例如“ml.c4.xlarge”。\n",
    "- **instance_count**：要使用的 EC2 实例数。\n",
    "- **assemble_with**：输出的组合方式。有效值为“Line”或“None”。\n",
    "- **strategy**：用于确定如何在单个请求中批处理记录的策略。有效值为“MultiRecord”和“SingleRecord”。\n",
    "- **accept**：接受的文件类型。\n",
    "- **output_path**：用于保存转换结果的 Amazon S3 位置。如果未指定，结果将存储到默认存储桶。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create-batch-transformer\n",
    "transformer = Transformer(\n",
    "    model_name=model_name,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    instance_count=1,\n",
    "    assemble_with=\"Line\",\n",
    "    strategy=\"MultiRecord\",\n",
    "    accept=\"text/csv\",\n",
    "    output_path=\"s3://{}/{}/batch-transform/test\".format(bucket, prefix)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用测试数据集作为客户记录并运行批量转换任务。使用这组客户记录运行该任务大约需要长达 10 分钟的时间。\n",
    "\n",
    "有关批量转换任务的更多信息，请参阅 [Use Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run-batch-transform-job\n",
    "transformer.transform(batch_path, content_type=\"text/csv\", split_type=\"Line\", join_source=\"Input\")\n",
    "transformer.wait()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务 5.3：在 Amazon S3 中查看预测数据\n",
    "\n",
    "批量转换任务将输出存储在您设置转换程序时指定的存储桶和文件夹中。您可以通过 AWS 管理控制台或笔记本在 Amazon S3 中查看预测结果。\n",
    "\n",
    "如果您要从控制台下载和查看输出，请导航到 Amazon S3，打开以 **sagemaker-** 开头的存储桶，然后导航到位于 **/sagemaker/mlasms/batch-transform/test** 中的对象。下载 **batch_data.csv.out** 对象并使用记事本编辑器将其打开。该文件包含通过批量转换任务运行的客户记录的数百个预测值。\n",
    "\n",
    "您还可以在笔记本中查看输出示例。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $transformer.output_path ./\n",
    "!head batch_data.csv.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总结\n",
    "\n",
    "恭喜！ 您已使用 Amazon SageMaker 成功运行一项批量转换任务。\n",
    "\n",
    "### 清理\n",
    "\n",
    "您已完成此笔记本。要进入本实验的下一部分，请执行以下操作：\n",
    "\n",
    "- 关闭此笔记本文件。\n",
    "- 返回至实验会话并继续**总结**部分。"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.xlarge",
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "2e45558c452cedcb26631315a9b3b77e80a9c32d662ed25df58964b99bc5b9b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}