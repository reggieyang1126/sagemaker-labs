{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습 10: SageMaker Studio와 함께 SageMaker 파이프라인 및 SageMaker Model Registry 사용\n",
    "\n",
    "이 실습에서는 Amazon SageMaker 파이프라인을 생성하고 해당 파이프라인의 진행률을 모니터링합니다. 그리고 기계 학습(ML) 프로세스가 사용하거나 생성하는 몇 가지 아티팩트도 찾아서 살펴봅니다.\n",
    "\n",
    "시간이 되면 파이프라인에서 생성된 모델의 계보 세부 정보도 검토할 수 있습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과제 2.1: 환경 설정\n",
    "\n",
    "SageMaker 파이프라인을 생성하기 전에 먼저 필요한 패키지를 설치하고 모듈을 가져온 후 지원 파일을 스테이징하여 환경을 준비해야 합니다. 이 파이프라인은 특성 그룹을 사용하도록 설계되었으므로 Amazon SageMaker Feature Store에서 특성 그룹도 생성하며 Data Wrangler 흐름을 실행하여 환경을 준비합니다. \n",
    "\n",
    "이 과제의 셀을 실행하여 다음 작업을 수행합니다.\n",
    "- 종속성 설치\n",
    "- 필요한 모듈 가져오기\n",
    "- Amazon Simple Storage Service(Amazon S3)에 데이터 및 코드 복사\n",
    "- 특성 그룹 생성\n",
    "- 특성 그룹에 특성 수집"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과제 2.1.1: 종속성 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install dependencies\n",
    "%pip install --upgrade pip \n",
    "%pip install pytest-astropy ==  0.7.0\n",
    "%pip install rsa == 4.7.2\n",
    "%pip install PyYAML\n",
    "!apt update && apt install -y git\n",
    "%pip install git+https://github.com/aws-samples/ml-lineage-helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과제 2.1.2: 모듈 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import-modules\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker_datawrangler\n",
    "import sagemaker.session\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import uuid\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.model_metrics import (\n",
    "    MetricsSource,\n",
    "    ModelMetrics,\n",
    ")\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    "    ScriptProcessor,\n",
    ")\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThan\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep,\n",
    "    TrainingStep,\n",
    ")\n",
    "from sagemaker.workflow.condition_step import (\n",
    "    ConditionStep,\n",
    "    JsonGet,\n",
    ")\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "from ml_lineage_helper import *\n",
    "from sagemaker.feature_store.feature_definition import FeatureDefinition\n",
    "from sagemaker.feature_store.feature_definition import FeatureTypeEnum\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import FeatureStoreOutput\n",
    "from sagemaker.processing import Processor\n",
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.dataset_definition.inputs import AthenaDatasetDefinition, DatasetDefinition, RedshiftDatasetDefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sessions\n",
    "boto_session  =  boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create clients\n",
    "s3_client = boto3.client('s3')\n",
    "featurestore_runtime = boto3.client('sagemaker-featurestore-runtime')\n",
    "sagemaker_client = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature store session\n",
    "feature_store_session = Session(\n",
    "    boto_session = boto_session,\n",
    "    sagemaker_client = sagemaker_client,\n",
    "    sagemaker_featurestore_runtime_client = featurestore_runtime\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set global variables\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "region = boto_session.region_name\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과제 2.1.3 Amazon S3에 실습 파일 복사 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload files to default bucket\n",
    "s3_client.put_object(Bucket = default_bucket, Key = 'data/')\n",
    "s3_client.put_object(Bucket = default_bucket, Key = 'input/code/')\n",
    "s3_client.upload_file('pipelines/data/storedata_total.csv', default_bucket, 'data/storedata_total.csv')\n",
    "s3_client.upload_file('pipelines/input/code/evaluate.py', default_bucket, 'input/code/evaluate.py')\n",
    "s3_client.upload_file('pipelines/input/code/generate_config.py', default_bucket, 'input/code/generate_config.py')\n",
    "s3_client.upload_file('pipelines/input/code/processfeaturestore.py', default_bucket, 'input/code/processfeaturestore.py')\n",
    "\n",
    "# Preview the dataset\n",
    "print('Dataset preview:')\n",
    "customer_data = pd.read_csv('pipelines/data/storedata_total.csv')\n",
    "customer_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과제 2.1.4: 특성 그룹 생성"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 작업에서는 데이터에 대한 특성 그룹을 생성합니다. 먼저 데이터의 스키마를 만듭니다. 이 실습의 경우, 스키마는 **name** 열과 변수의 **type** 열에서 생성되어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set-up-feature-store-variables\n",
    "record_identifier_feature_name = 'FS_ID'\n",
    "event_time_feature_name = 'FS_time'\n",
    "\n",
    "column_schemas = [\n",
    "    {\n",
    "        \"name\": \"retained\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"esent\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"eopenrate\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"eclickrate\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"avgorder\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ordfreq\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"paperless\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"refill\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"doorstep\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"first_last_days_diff\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"created_first_days_diff\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Friday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Monday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Saturday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Sunday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Thursday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Tuesday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Wednesday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"city_BLR\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"city_BOM\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"city_DEL\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"city_MAA\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"FS_ID\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"FS_time\",\n",
    "        \"type\": \"float\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 특성 그룹을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow name and a unique ID for this export (used later as the processing job name for the export)\n",
    "flow_name = 'featureengineer'\n",
    "flow_export_id = f\"{strftime('%d-%H-%M-%S', gmtime())}-{str(uuid.uuid4())[:8]}\"\n",
    "flow_export_name = f\"flow-{flow_export_id}\"\n",
    "\n",
    "# Feature group name, with flow_name and a unique id. You can give it a customized name\n",
    "feature_group_name = f\"FG-{flow_name}-{str(uuid.uuid4())[:8]}\"\n",
    "\n",
    "# SageMaker Feature Store writes the data in the offline store of a Feature Group to a \n",
    "# Amazon S3 location owned by you.\n",
    "feature_store_offline_s3_uri = 's3://' + default_bucket\n",
    "\n",
    "# Controls if online store is enabled. Enabling the online store allows quick access to \n",
    "# the latest value for a record by using the GetRecord API.\n",
    "enable_online_store = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create-feature-group\n",
    "default_feature_type = FeatureTypeEnum.STRING\n",
    "column_to_feature_type_mapping = {\n",
    "    \"float\": FeatureTypeEnum.FRACTIONAL,\n",
    "    \"long\": FeatureTypeEnum.INTEGRAL\n",
    "}\n",
    "\n",
    "feature_definitions = [\n",
    "    FeatureDefinition(\n",
    "        feature_name = column_schema['name'], \n",
    "        feature_type = column_to_feature_type_mapping.get(column_schema['type'], default_feature_type)\n",
    "    ) for column_schema in column_schemas\n",
    "]\n",
    "\n",
    "\n",
    "print(f\"Feature Group Name: {feature_group_name}\")\n",
    "\n",
    "# Confirm the Athena settings are configured\n",
    "try:\n",
    "    boto3.client('athena').update_work_group(\n",
    "        WorkGroup = 'primary',\n",
    "        ConfigurationUpdates = {\n",
    "            'EnforceWorkGroupConfiguration':False\n",
    "        }\n",
    "    )\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "feature_group = FeatureGroup(\n",
    "    name = feature_group_name, sagemaker_session = feature_store_session, feature_definitions = feature_definitions)\n",
    "\n",
    "feature_group.create(\n",
    "    s3_uri = feature_store_offline_s3_uri,\n",
    "    record_identifier_name = record_identifier_feature_name,\n",
    "    event_time_feature_name = event_time_feature_name,\n",
    "    role_arn = role,\n",
    "    enable_online_store = enable_online_store\n",
    ")\n",
    "\n",
    "def wait_for_feature_group_creation_complete(feature_group):\n",
    "    \"\"\"Helper function to wait for the completions of creating a feature group\"\"\"\n",
    "    response = feature_group.describe()\n",
    "    status = response.get(\"FeatureGroupStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for feature group creation\")\n",
    "        time.sleep(5)\n",
    "        response = feature_group.describe()\n",
    "        status = response.get(\"FeatureGroupStatus\")\n",
    "\n",
    "    if status != \"Created\":\n",
    "        print(f\"Failed to create feature group, response: {response}\")\n",
    "        failureReason = response.get(\"FailureReason\", \"\")\n",
    "        raise SystemExit(\n",
    "            f\"Failed to create feature group {feature_group.name}, status: {status}, reason: {failureReason}\"\n",
    "        )\n",
    "    print(f\"Feature Group {feature_group.name} successfully created.\")\n",
    "\n",
    "wait_for_feature_group_creation_complete(feature_group = feature_group)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과제 2.1.5: 특성 수집\n",
    "\n",
    "이 프로세스 실행을 완료하려면 약 8분이 소요됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate-feature-store\n",
    "column_list = ['retained','esent','eopenrate','eclickrate','avgorder','ordfreq','paperless','refill','doorstep','first_last_days_diff','created_first_days_diff','favday_Friday','favday_Monday', 'favday_Saturday','favday_Sunday','favday_Thursday','favday_Tuesday','favday_Wednesday','city_BLR','city_BOM','city_DEL','city_MAA','FS_ID','FS_time']\n",
    "lab_test_data = pd.read_csv('featureengineer_data/store_data_processed.csv', names = (column_list), header = 1)\n",
    "feature_group.ingest(data_frame = lab_test_data, wait = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과제 2.2: SageMaker 파이프라인 생성 및 실행\n",
    "\n",
    "환경을 설정했으므로 이제 SageMaker 파이프라인을 구성, 생성 및 시작합니다. \n",
    "\n",
    "SageMaker 파이프라인은 종속 단계 집합을 실행하는 워크플로입니다. 단계에서는 입력을 수락하고 출력을 전송할 수 있으므로 단계 간에 데이터와 기타 자산을 전달할 수 있습니다. \n",
    "\n",
    "아래 셀을 실행하여 다음 작업을 수행합니다.\n",
    "- 파이프라인을 구성하기 위해 필요한 변수 정의\n",
    "- SageMaker 세션 구성\n",
    "- 파이프라인 단계 정의\n",
    "- 파이프라인 구성\n",
    "- 파이프라인 생성\n",
    "- 파이프라인 시작\n",
    "- 파이프라인 설명\n",
    "- 파이프라인 실행이 완료될 때까지 노트북이 처리되지 않도록 대기 이벤트 생성"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과제 2.2.1: 파이프라인이 사용하는 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pipeline-variables\n",
    "feature_group_name = feature_group.name\n",
    "model_name = \"Churn-model\"\n",
    "\n",
    "sklearn_processor_version = \"0.23-1\"\n",
    "model_package_group_name = \"ChurnModelPackageGroup\"\n",
    "pipeline_name = \"ChurnModelSMPipeline\"\n",
    "\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name = \"ProcessingInstanceCount\",\n",
    "    default_value = 1\n",
    "    )\n",
    "\n",
    "processing_instance_type = ParameterString(\n",
    "        name = \"ProcessingInstanceType\",\n",
    "        default_value = \"ml.m5.xlarge\"\n",
    "    )\n",
    "\n",
    "training_instance_type = ParameterString(\n",
    "        name = \"TrainingInstanceType\",\n",
    "        default_value = \"ml.m5.xlarge\"\n",
    "    )\n",
    "\n",
    "input_data = ParameterString(\n",
    "        name = \"InputData\",\n",
    "        default_value = \"s3://{}/data/storedata_total.csv\".format(default_bucket), \n",
    "    )\n",
    "\n",
    "batch_data = ParameterString(\n",
    "        name = \"BatchData\",\n",
    "        default_value = \"s3://{}/data/batch/batch.csv\".format(default_bucket),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과제 2.2.2: 파이프라인 구성\n",
    "\n",
    "이 과제에서는 고객 유지 또는 이탈 가능성을 평가하는 모델을 생성하기 위해 이름이 **ChurnModelPipeline**인 파이프라인을 정의합니다. 이 파이프라인에는 9개 단계가 포함됩니다. \n",
    "\n",
    "파이프라인의 각 단계에서는 특정 작업 유형을 실행합니다. 작업에 필요한 입력은 작업 유형에 따라 다릅니다. SageMaker 파이프라인 단계 유형에 관한 자세한 내용은 [단계 유형](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#build-and-manage-steps-types)을 참조하세요.\n",
    "\n",
    "다음 셀의 코드를 검토하여 각 단계가 정의된 방식을 파악합니다.\n",
    "\n",
    "**ChurnModelProcess** 단계는 **step_process** 변수에서 정의됩니다. \n",
    "\n",
    "단계 구성에는 다음 항목이 포함됩니다.\n",
    "- **Type**: Processing. ProcessingStep() 클래스를 사용하여 처리 작업을 정의합니다.\n",
    "- **Processor**: SKLearnProcessor입니다.\n",
    "- **Destination**: 기본 S3 버킷의 폴더로 출력이 전송됩니다.\n",
    "- **Job Arguments**: 이 단계에서는 특성 저장소를 사용하여 데이터 집합을 처리합니다.\n",
    "- **Code**: 기본 S3 버킷에 있는 **processfeaturestore.py**입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-processing-step\n",
    "# Run a scikit-learn script to do data processing on SageMaker \n",
    "# using the SKLearnProcessor class\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "        framework_version = sklearn_processor_version,\n",
    "        instance_type = processing_instance_type.default_value, \n",
    "        instance_count = processing_instance_count,\n",
    "        sagemaker_session = sagemaker_session,\n",
    "        role = role,\n",
    "    )\n",
    "\n",
    "# Inputs, outputs, and code are parameters to the processor\n",
    "# step_* will become the pipeline steps toward the end of the cell\n",
    "# in this case, use the feature store as input, so there is no externalinput\n",
    "step_process = ProcessingStep(\n",
    "        name = \"ChurnModelProcess\",\n",
    "        processor = sklearn_processor,\n",
    "        outputs = [\n",
    "            ProcessingOutput(output_name = \"train\", source = \"/opt/ml/processing/train\",\\\n",
    "                             destination = f\"s3://{default_bucket}/output/train\" ),\n",
    "            ProcessingOutput(output_name = \"validation\", source = \"/opt/ml/processing/validation\",\\\n",
    "                            destination = f\"s3://{default_bucket}/output/validation\"),\n",
    "            ProcessingOutput(output_name = \"test\", source = \"/opt/ml/processing/test\",\\\n",
    "                            destination = f\"s3://{default_bucket}/output/test\"),\n",
    "            ProcessingOutput(output_name = \"batch\", source = \"/opt/ml/processing/batch\",\\\n",
    "                            destination = f\"s3://{default_bucket}/data/batch\"),\n",
    "            ProcessingOutput(output_name = \"baseline\", source = \"/opt/ml/processing/baseline\",\\\n",
    "                            destination = f\"s3://{default_bucket}/input/baseline\")\n",
    "        ],\n",
    "        job_arguments = [\"--featuregroupname\",feature_group_name,\"--default-bucket\",default_bucket,\"--region\",region],\n",
    "        code = f\"s3://{default_bucket}/input/code/processfeaturestore.py\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ChurnHyperParameterTuning** 단계는 **step_tuning** 변수에서 정의됩니다. \n",
    "\n",
    "단계 구성에는 다음 항목이 포함됩니다.\n",
    "- **Type**: Tuning. TuningStep() 클래스를 사용하여 튜닝 작업을 정의합니다.\n",
    "- **Tuner**: 이 작업에서는 XGBoost 프레임워크를 사용합니다.\n",
    "- **Inputs**: 이 작업은 ChurnModelProcess 단계인 **step_process**에서 생성된 훈련 및 검증 데이터를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-churn-hyperparameter-tuning\n",
    "# Training/tuning step for generating model artifacts\n",
    "model_path = f\"s3://{default_bucket}/output\"\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework = \"xgboost\",\n",
    "    region = region,\n",
    "    version = \"1.5-1\",\n",
    "    py_version = \"py3\",\n",
    "    instance_type = training_instance_type.default_value,\n",
    ")\n",
    "\n",
    "fixed_hyperparameters = {\n",
    "    \"eval_metric\":\"auc\",\n",
    "    \"objective\":\"binary:logistic\",\n",
    "    \"num_round\":\"100\",\n",
    "    \"rate_drop\":\"0.3\",\n",
    "    \"tweedie_variance_power\":\"1.4\"\n",
    "    }\n",
    "\n",
    "xgb_train = Estimator(\n",
    "    image_uri = image_uri,\n",
    "    instance_type = training_instance_type,\n",
    "    instance_count = 1,\n",
    "    hyperparameters = fixed_hyperparameters,\n",
    "    output_path = model_path,\n",
    "    base_job_name = f\"churn-train\",\n",
    "    sagemaker_session = sagemaker_session,\n",
    "    role = role\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning steps\n",
    "hyperparameter_ranges = {\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "    \"min_child_weight\": ContinuousParameter(1, 10),\n",
    "    \"alpha\": ContinuousParameter(0, 2),\n",
    "    \"max_depth\": IntegerParameter(1, 10),\n",
    "    }\n",
    "objective_metric_name = \"validation:auc\"\n",
    "\n",
    "step_tuning = TuningStep(\n",
    "    name = \"ChurnHyperParameterTuning\",\n",
    "    tuner = HyperparameterTuner(xgb_train, objective_metric_name, hyperparameter_ranges, max_jobs = 2, max_parallel_jobs = 2),\n",
    "    inputs = {\n",
    "            \"train\": TrainingInput(\n",
    "                s3_data = step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"train\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type = \"text/csv\",\n",
    "            ),\n",
    "            \"validation\": TrainingInput(\n",
    "                s3_data = step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"validation\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type = \"text/csv\",\n",
    "            ),\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ChurnEvalBestModel** 단계는 **step_eval** 변수에서 정의됩니다. \n",
    "\n",
    "단계 구성에는 다음 항목이 포함됩니다.\n",
    "- **Type**: Processing입니다.\n",
    "- **Processor**: ScriptProcessor입니다.\n",
    "- **Inputs**: 이 작업은 ChurnHyperParameterTuning(**step_tuning**)의 상위 모델과 ChurnModelProcess(**step_process**)의 테스트 출력을 사용합니다.\n",
    "- **Outputs**: 출력은 기본 S3 버킷에 작성됩니다.\n",
    "- **Code**: Amazon S3에 있는 **evaluate.py** 스크립트가 평가에 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-churn-best-model\n",
    "evaluation_report = PropertyFile(\n",
    "    name = \"ChurnEvaluationReport\",\n",
    "    output_name = \"evaluation\",\n",
    "    path = \"evaluation.json\",\n",
    ")\n",
    "\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri = image_uri,\n",
    "    command = [\"python3\"],\n",
    "    instance_type = processing_instance_type,\n",
    "    instance_count = 1,\n",
    "    base_job_name = \"script-churn-eval\",\n",
    "    role = role,\n",
    "    sagemaker_session = sagemaker_session,\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name = \"ChurnEvalBestModel\",\n",
    "    processor = script_eval,\n",
    "    inputs = [\n",
    "        ProcessingInput(\n",
    "            source = step_tuning.get_top_model_s3_uri(top_k = 0, s3_bucket = default_bucket, prefix = \"output\"),\n",
    "            destination = \"/opt/ml/processing/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source = step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri,\n",
    "            destination = \"/opt/ml/processing/test\"\n",
    "        )\n",
    "    ],\n",
    "    outputs = [\n",
    "        ProcessingOutput(output_name = \"evaluation\", source = \"/opt/ml/processing/evaluation\",\\\n",
    "                            destination = f\"s3://{default_bucket}/output/evaluation\"),\n",
    "    ],\n",
    "    code = f\"s3://{default_bucket}/input/code/evaluate.py\",\n",
    "    property_files = [evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ChurnCreateModel** 단계는 **step_create_model** 변수에서 정의됩니다. \n",
    "\n",
    "단계 구성에는 다음 항목이 포함됩니다.\n",
    "- **Type**: Model. Model() 클래스를 사용하여 모델 작업을 정의합니다.\n",
    "- **Model**: 이 단계에서 사용되는 모델은 이전에 정의한 **model** 변수에서 정의됩니다. **model** 변수는 ChurnHyperParameterTuning(**step_tuning**)에서 생성된 상위 모델을 사용합니다.\n",
    "- **Inputs**: 입력에는 인스턴스 유형과 액셀러레이터 유형이 포함됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-model-creation\n",
    "model = Model(\n",
    "    image_uri = image_uri,        \n",
    "    model_data = step_tuning.get_top_model_s3_uri(top_k = 0,s3_bucket = default_bucket,prefix = \"output\"),\n",
    "    name = model_name,\n",
    "    sagemaker_session = sagemaker_session,\n",
    "    role = role,\n",
    ")\n",
    "\n",
    "inputs = CreateModelInput(\n",
    "    instance_type = \"ml.m5.large\",\n",
    "    accelerator_type = \"ml.inf1.xlarge\",\n",
    ")\n",
    "\n",
    "step_create_model = CreateModelStep(\n",
    "    name = \"ChurnCreateModel\",\n",
    "    model = model,\n",
    "    inputs = inputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ChurnModelConfigFile** 단계는 **step_config_file** 변수에서 정의됩니다. \n",
    "\n",
    "단계 구성에는 다음 항목이 포함됩니다.\n",
    "- **Type**: Processing입니다.\n",
    "- **Processor**: ScriptProcessor입니다.\n",
    "- **Code**: 기본 S3 버킷에 있는 **generate_config.py**입니다.\n",
    "- **Job Arguments**: 작업 인수에는 **ChurnCreateModel**에서 생성된 모델, 바이어스 보고서 경로, 기본 버킷, 샘플 수, 처리에 사용되는 인스턴스 수가 포함됩니다.\n",
    "- **Depends On**: 모델 생성이 완료될 때까지는 이 작업을 실행할 수 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#configure-script-processing\n",
    "bias_report_output_path = f\"s3://{default_bucket}/clarify-output/bias\"\n",
    "clarify_instance_type = 'ml.m5.xlarge'\n",
    "analysis_config_path = f\"s3://{default_bucket}/clarify-output/bias/analysis_config.json\"\n",
    "clarify_image = sagemaker.image_uris.retrieve(framework = 'sklearn', version = sklearn_processor_version, region = region)\n",
    "\n",
    "#custom_image_uri = None\n",
    "script_processor = ScriptProcessor(\n",
    "    command = ['python3'],\n",
    "    image_uri = clarify_image,\n",
    "    role = role,\n",
    "    instance_count = 1,\n",
    "    instance_type = processing_instance_type,\n",
    "    sagemaker_session = sagemaker_session,\n",
    ")\n",
    "\n",
    "step_config_file = ProcessingStep(\n",
    "    name = \"ChurnModelConfigFile\",\n",
    "    processor = script_processor,\n",
    "    code = f\"s3://{default_bucket}/input/code/generate_config.py\",\n",
    "    job_arguments = [\"--modelname\", step_create_model.properties.ModelName, \"--bias-report-output-path\", bias_report_output_path, \"--clarify-instance-type\", clarify_instance_type,\\\n",
    "                  \"--default-bucket\", default_bucket, \"--num-baseline-samples\", \"50\", \"--instance-count\", \"1\"],\n",
    "    depends_on = [step_create_model.name]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ChurnTransform** 단계는 **step_transform** 변수에서 정의됩니다. \n",
    "\n",
    "단계 구성에는 다음 항목이 포함됩니다.\n",
    "- **Type**: Transform. TransformStep() 클래스를 사용하여 변환 작업을 정의합니다.\n",
    "- **Transformer**: 변환기 세부 정보는 앞에서 정의한 **transformer** 변수에서 설정됩니다. 이 변수는 ChurnCreateModel(**step_create_model**)에서 생성된 모델을 사용합니다.\n",
    "- **Inputs**: 이전 과제를 수행할 때 노트북에서 정의한 변환되는 데이터(batch.csv)입니다. 입력에는 파일 형식과 파일 분할 방법도 포함됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-inference\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type = \"ml.m5.xlarge\",\n",
    "    instance_count = 1,\n",
    "    assemble_with = \"Line\",\n",
    "    accept = \"text/csv\",    \n",
    "    output_path = f\"s3://{default_bucket}/ChurnTransform\"\n",
    "    )\n",
    "\n",
    "step_transform = TransformStep(\n",
    "    name = \"ChurnTransform\",\n",
    "    transformer = transformer,\n",
    "    inputs = TransformInput(data = batch_data, content_type = \"text/csv\", join_source = \"Input\", split_type = \"Line\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ClarifyProcessingStep** 단계는 **step_clarify** 변수에서 정의됩니다. \n",
    "\n",
    "단계 구성에는 다음 항목이 포함됩니다.\n",
    "- **Type**: Processing입니다.\n",
    "- **Processor**: 이 작업에서는 SageMakerClarifyProcessor를 사용합니다. **clarify_processor** 변수에서 프로세서 구성을 검토할 수 있습니다.\n",
    "- **Inputs**: 입력은 **data_input** 및 **congif_input** 변수에서 정의됩니다.\n",
    "- **Outputs**: 출력은 기본 버킷의 폴더에 작성됩니다. \n",
    "- **Depends On**: **ChurnModelConfigFile**을 사용하여 Amazon SageMaker Clarify에 필요한 구성 파일을 생성할 때까지는 이 작업을 실행할 수 없습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-clarify-processing\n",
    "data_config = sagemaker.clarify.DataConfig(\n",
    "s3_data_input_path = f's3://{default_bucket}/output/train/train.csv',\n",
    "s3_output_path = bias_report_output_path,\n",
    "    label = 0,\n",
    "    headers = ['target','esent','eopenrate','eclickrate','avgorder','ordfreq','paperless','refill','doorstep','first_last_days_diff','created_first_days_diff','favday_Friday','favday_Monday','favday_Saturday','favday_Sunday','favday_Thursday','favday_Tuesday','favday_Wednesday','city_BLR','city_BOM','city_DEL','city_MAA'],\n",
    "    dataset_type = \"text/csv\",\n",
    ")\n",
    "\n",
    "clarify_processor = sagemaker.clarify.SageMakerClarifyProcessor(\n",
    "    role = role,\n",
    "    instance_count = 1,\n",
    "    instance_type = clarify_instance_type,\n",
    "    sagemaker_session = sagemaker_session,\n",
    ")\n",
    "\n",
    "config_input = ProcessingInput(\n",
    "    input_name = \"analysis_config\",\n",
    "    source=analysis_config_path,\n",
    "    destination = \"/opt/ml/processing/input/analysis_config\",\n",
    "    s3_data_type = \"S3Prefix\",\n",
    "    s3_input_mode = \"File\",\n",
    "    s3_compression_type = \"None\",\n",
    "    )\n",
    "\n",
    "data_input = ProcessingInput(\n",
    "    input_name = \"dataset\",\n",
    "    source = data_config.s3_data_input_path,\n",
    "    destination = \"/opt/ml/processing/input/data\",\n",
    "    s3_data_type = \"S3Prefix\",\n",
    "    s3_input_mode = \"File\",\n",
    "    s3_data_distribution_type = data_config.s3_data_distribution_type,\n",
    "    s3_compression_type = data_config.s3_compression_type,\n",
    ")\n",
    "\n",
    "result_output = ProcessingOutput( \n",
    "    source = \"/opt/ml/processing/output\",\n",
    "    destination = data_config.s3_output_path,\n",
    "    output_name = \"analysis_result\",\n",
    "    s3_upload_mode = \"EndOfJob\",\n",
    ")\n",
    "\n",
    "step_clarify = ProcessingStep(\n",
    "    name = \"ClarifyProcessingStep\",\n",
    "    processor = clarify_processor,\n",
    "    inputs = [data_input, config_input],\n",
    "    outputs = [result_output],\n",
    "    depends_on = [step_config_file.name]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RegisterChurnModel** 단계는 **step_register** 변수에서 정의됩니다. \n",
    "\n",
    "단계 구성에는 다음 항목이 포함됩니다.\n",
    "- **Type**: RegisterModel. RegisterModel() 클래스를 사용하여 등록 작업을 정의합니다.\n",
    "- **Estimator**: 추정기는 셀 앞부분의 **xgbtrain** 변수에서 정의됩니다.\n",
    "- **Model Data**: **ChurnHyperParameterTuning**에서 반환되는 모델 URI입니다.\n",
    "- **Content Types**: text/csv입니다.\n",
    "- **Response Types**: text/csv입니다.\n",
    "- **Inference Instance**: 추론 처리에 사용할 인스턴스 유형입니다.\n",
    "- **Transform Instance**: 변환을 처리하는 데 사용할 인스턴스 유형입니다.\n",
    "- **Model Package Group Name**: 모델 버전 그룹을 저장할 그룹의 이름입니다.\n",
    "- **Model Metrics**: 모델 지표의 위치를 정의합니다. 지표에 포함된 파일은 SageMaker Clarify 바이어스 보고서, SageMaker Clarify 설명 가능성 보고서 및 모델 평가입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-model-registry\n",
    "model_statistics = MetricsSource(\n",
    "    s3_uri = \"s3://{}/output/evaluation/evaluation.json\".format(default_bucket),\n",
    "    content_type = \"application/json\"\n",
    "    )\n",
    "explainability = MetricsSource(\n",
    "    s3_uri = \"s3://{}/clarify-output/bias/analysis.json\".format(default_bucket),\n",
    "    content_type = \"application/json\"\n",
    "    )\n",
    "\n",
    "bias = MetricsSource(\n",
    "    s3_uri = \"s3://{}/clarify-output/bias/analysis.json\".format(default_bucket),\n",
    "    content_type = \"application/json\"\n",
    "    ) \n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics = model_statistics,\n",
    "    explainability = explainability,\n",
    "    bias = bias\n",
    ")\n",
    "\n",
    "step_register = RegisterModel(\n",
    "    name = \"RegisterChurnModel\",\n",
    "    estimator = xgb_train,\n",
    "    model_data = step_tuning.get_top_model_s3_uri(top_k = 0, s3_bucket = default_bucket, prefix = \"output\"),\n",
    "    content_types = [\"text/csv\"],\n",
    "    response_types = [\"text/csv\"],\n",
    "    inference_instances = [\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "    transform_instances = [\"ml.m5.large\"],\n",
    "    model_package_group_name = model_package_group_name,\n",
    "    model_metrics = model_metrics,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CheckAUCScoreChurnEvaluation** 단계는 **step_cond** 변수에서 정의됩니다. \n",
    "\n",
    "단계 구성에는 다음 항목이 포함됩니다.\n",
    "- **Type**: Condition. ConditionStep() 클래스를 사용하여 조건 작업을 정의합니다.\n",
    "- **Conditions**: **ChurnEvalBestModel**의 출력이 0.75보다 크면 이 조건이 True로 평가됩니다.\n",
    "- **If Steps**: 조건이 True로 평가되면 실행할 단계의 목록입니다.\n",
    "- **Else Steps**: 조건이 False로 평가되면 실행할 단계의 목록입니다. 이 목록은 비어 있습니다. 즉, 조건이 충족되지 않으면 파이프라인 처리가 중지됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "cond_lte = ConditionGreaterThan(\n",
    "    left = JsonGet(\n",
    "        step = step_eval,\n",
    "        property_file = evaluation_report,\n",
    "        json_path = \"binary_classification_metrics.auc.value\"\n",
    "    ),\n",
    "    right = 0.75,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name = \"CheckAUCScoreChurnEvaluation\",\n",
    "    conditions = [cond_lte],\n",
    "    if_steps = [step_create_model, step_config_file, step_transform, step_clarify, step_register],\n",
    "    else_steps = [],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과제 2.2.3: 파이프라인 정의\n",
    "\n",
    "단계를 정의한 후에는 **pipeline** 변수에서 파이프라인을 구성합니다. 앞에서 정의한 단계가 파이프라인 정의로 전달되는 방식을 잘 살펴보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #define pipeline function\n",
    "def get_pipeline(\n",
    "    region,\n",
    "    role = None,\n",
    "    default_bucket = None,\n",
    "    model_package_group_name = \"ChurnModelPackageGroup\",\n",
    "    pipeline_name = \"ChurnModelPipeline\",\n",
    "    base_prefix = None,\n",
    "    custom_image_uri = None,\n",
    "    sklearn_processor_version = None\n",
    "    ):\n",
    "\n",
    "    #configure pipeline instance\n",
    "    pipeline = Pipeline(\n",
    "        name = pipeline_name,\n",
    "        parameters = [\n",
    "            processing_instance_type,\n",
    "            processing_instance_count,\n",
    "            training_instance_type,\n",
    "            input_data,\n",
    "            batch_data,\n",
    "        ],\n",
    "        steps = [step_process, step_tuning, step_eval, step_cond],\n",
    "        sagemaker_session = sagemaker_session\n",
    "    )\n",
    "    return pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과제 2.2.4: 파이프라인 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #create pipeline using function\n",
    "pipeline = get_pipeline(\n",
    "  region = region,\n",
    "    role = role,\n",
    "    default_bucket = default_bucket,\n",
    "    model_package_group_name = model_package_group_name,\n",
    "    pipeline_name = pipeline_name,\n",
    "    custom_image_uri = clarify_image,\n",
    "    sklearn_processor_version = sklearn_processor_version\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과제 2.2.5: 올바른 IAM 역할을 사용하도록 파이프라인 업데이트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set-iam-role\n",
    "pipeline.upsert(role_arn = role)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**참고**: 셀을 실행한 후에 다음 경고가 표시되면 무시해도 됩니다.\n",
    "\n",
    "\"No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\"(이 추정기와 관련하여 완료된 훈련 작업이 없습니다. 이 추정기가 워크플로 구성 빌드에만 사용되는지 확인하세요.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과제 2.2.6: 파이프라인 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start-pipeline\n",
    "RunPipeline = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과제 2.2.7: 파이프라인 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe-pipeline\n",
    "RunPipeline.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 파이프라인을 실행하려면 약 35분이 소요됩니다.\n",
    "\n",
    "파이프라인이 실행되는 동안 다음 과제를 계속 진행하여 Amazon SageMaker Studio 콘솔에서 파이프라인을 살펴봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과제 2.3: 파이프라인 모니터링 및 승인\n",
    "\n",
    "이 과제에서는 Amazon SageMaker Studio 콘솔을 사용하여 파이프라인을 살펴봅니다.\n",
    "\n",
    "### 과제 2.3.1: SageMaker Studio에서 파이프라인 모니터링\n",
    "\n",
    "다음 과제에서는 SageMake Studio에서 새 탭이 열립니다. 여기서 설명하는 지침에 따라 작업을 진행하려면 다음 옵션 중 하나를 사용하세요.\n",
    "- **옵션 1**: 탭을 나란히 표시합니다. 주 SageMaker Studio 창에서 분할 화면 보기를 생성하려면 **lab_10.ipynb** 탭을 옆쪽으로 끌거나 **lab_10.ipynb** 탭을 마우스 오른쪽 버튼으로 클릭하여 선택한 후 **New View for Notebook**을 선택합니다. 그러면 파이프라인 단계를 살펴볼 때 지침을 표시할 수 있습니다.\n",
    "- **옵션 2**: SageMaker Studio 탭을 서로 전환하면서 지침에 따라 작업을 진행합니다. 파이프라인 단계 결과 탐색을 완료한 후 **lab_10.ipynb** 탭을 선택하여 노트북으로 돌아옵니다.\n",
    "\n",
    "1. SageMaker Studio에서 **SageMaker Home** 아이콘을 선택합니다.\n",
    "1. **Pipelines**를 선택합니다.\n",
    "\n",
    "SageMaker Studio에서 **Pipelines** 탭이 열립니다.\n",
    "\n",
    "1. **ChurnModelSMPipeline**이라는 파이프라인을 선택합니다. \n",
    "\n",
    "SageMaker Studio에서 **ChurnModelSMPipeline** 탭이 열립니다.\n",
    "\n",
    "1. **ChurnModelSMPipeline** 탭의 **Executions**에서 파이프라인 상태를 마우스 오른쪽 버튼으로 클릭하여 열고 **Open execution details**를 선택합니다. \n",
    "\n",
    "SageMaker Studio에서 **Directed Acyclic Graph**(DAG) 페이지가 열립니다.\n",
    "\n",
    "DAG(Directed Acyclic Graph)에 파이프라인 워크플로와 진행률이 표시됩니다. DAG에서는 각 단계 상태가 고유한 색상으로 표시됩니다. 단계 색상 표시기는 다음과 같습니다.\n",
    "- **회색**: 실행 대기 중.\n",
    "- **파란색**: 실행 중.\n",
    "- **녹색**: 성공적으로 완료됨.\n",
    "- **빨간색**: 오류.\n",
    "\n",
    "여기서 살펴보는 각 단계의 단계 세부 정보 창에는 동일한 탭 4개가 있습니다. 탭 제목은 동일하지만 각 탭의 내용은 작업 유형과 작업 구성에 따라 달라집니다.\n",
    "\n",
    "- **Input**: 작업으로 전달된 입력이 포함되어 있는 탭입니다. 입력의 예로는 인스턴스 유형, AWS Identity and Access Management(IAM) 역할 또는 작업 실행에 필요한 인수를 지정하는 파라미터가 포함됩니다. 코드, 데이터 집합, Docker 이미지 등의 파일도 입력의 예에 포함됩니다.\n",
    "- **Output**: 작업에서 생성된 출력이 표시되는 탭입니다. 출력의 예로는 지표, 차트, 파일, 평가 결과 등이 있습니다.\n",
    "- **Logs**: 작업과 연관된 로그 목록이 제공되는 탭입니다. Amazon CloudWatch Logs 액세스 권한이 있는 사용자는 로그 링크를 선택하여 CloudWatch에서 세부 로그 메시지를 확인할 수 있습니다. 로그가 생성되지 않는 작업 유형도 있습니다.\n",
    "- **Information**: 작업 유형, 작업 이름, 작업 실행 시간 등 작업에 관한 기본적인 정보가 제공되는 탭입니다.\n",
    "\n",
    "1. **ChurnModelProcess** 단계를 선택합니다. 이름이 **ChurnModelProcess**인 새 창이 표시됩니다.\n",
    "1. **ChurnModelProcess** 창에서 이 파이프라인 단계와 연관된 탭을 검토합니다. \n",
    "    - **Input** 탭을 선택합니다. 이 탭에는 처리 단계에서 사용하는 파일 및 파라미터와 관련된 유용한 정보가 포함되어 있습니다. 파라미터 목록에는 작업에서 사용하는 인스턴스 유형과 이미지, 데이터 집합 위치, 코드 위치, 생성되는 여러 출력의 대상을 비롯한 세부 정보가 있습니다. 창 아래쪽으로 스크롤하여 작업으로 전달된 파일 입력을 확인합니다.\n",
    "    - **Outputs** 탭을 선택합니다. 이 탭에는 파이프라인 단계에서 생성된 여러 파일과 해당 파일이 있는 위치가 표시됩니다. 이 파이프라인은 SageMaker Studio 기본 버킷에 모든 출력을 저장합니다.\n",
    "    - **Logs** 탭을 선택합니다. 이 탭에는 작업에서 생성되는 로그가 표시됩니다. SageMaker Studio 내에서 로깅을 사용 가능하도록 설정하면 파이프라인 단계가 정상적으로 실행되지 않을 때 조사와 문제 해결을 빠르게 진행할 수 있습니다.\n",
    "    - **Information** 탭을 선택합니다. 이 탭에서는 파이프라인 단계의 대략적인 개요가 제공됩니다. 개요에는 단계 유형, 단계 이름, 작업 로그 링크 등의 정보가 포함됩니다. 그리고 작업 실행 시간 및 작업을 실행하는 데 걸린 시간에 관한 세부 정보도 제공됩니다.\n",
    "        - **Step Type**은 **Processing**입니다.\n",
    "\n",
    "### 과제 2.3.2: 파이프라인 단계 세부 정보 검색\n",
    "\n",
    "이어지는 단계에서는 DAG(Directed Acyclic Graph)에서 적절한 노드를 선택하여 지정된 파이프라인 단계에 관한 정보를 찾습니다. 아래에 나와 있는 문제의 해답을 찾는 과정에서 도움이 필요한 경우, 이 Python 노트북 끝부분에 포함되어 있는 정답이나 힌트를 참조할 수 있습니다.\n",
    "\n",
    "1. **ChurnHyperParameterTuning** 단계에서 다음 세부 정보를 찾습니다.\n",
    "    - 이 단계의 **Step Type**은 무엇인가요?\n",
    "    - 이 단계에서 생성된 **Overall Best Training Job**은 어느 것인가요?\n",
    "1. **ChurnEvalBestModel** 단계에서 다음 세부 정보를 찾습니다.\n",
    "    - 이 단계의 **Step Type**은 무엇인가요?\n",
    "    - 이전 단계에서 확인된 상위 모델을 평가하는 데 사용되는 Python 스크립트의 이름은 무엇인가요?\n",
    "    - 이 파일은 어디에 있나요?\n",
    "    - 이 단계의 결과는 어디에 작성되었나요?\n",
    "1. **CheckAUCScoreChurnEvaluation** 단계에서 다음 세부 정보를 찾습니다.\n",
    "    - 이 단계의 **Step Type**은 무엇인가요?\n",
    "    - **Evaluation outcome**은 무엇인가요?\n",
    "1. **ChurnCreateModel** 단계에서 다음 세부 정보를 찾습니다.\n",
    "    - 이 단계의 **Step Type**은 무엇인가요?\n",
    "    - 이 작업에서 로그가 생성되었나요?\n",
    "1. **RegisterChurnModel** 단계에서 다음 세부 정보를 찾습니다.\n",
    "    - 이 단계의 **Step Type**은 무엇인가요?\n",
    "    - AUC(곡선 아래 면적) 지표의 값은 무엇인가요?\n",
    "1. **ChurnTransform** 단계에서 다음 세부 정보를 찾습니다.\n",
    "    - 이 단계의 **Step Type**은 무엇인가요?\n",
    "    - 이 작업에서 로그가 생성되었나요?\n",
    "    - 이 단계의 입력으로 사용된 파일은 무엇인가요?\n",
    "1. **ChurnModelConfigFile** 단계에서 다음 세부 정보를 찾습니다. \n",
    "    - 이 작업을 실행하는 데 사용된 ProcessingInstanceType은 무엇인가요?\n",
    "    - 이 단계의 **Step Type**은 무엇인가요?\n",
    "1. **ClarifyProcessingStep** 단계에서 다음 세부 정보를 찾습니다.\n",
    "    - 이 단계의 파일 출력은 무엇인가요?\n",
    "    - 출력은 어디에 작성되었나요?\n",
    "\n",
    "### 2.3.3: 파이프라인에서 모델 승인\n",
    "\n",
    "1. 파이프라인 실행이 완료되면 **Model registry**에서 파이프라인이 생성한 모델을 확인합니다.\n",
    "    SageMaker Studio에서 **SageMaker Home** 아이콘을 선택합니다.\n",
    "    - **Models** 목록을 확장합니다.\n",
    "    - **Model registry**를 선택합니다.\n",
    "    - **ChurnModelPackageGroup** 모델 그룹을 엽니다.\n",
    "    - **ChurnModelPackageGroup** 탭에서 **Versions** 테이블의 행을 마우스 오른쪽 버튼으로 클릭하여 열고 **Open model version**을 선택합니다. 모델 상태는 **Pending**입니다. **Execution** 값은 방금 완료된 파이프라인 실행의 이름입니다.\n",
    "\n",
    "    각 탭에서 파이프라인에 관한 추가 세부 정보를 확인할 수 있습니다.\n",
    "    - **Activity**: 모델의 활동이 표시되는 탭입니다. 모델을 수정한 후 경과한 시간과 이벤트 정보가 수록되어 있습니다.\n",
    "    - **Model quality**: 모델 정확도 지표가 표시되는 탭입니다.\n",
    "    - **Explainability**: 모델 특성의 중요도가 Shapley 값(SHAP) 단위로 표시되는 탭입니다.\n",
    "    - **Bias report**: 모델에 포함될 수 있는 바이어스가 표시되는 탭입니다.\n",
    "    - **Inference recommender**: 모델의 가성비를 높일 수 있는 권장 사항이 제공되는 탭입니다. 이 모델 패키지에서는 해당 기능이 지원되지 않으므로 이 탭에는 데이터가 포함되어 있지 않습니다.\n",
    "    - **Load test**: 이 탭에서는 부하 테스트를 시작하여 다양한 인스턴스 유형을 실행해 보고 각 유형이 프로덕션 배포에 필요한 처리량 및 지연 시간 지표를 충족하는지 평가할 수 있습니다.\n",
    "    - **Settings**: 모델이 생성된 시간, 모델이 생성된 파이프라인, 모델의 위치, 모델과 연관된 시험 구성 요소 등의 정보가 표시되는 탭입니다.\n",
    "\n",
    "1. 모델을 승인합니다. 이 프로세스에서는 모델을 승인하기 전에 수동으로 검토해야 합니다. 하지만 파이프라인 내에서 모델 승인을 자동화할 수 있습니다.\n",
    "    - <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">**Update status**</span>를 선택합니다.\n",
    "    - 드롭다운 목록을 열고 <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">**Approved**</span>를 선택합니다.\n",
    "    - <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">**Update status**</span>를 선택합니다.\n",
    "1. **ChurnModelPackageGroup** 탭을 닫습니다.\n",
    "\n",
    "### 과제 2.3.4: AWS SDK를 사용하여 파이프라인 단계 확인\n",
    "\n",
    "SageMaker Studio UI를 사용하여 파이프라인 세부 정보를 확인할 수 있을 뿐만 아니라 AWS SDK 명령을 사용할 수도 있습니다. 예를 들어, 다음 명령은 파이프라인 단계 목록을 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list-steps\n",
    "RunPipeline.list_steps()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과제 2.4: 아티팩트 검토\n",
    "\n",
    "다음 과제에서는 SageMake Studio에서 새 탭이 열립니다. 여기서 설명하는 지침에 따라 작업을 진행하려면 다음 옵션 중 하나를 사용하세요.\n",
    "- **옵션 1**: 탭을 나란히 표시합니다. 주 SageMaker Studio 창에서 분할 화면 보기를 생성하려면 **lab_10.ipynb** 탭을 옆쪽으로 끌거나 **lab_10.ipynb** 탭을 마우스 오른쪽 버튼으로 클릭하여 선택한 후 **New View for Notebook**을 선택합니다. 그러면 아티팩트를 살펴볼 때 지침을 표시할 수 있습니다.\n",
    "- **옵션 2**: SageMaker Studio 탭을 서로 전환하면서 지침에 따라 작업을 진행합니다. 아티팩트 탐색을 완료한 후 **lab_10.ipynb** 탭을 선택하여 노트북으로 돌아옵니다.\n",
    "\n",
    "### 과제 2.4.1: SageMaker Studio에서 아티팩트 검토\n",
    "\n",
    "파이프라인이 실행되면 각 단계에서 파일, 훈련된 파라미터, 모델 등의 아티팩트가 생성됩니다. SageMaker Studio의 파이프라인에서 생성된 아티팩트를 확인할 수 있습니다.\n",
    "1. **ChurnModelSMPipeline** 탭으로 돌아옵니다.\n",
    "1. **Executions** 탭을 선택합니다.\n",
    "1. 목록에 나열된 실행을 마우스 오른쪽 버튼으로 클릭하여 열고 **View trial components generated by execution**을 선택합니다. \n",
    "\n",
    "SageMaker Studio에서 이름이 **Trial Component List**인 새 탭이 열립니다. \n",
    "\n",
    "파이프라인에서 실행된 모든 작업의 목록이 이 탭에 표시됩니다.\n",
    "\n",
    "각 시험 구성 요소에는 **Trial Component Type**이 지정되어 있습니다. 관련 시험 세부 정보의 여러 탭에서 제공되는 정보는 시험 구성 요소 유형에 따라 다릅니다. 시험 세부 정보에서 일부 구성 요소 유형의 데이터가 표시되지 않는 탭도 있습니다.\n",
    "\n",
    "1. 작업 목록의 맨 위 행을 마우스 오른쪽 버튼으로 클릭하여 열고 **Open in trial details**를 선택합니다. \n",
    "\n",
    "SageMaker Studio에서 이름이 **Describe Trial Component**인 새 탭이 열립니다. \n",
    "\n",
    "**Trial Components** 아래에는 여러 탭이 있습니다. 파이프라인 단계에서 수행한 작업에 따라 일부 탭은 비어 있을 수도 있습니다. \n",
    "\n",
    "1. **Artifacts** 탭을 선택합니다. 단계에 사용된 입력과 출력의 세부 정보를 볼 수 있습니다.\n",
    "1. **Explainability** 탭을 선택합니다. 이 탭에는 SageMaker Clarify에서 생성된 설명 가능성 보고서가 표시됩니다.\n",
    "1. **Bias Report** 탭을 선택합니다. 이 탭에는 SageMaker Clarify에서 생성된 바이어스 보고서가 표시됩니다.\n",
    "\n",
    "### 과제 2.4.2: 기본 S3 버킷에서 아티팩트 찾기\n",
    "**참고**: 이 과제에는 AWS Management Console을 사용합니다. S3 버킷을 살펴본 후 SageMaker Studio가 열려 있는 브라우저 탭으로 돌아와 **lab_10.ipynb** 탭을 선택합니다.\n",
    "\n",
    "1. 콘솔이 열려 있는 브라우저 탭에서 Amazon S3로 이동합니다.\n",
    "1. **sagemaker-** 와 AWS 리전으로 시작하는 버킷 이름(예: **sagemaker-us-west-2-123456789**)을 선택합니다.\n",
    "1. 이 버킷에 있는 폴더와 파일을 살펴봅니다. 이 버킷에는 데이터 집합, 처리 입력과 출력, SageMaker Clarify 결과 그리고 결과 모델에 사용된 기타 파일이 포함되어 있습니다.\n",
    "1. SageMaker Studio가 열려 있는 브라우저 탭으로 돌아와 **lab_10.ipynb** 탭을 선택합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과제 2.5(선택 사항): 파이프라인용 계보 빌드 및 검토\n",
    "\n",
    "이전 과제에서는 SageMaker Clarify를 사용해 모델이 예측을 하는 방식을 설명하고 모델에 포함될 수 있는 바이어스를 파악하는 방법을 알아보았습니다. SageMaker Clarify를 사용하여 모델을 생성하는 데 사용되는 단계를 검색할 수도 있습니다. 모델을 감사할 때 이러한 방식으로 단계를 검색해야 하는 경우가 많습니다. 이 과제에서는 MLLineageHelper 모듈을 활용하여 현재 파이프라인 실행의 계보를 빌드합니다. ML Lineage Helper에 관한 자세한 내용은 [MLLineageHelper](https://github.com/aws-samples/ml-lineage-helper)를 참조하세요.\n",
    "\n",
    "Amazon SageMaker ML Lineage Tracking은 ML 워크플로에 포함되어 있는 데이터 준비에서 모델 배포까지의 단계에 관한 정보를 생성하여 저장합니다. 이러한 추적 정보를 활용하면 워크플로 단계 재현, 모델 및 데이터 집합 계보 추적, 모델 거버넌스 및 감사 표준 설정 등의 작업을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과제 2.5.1: 세션 및 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set-variables\n",
    "fs_query = feature_group.athena_query()\n",
    "fs_table = fs_query.table_name\n",
    "query_string = 'SELECT * FROM \"'+fs_table+'\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과제 2.5.2: 모델 계보를 빌드하는 데 사용할 값 표시\n",
    "\n",
    "구성에 포함되는 항목은 다음과 같습니다.\n",
    "- **query_string**: MLLineageHelper 모듈로 전달되는 SageMaker Feature Store 쿼리입니다.\n",
    "- **model_ref**: 평가 중인 모델의 이름입니다.\n",
    "- **processing_job**: 모델을 생성한 처리 작업의 이름입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print-values\n",
    "print ('query_string:',query_string)\n",
    "\n",
    "model_ref = sagemaker_client.list_models(SortBy = 'CreationTime', SortOrder = 'Descending')['Models'][0]['ModelName']\n",
    "print ('model_ref:',model_ref)\n",
    "\n",
    "processing_job = sagemaker_client.list_processing_jobs(SortBy = 'CreationTime', SortOrder = 'Descending', NameContains = 'ChurnModelProcess')['ProcessingJobSummaries'][0]['ProcessingJobName']\n",
    "print ('processing_job:',processing_job)\n",
    "\n",
    "processing_job_description = sagemaker_client.describe_processing_job(\n",
    "    ProcessingJobName = processing_job\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과제 2.5.3: 처리 작업 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe-processing-job\n",
    "processing_job_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과제 2.5.4: 모델을 생성하는 데 사용된 훈련 작업의 이름 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print-training-job\n",
    "training_job_name  =  sagemaker_client.list_training_jobs(SortBy = 'CreationTime', SortOrder = 'Descending')['TrainingJobSummaries'][0]['TrainingJobName']\n",
    "print (training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과제 2.5.5: 모델의 계보 빌드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 오류가 표시되면 셀을 다시 실행합니다.\n",
    "- **ClientError: An error occurred (ThrottlingException) when calling the UpdateArtifact operation (reached max retries: 4): Rate exceeded**(ClientError: UpdateArtifact 작업 호출 중 오류 발생(ThrottlingException)(최대 재시도 횟수 도달: 4): 빈도가 초과됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build-lineage\n",
    "ml_lineage = MLLineageHelper()\n",
    "lineage = ml_lineage.create_ml_lineage(training_job_name, model_name = model_ref,\n",
    "                                       query = query_string, sagemaker_processing_job_description = processing_job_description,\n",
    "                                       feature_group_names = [feature_group_name])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과제 2.5.6: 현재 시험 및 특성 그룹만 포함하도록 계보 제한\n",
    "\n",
    "파이프라인은 여러 번 실행할 수 있습니다. 가장 최근의 훈련 작업 실행에서 세부 정보를 검색하려는 경우 현재 시험의 이름과 시험에서 사용하는 특성 그룹을 사용하여 계보 호출을 필터링합니다. \n",
    "\n",
    "이 셀을 실행하고 나면 모델을 생성하는 데 사용된 단계, 단계가 실행된 순서 그리고 파이프라인 내의 다른 작업을 실행하기 위해 실행된 작업이 하나의 테이블로 표시됩니다. **lineage_FS.csv** 파일에도 같은 정보가 작성됩니다. 이 파일을 다운로드하여 출력을 저장한 후 감사자 등 다른 팀원과 공유할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit-lineage\n",
    "trial_name = RunPipeline.describe()['PipelineExperimentConfig']['TrialName']\n",
    "pat = str(trial_name)+'|'+'fg-FG'\n",
    "df1 = lineage[lineage.apply(lambda x: any(x.str.contains(pat)),axis = 1)]\n",
    "pd.set_option('display.max_colwidth', 120)\n",
    "df1.to_csv('lineage_FS.csv') \n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과제 2.5.7: 모델 계보의 시각화 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize-lineage\n",
    "plt.figure(3, figsize = (20, 14))\n",
    "graph = nx.DiGraph()\n",
    "graph.add_edges_from([(each[0], each[2]) for each in df1.values])\n",
    "fig, ax = plt.subplots()\n",
    "nx.draw_networkx(\n",
    "    graph,\n",
    "    node_size = 300,\n",
    "    node_color = \"orange\",\n",
    "    alpha = 0.65,\n",
    "    font_size = 8,\n",
    "    pos = nx.spring_layout(graph)\n",
    ")\n",
    "ax.set_facecolor('deepskyblue')\n",
    "ax.axis('off')\n",
    "fig.set_facecolor('deepskyblue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과제 2.6: 파이프라인 제거\n",
    "\n",
    "파이프라인을 삭제하려면 다음 셀을 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete-pipeline\n",
    "response = sagemaker_client.delete_pipeline(PipelineName = 'ChurnModelSMPipeline')\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 마무리 \n",
    "\n",
    "축하합니다! SageMaker 파이프라인을 사용하여 모델 생성과 등록을 자동화했습니다. 그리고 각 파이프라인 단계를 드릴다운하여 연관된 파라미터, 파일 및 로그를 확인하는 방법을 알아보았습니다. 또한 파이프라인에서 모델을 생성하는 데 사용한 자산을 확인하는 방법, 모델 레지스트리에서 모델을 찾는 방법 그리고 파이프라인이 생성할 수 있는 설명 가능성 및 바이어스 보고서를 찾아서 확인하는 방법도 살펴보았습니다.\n",
    "\n",
    "### 정리\n",
    "\n",
    "이 노트북을 완료했습니다. 실습의 다음 부분으로 이동하려면 다음을 수행합니다.\n",
    "\n",
    "- 이 노트북 파일을 닫습니다.\n",
    "- 실습 세션으로 돌아가 **Conclusion** 부분을 계속 진행합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과제 2.3.1.1의 힌트와 정답\n",
    "일반 힌트: **Step type**은 **Information** 탭에서 확인할 수 있습니다.\n",
    "\n",
    "1. **ChurnHyperParameterTuning** 단계에서 다음 세부 정보를 찾습니다.\n",
    "    - 이 단계의 **Step Type**은 무엇인가요?</br>\n",
    "    **정답**: Tuning</br>\n",
    "    - 이 단계에서 생성된 **Overall Best Training Job**은 어느 것인가요? </br>\n",
    "    **힌트**: 이 정보는 **Output** 탭에서 확인할 수 있습니다.</br>\n",
    "    **정답**: 생성되는 모델 이름은 수강생별로 다릅니다. 예를 들어 056vhzs2vkxc-ChurnHy-TCAtUr16oV-001-17d5bd01과 비슷한 이름이 생성됩니다.\n",
    "1. **ChurnEvalBestModel** 단계에서 다음 세부 정보를 찾습니다.\n",
    "    - 이 단계의 **Step Type**은 무엇인가요?\n",
    "    **정답**: Processing</br>\n",
    "    - 이전 단계에서 확인된 상위 모델을 평가하는 데 사용되는 Python 스크립트의 이름은 무엇인가요?</br>\n",
    "    **힌트**: 이 정보는 **Input** 탭에서 확인할 수 있습니다.</br>\n",
    "    **정답**: evaluate.py</br>\n",
    "    - 이 파일은 어디에 있나요?</br>\n",
    "    **힌트**: 이 정보는 **Input** 탭에서 확인할 수 있습니다.</br>\n",
    "    **정답**: 해당 파일은 S3 버킷에 있습니다. 버킷의 경로는 예를 들어 s3://sagemaker-us-west-2-1234567890/input/code/evaluate.py와 비슷합니다.</br>\n",
    "    - 이 단계의 결과는 어디에 작성되었나요?</br>\n",
    "    **힌트**: 이 정보는 **Output** 탭에서 확인할 수 있습니다.</br>\n",
    "    **정답**: 평가 결과는 S3 버킷에 작성되었습니다. 파일 경로는 예를 들어 s3://sagemaker-us-west-2-1234567890/output/evaluation과 비슷합니다.</br>\n",
    "1. **CheckAUCScoreChurnEvaluation** 단계에서 다음 세부 정보를 찾습니다.\n",
    "    - 이 단계의 **Step Type**은 무엇인가요?</br>\n",
    "    **정답**: Condition</br>\n",
    "    - **Evaluation outcome**은 무엇인가요?</br>\n",
    "    **힌트**: 이 정보는 **Output** 탭에서 확인할 수 있습니다.</br>\n",
    "    **정답**: True\n",
    "1. **ChurnCreateModel** 단계에서 다음 세부 정보를 찾습니다.\n",
    "    - 이 단계의 **Step Type**은 무엇인가요?</br>\n",
    "    **정답**: Model</br>\n",
    "    - 이 작업에서 로그가 생성되었나요?</br>\n",
    "    **정답**: 아니요\n",
    "1. **RegisterChurnModel** 단계에서 다음 세부 정보를 찾습니다.\n",
    "    - 이 단계의 **Step Type**은 무엇인가요?</br>\n",
    "    **정답**: RegisterModel</br>\n",
    "    - AUC 지표의 값은 무엇인가요?</br>\n",
    "    **힌트**: 이 정보는 **Output** 탭에서 확인할 수 있습니다.</br>\n",
    "    **정답**: 이 값은 수강생별로 다르지만 0.98에 가까운 값이 표시됩니다.\n",
    "1. **ChurnTransform** 단계에서 다음 세부 정보를 찾습니다.\n",
    "    - 이 단계의 **Step Type**은 무엇인가요?</br>\n",
    "    **정답**: Transform</br>\n",
    "    - 이 작업에서 로그가 생성되었나요?</br>\n",
    "    **정답**: Yes</br>\n",
    "    - 이 단계의 입력으로 사용된 파일은 무엇인가요?</br>\n",
    "    **힌트**: 이 정보는 **Input** 탭에서 확인할 수 있습니다. 파일 이름을 확인하려면 창 아래쪽으로 스크롤해야 할 수 있습니다.</br>\n",
    "    **정답**: model.tar.gz, sagemaker-xgboost:1.5-1-cpu-py3, batch.csv\n",
    "1. **ChurnModelConfigFile** 단계에서 다음 세부 정보를 찾습니다. \n",
    "    - 이 작업을 실행하는 데 사용된 ProcessingInstanceType은 무엇인가요?</br>\n",
    "    **힌트**: 이 정보는 **Input** 탭에서 확인할 수 있습니다.</br>\n",
    "    **정답**: ml.m5.xlarge\n",
    "    - 이 단계의 **Step Type**은 무엇인가요?</br>\n",
    "    **정답**: Processing\n",
    "1. **ClarifyProcessingStep** 단계에서 다음 세부 정보를 찾습니다.\n",
    "    - 이 단계의 파일 출력은 무엇인가요?\n",
    "    **힌트**: 이 정보는 **Output** 탭에서 확인할 수 있습니다.</br>\n",
    "    **정답**: 출력은 바이어스 데이터입니다.\n",
    "    - 출력은 어디에 작성되었나요?\n",
    "    **정답**: 출력은 S3 버킷에 작성되었습니다. 경로는 예를 들어 s3://sagemaker-us-west-2-1234567890/clarify-output/bias와 비슷합니다."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "741de909edea0d5644898c592544ed98bede62b404d20772e5c4abc3c2f12566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}