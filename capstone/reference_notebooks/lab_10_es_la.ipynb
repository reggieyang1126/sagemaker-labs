{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Laboratorio 10: uso de SageMaker Pipelines y SageMaker Model Registry con SageMaker Studio\n",
    "\n",
    "En este laboratorio, usted crea y ejecuta una canalización de Amazon SageMaker y supervisa su progreso. También ubica y explora algunos de los artefactos que el proceso de machine learning (ML) utiliza o genera.\n",
    "\n",
    "Si el tiempo lo permite, también puede revisar los detalles de linaje del modelo que generó la canalización."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 2.1: configuración del entorno\n",
    "\n",
    "Antes de crear su canalización de SageMaker, debe instalar los paquetes necesarios, importar módulos y organizar los archivos de apoyo para preparar el entorno. Esta canalización se diseñó para utilizar un grupo de funciones, para que también pueda crear un grupo de funciones en Amazon SageMaker Feature Store y ejecutar un flujo de Data Wrangler para preparar su entorno. \n",
    "\n",
    "Ejecute las celdas de esta tarea para hacer lo siguiente:\n",
    "- Instalar dependencias.\n",
    "- Importar los módulos necesarios.\n",
    "- Copiar datos y código en Amazon Simple Storage Service (Amazon S3).\n",
    "- Crear un grupo de funciones.\n",
    "- Ingerir funciones en el grupo de funciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.1.1: instalar dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install dependencies\n",
    "%pip install --upgrade pip \n",
    "%pip install pytest-astropy ==  0.7.0\n",
    "%pip install rsa == 4.7.2\n",
    "%pip install PyYAML\n",
    "!apt update && apt install -y git\n",
    "%pip install git+https://github.com/aws-samples/ml-lineage-helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.1.2: importar módulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import-modules\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker_datawrangler\n",
    "import sagemaker.session\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import uuid\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.model_metrics import (\n",
    "    MetricsSource,\n",
    "    ModelMetrics,\n",
    ")\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    "    ScriptProcessor,\n",
    ")\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThan\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep,\n",
    "    TrainingStep,\n",
    ")\n",
    "from sagemaker.workflow.condition_step import (\n",
    "    ConditionStep,\n",
    "    JsonGet,\n",
    ")\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.pytorch.estimator import PyTorch\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "from ml_lineage_helper import *\n",
    "from sagemaker.feature_store.feature_definition import FeatureDefinition\n",
    "from sagemaker.feature_store.feature_definition import FeatureTypeEnum\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import FeatureStoreOutput\n",
    "from sagemaker.processing import Processor\n",
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.dataset_definition.inputs import AthenaDatasetDefinition, DatasetDefinition, RedshiftDatasetDefinition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sessions\n",
    "boto_session  =  boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create clients\n",
    "s3_client = boto3.client('s3')\n",
    "featurestore_runtime = boto3.client('sagemaker-featurestore-runtime')\n",
    "sagemaker_client = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature store session\n",
    "feature_store_session = Session(\n",
    "    boto_session = boto_session,\n",
    "    sagemaker_client = sagemaker_client,\n",
    "    sagemaker_featurestore_runtime_client = featurestore_runtime\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set global variables\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "region = boto_session.region_name\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.1.3: copiar archivos del laboratorio en Amazon S3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload files to default bucket\n",
    "s3_client.put_object(Bucket = default_bucket, Key = 'data/')\n",
    "s3_client.put_object(Bucket = default_bucket, Key = 'input/code/')\n",
    "s3_client.upload_file('pipelines/data/storedata_total.csv', default_bucket, 'data/storedata_total.csv')\n",
    "s3_client.upload_file('pipelines/input/code/evaluate.py', default_bucket, 'input/code/evaluate.py')\n",
    "s3_client.upload_file('pipelines/input/code/generate_config.py', default_bucket, 'input/code/generate_config.py')\n",
    "s3_client.upload_file('pipelines/input/code/processfeaturestore.py', default_bucket, 'input/code/processfeaturestore.py')\n",
    "\n",
    "# Preview the dataset\n",
    "print('Dataset preview:')\n",
    "customer_data = pd.read_csv('pipelines/data/storedata_total.csv')\n",
    "customer_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.1.4: crear el grupo de funciones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta tarea, cree un grupo de funciones para los datos. Primero, cree un esquema de los datos. En este laboratorio, el esquema debe ordenarse primero por la columna **name** (nombre), y después por la variable **type** (tipo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set-up-feature-store-variables\n",
    "record_identifier_feature_name = 'FS_ID'\n",
    "event_time_feature_name = 'FS_time'\n",
    "\n",
    "column_schemas = [\n",
    "    {\n",
    "        \"name\": \"retained\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"esent\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"eopenrate\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"eclickrate\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"avgorder\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ordfreq\",\n",
    "        \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"paperless\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"refill\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"doorstep\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"first_last_days_diff\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"created_first_days_diff\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Friday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Monday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Saturday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Sunday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Thursday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Tuesday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"favday_Wednesday\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"city_BLR\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"city_BOM\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"city_DEL\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"city_MAA\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"FS_ID\",\n",
    "        \"type\": \"long\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"FS_time\",\n",
    "        \"type\": \"float\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, cree el grupo de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow name and a unique ID for this export (used later as the processing job name for the export)\n",
    "flow_name = 'featureengineer'\n",
    "flow_export_id = f\"{strftime('%d-%H-%M-%S', gmtime())}-{str(uuid.uuid4())[:8]}\"\n",
    "flow_export_name = f\"flow-{flow_export_id}\"\n",
    "\n",
    "# Feature group name, with flow_name and a unique id. You can give it a customized name\n",
    "feature_group_name = f\"FG-{flow_name}-{str(uuid.uuid4())[:8]}\"\n",
    "\n",
    "# SageMaker Feature Store writes the data in the offline store of a Feature Group to a \n",
    "# Amazon S3 location owned by you.\n",
    "feature_store_offline_s3_uri = 's3://' + default_bucket\n",
    "\n",
    "# Controls if online store is enabled. Enabling the online store allows quick access to \n",
    "# the latest value for a record by using the GetRecord API.\n",
    "enable_online_store = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create-feature-group\n",
    "default_feature_type = FeatureTypeEnum.STRING\n",
    "column_to_feature_type_mapping = {\n",
    "    \"float\": FeatureTypeEnum.FRACTIONAL,\n",
    "    \"long\": FeatureTypeEnum.INTEGRAL\n",
    "}\n",
    "\n",
    "feature_definitions = [\n",
    "    FeatureDefinition(\n",
    "        feature_name = column_schema['name'], \n",
    "        feature_type = column_to_feature_type_mapping.get(column_schema['type'], default_feature_type)\n",
    "    ) for column_schema in column_schemas\n",
    "]\n",
    "\n",
    "\n",
    "print(f\"Feature Group Name: {feature_group_name}\")\n",
    "\n",
    "# Confirm the Athena settings are configured\n",
    "try:\n",
    "    boto3.client('athena').update_work_group(\n",
    "        WorkGroup = 'primary',\n",
    "        ConfigurationUpdates = {\n",
    "            'EnforceWorkGroupConfiguration':False\n",
    "        }\n",
    "    )\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "feature_group = FeatureGroup(\n",
    "    name = feature_group_name, sagemaker_session = feature_store_session, feature_definitions = feature_definitions)\n",
    "\n",
    "feature_group.create(\n",
    "    s3_uri = feature_store_offline_s3_uri,\n",
    "    record_identifier_name = record_identifier_feature_name,\n",
    "    event_time_feature_name = event_time_feature_name,\n",
    "    role_arn = role,\n",
    "    enable_online_store = enable_online_store\n",
    ")\n",
    "\n",
    "def wait_for_feature_group_creation_complete(feature_group):\n",
    "    \"\"\"Helper function to wait for the completions of creating a feature group\"\"\"\n",
    "    response = feature_group.describe()\n",
    "    status = response.get(\"FeatureGroupStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for feature group creation\")\n",
    "        time.sleep(5)\n",
    "        response = feature_group.describe()\n",
    "        status = response.get(\"FeatureGroupStatus\")\n",
    "\n",
    "    if status != \"Created\":\n",
    "        print(f\"Failed to create feature group, response: {response}\")\n",
    "        failureReason = response.get(\"FailureReason\", \"\")\n",
    "        raise SystemExit(\n",
    "            f\"Failed to create feature group {feature_group.name}, status: {status}, reason: {failureReason}\"\n",
    "        )\n",
    "    print(f\"Feature Group {feature_group.name} successfully created.\")\n",
    "\n",
    "wait_for_feature_group_creation_complete(feature_group = feature_group)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.1.5: ingerir funciones\n",
    "\n",
    "Este proceso tarda aproximadamente 8 minutos en completarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate-feature-store\n",
    "column_list = ['retained','esent','eopenrate','eclickrate','avgorder','ordfreq','paperless','refill','doorstep','first_last_days_diff','created_first_days_diff','favday_Friday','favday_Monday', 'favday_Saturday','favday_Sunday','favday_Thursday','favday_Tuesday','favday_Wednesday','city_BLR','city_BOM','city_DEL','city_MAA','FS_ID','FS_time']\n",
    "lab_test_data = pd.read_csv('featureengineer_data/store_data_processed.csv', names = (column_list), header = 1)\n",
    "feature_group.ingest(data_frame = lab_test_data, wait = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.2: crear y ejecutar una canalización de SageMaker\n",
    "\n",
    "Ahora que su entorno está configurado, configure, cree e inicie una canalización de SageMaker. \n",
    "\n",
    "Una canalización de SageMaker es un flujo de trabajo que ejecuta una serie de pasos dependientes. Los pasos pueden aceptar entradas y enviar salidas, para que los datos y otros activos puedan pasar entre ellos. \n",
    "\n",
    "Ejecute las siguientes celdas para hacer lo siguiente:\n",
    "- Definir las variables que se necesitan para configurar la canalización.\n",
    "- Configurar una sesión de SageMaker.\n",
    "- Definir los pasos de la canalización.\n",
    "- Configurar la canalización.\n",
    "- Crear la canalización.\n",
    "- Iniciar la canalización.\n",
    "- Describir la canalización.\n",
    "- Crear un evento de espera para que el cuaderno no proceda hasta que la canalización haya terminado de ejecutarse."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.2.1: configurar las variables que utiliza la canalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pipeline-variables\n",
    "feature_group_name = feature_group.name\n",
    "model_name = \"Churn-model\"\n",
    "\n",
    "sklearn_processor_version = \"0.23-1\"\n",
    "model_package_group_name = \"ChurnModelPackageGroup\"\n",
    "pipeline_name = \"ChurnModelSMPipeline\"\n",
    "\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name = \"ProcessingInstanceCount\",\n",
    "    default_value = 1\n",
    "    )\n",
    "\n",
    "processing_instance_type = ParameterString(\n",
    "        name = \"ProcessingInstanceType\",\n",
    "        default_value = \"ml.m5.xlarge\"\n",
    "    )\n",
    "\n",
    "training_instance_type = ParameterString(\n",
    "        name = \"TrainingInstanceType\",\n",
    "        default_value = \"ml.m5.xlarge\"\n",
    "    )\n",
    "\n",
    "input_data = ParameterString(\n",
    "        name = \"InputData\",\n",
    "        default_value = \"s3://{}/data/storedata_total.csv\".format(default_bucket), \n",
    "    )\n",
    "\n",
    "batch_data = ParameterString(\n",
    "        name = \"BatchData\",\n",
    "        default_value = \"s3://{}/data/batch/batch.csv\".format(default_bucket),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.2.2: configurar la canalización\n",
    "\n",
    "Usted define una canalización llamada **ChurnModelPipeline** para producir un modelo que evalúe la posibilidad de conservar o perder clientes. Esta canalización tienen nueve pasos. \n",
    "\n",
    "Cada paso en una canalización ejecuta un tipo de trabajo específico. Las entradas requeridas para un trabajo varían en función del tipo de trabajo. Consulte [Tipos de pasos](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html#build-and-manage-steps-types) para obtener más información sobre los tipos de pasos de la canalización de SageMaker.\n",
    "\n",
    "Revise el código en las siguientes celdas para comprender cada paso que se define:\n",
    "\n",
    "El paso **ChurnModelProcess** se define en la variable llamada **step_process**. \n",
    "\n",
    "La configuración del paso incluye lo siguiente:\n",
    "- **Type** (Tipo) Processing (Procesamiento): los trabajos de procesamiento se definen con la clase ProcessingStep().\n",
    "- **Processor** (Procesador): SKLearnProcessor.\n",
    "- **Destination** (Destino): la salida se enviará a las carpetas que defina en el bucket de S3 predeterminado.\n",
    "- **Job Arguments** (Argumentos del trabajo): este paso usará el almacén de funciones para procesar el conjunto de datos.\n",
    "- **Code** (Código): **processfeaturestore.py**, que reside en su bucket de S3 predeterminado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-processing-step\n",
    "# Run a scikit-learn script to do data processing on SageMaker \n",
    "# using the SKLearnProcessor class\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "        framework_version = sklearn_processor_version,\n",
    "        instance_type = processing_instance_type.default_value, \n",
    "        instance_count = processing_instance_count,\n",
    "        sagemaker_session = sagemaker_session,\n",
    "        role = role,\n",
    "    )\n",
    "\n",
    "# Inputs, outputs, and code are parameters to the processor\n",
    "# step_* will become the pipeline steps toward the end of the cell\n",
    "# in this case, use the feature store as input, so there is no externalinput\n",
    "step_process = ProcessingStep(\n",
    "        name = \"ChurnModelProcess\",\n",
    "        processor = sklearn_processor,\n",
    "        outputs = [\n",
    "            ProcessingOutput(output_name = \"train\", source = \"/opt/ml/processing/train\",\\\n",
    "                             destination = f\"s3://{default_bucket}/output/train\" ),\n",
    "            ProcessingOutput(output_name = \"validation\", source = \"/opt/ml/processing/validation\",\\\n",
    "                            destination = f\"s3://{default_bucket}/output/validation\"),\n",
    "            ProcessingOutput(output_name = \"test\", source = \"/opt/ml/processing/test\",\\\n",
    "                            destination = f\"s3://{default_bucket}/output/test\"),\n",
    "            ProcessingOutput(output_name = \"batch\", source = \"/opt/ml/processing/batch\",\\\n",
    "                            destination = f\"s3://{default_bucket}/data/batch\"),\n",
    "            ProcessingOutput(output_name = \"baseline\", source = \"/opt/ml/processing/baseline\",\\\n",
    "                            destination = f\"s3://{default_bucket}/input/baseline\")\n",
    "        ],\n",
    "        job_arguments = [\"--featuregroupname\",feature_group_name,\"--default-bucket\",default_bucket,\"--region\",region],\n",
    "        code = f\"s3://{default_bucket}/input/code/processfeaturestore.py\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paso **ChurnHyperParameterTuning** se define en la variable llamada **step_tuning**. \n",
    "\n",
    "La configuración del paso incluye lo siguiente:\n",
    "- **Type** (Tipo) Tuning (Ajuste): los trabajos de ajuste se definen con la clase TuningStep().\n",
    "- **Tuner** (Ajustador): este trabajo utiliza el marco de trabajo de XGBoost.\n",
    "- **Inputs** (Entradas): observe que este trabajo utiliza los datos de entrenamiento y validación que obtenidos de paso ChurnModelProcess, **step_process**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-churn-hyperparameter-tuning\n",
    "# Training/tuning step for generating model artifacts\n",
    "model_path = f\"s3://{default_bucket}/output\"\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework = \"xgboost\",\n",
    "    region = region,\n",
    "    version = \"1.5-1\",\n",
    "    py_version = \"py3\",\n",
    "    instance_type = training_instance_type.default_value,\n",
    ")\n",
    "\n",
    "fixed_hyperparameters = {\n",
    "    \"eval_metric\":\"auc\",\n",
    "    \"objective\":\"binary:logistic\",\n",
    "    \"num_round\":\"100\",\n",
    "    \"rate_drop\":\"0.3\",\n",
    "    \"tweedie_variance_power\":\"1.4\"\n",
    "    }\n",
    "\n",
    "xgb_train = Estimator(\n",
    "    image_uri = image_uri,\n",
    "    instance_type = training_instance_type,\n",
    "    instance_count = 1,\n",
    "    hyperparameters = fixed_hyperparameters,\n",
    "    output_path = model_path,\n",
    "    base_job_name = f\"churn-train\",\n",
    "    sagemaker_session = sagemaker_session,\n",
    "    role = role\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning steps\n",
    "hyperparameter_ranges = {\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "    \"min_child_weight\": ContinuousParameter(1, 10),\n",
    "    \"alpha\": ContinuousParameter(0, 2),\n",
    "    \"max_depth\": IntegerParameter(1, 10),\n",
    "    }\n",
    "objective_metric_name = \"validation:auc\"\n",
    "\n",
    "step_tuning = TuningStep(\n",
    "    name = \"ChurnHyperParameterTuning\",\n",
    "    tuner = HyperparameterTuner(xgb_train, objective_metric_name, hyperparameter_ranges, max_jobs = 2, max_parallel_jobs = 2),\n",
    "    inputs = {\n",
    "            \"train\": TrainingInput(\n",
    "                s3_data = step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"train\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type = \"text/csv\",\n",
    "            ),\n",
    "            \"validation\": TrainingInput(\n",
    "                s3_data = step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"validation\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type = \"text/csv\",\n",
    "            ),\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paso **ChurnEvalBestModel** se define en la variable llamada **step_eval**. \n",
    "\n",
    "La configuración del paso incluye lo siguiente:\n",
    "- **Type** (Tipo) Processing (Procesamiento).\n",
    "- **Processor** (Procesador): ScriptProcessor.\n",
    "- **Inputs** (Entradas): observe que este trabajo utiliza el modele superior de ChurnHyperParameterTuning (**step_tuning**) y la salida de prueba de ChurnModelProcess (**step_process**).\n",
    "- **Outputs** (Salidas): la salida se escribe en el bucket de S3 predeterminado.\n",
    "- **Code** (Código): un script llamado **evaluate.py**, que reside en Amazon S3, se usa para la evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-churn-best-model\n",
    "evaluation_report = PropertyFile(\n",
    "    name = \"ChurnEvaluationReport\",\n",
    "    output_name = \"evaluation\",\n",
    "    path = \"evaluation.json\",\n",
    ")\n",
    "\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri = image_uri,\n",
    "    command = [\"python3\"],\n",
    "    instance_type = processing_instance_type,\n",
    "    instance_count = 1,\n",
    "    base_job_name = \"script-churn-eval\",\n",
    "    role = role,\n",
    "    sagemaker_session = sagemaker_session,\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name = \"ChurnEvalBestModel\",\n",
    "    processor = script_eval,\n",
    "    inputs = [\n",
    "        ProcessingInput(\n",
    "            source = step_tuning.get_top_model_s3_uri(top_k = 0, s3_bucket = default_bucket, prefix = \"output\"),\n",
    "            destination = \"/opt/ml/processing/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source = step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri,\n",
    "            destination = \"/opt/ml/processing/test\"\n",
    "        )\n",
    "    ],\n",
    "    outputs = [\n",
    "        ProcessingOutput(output_name = \"evaluation\", source = \"/opt/ml/processing/evaluation\",\\\n",
    "                            destination = f\"s3://{default_bucket}/output/evaluation\"),\n",
    "    ],\n",
    "    code = f\"s3://{default_bucket}/input/code/evaluate.py\",\n",
    "    property_files = [evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paso **ChurnCreateModel** se define en la variable llamada **step_create_model**. \n",
    "\n",
    "La configuración del paso incluye lo siguiente:\n",
    "- **Type** (Tipo) Model (Modelo): los trabajos de modelo se definen con la clase Model().\n",
    "- **Model** (Modelo): el modelo que usa este paso se define en la variable que se definió previamente llamada **model**. Observe que la variable **model** utiliza el modelo superior que se creó con ChurnHyperParameterTuning (**step_tuning**).\n",
    "- **Inputs** (Entradas): las entradas incluyen un tipo de instancia y un tipo de acelerador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-model-creation\n",
    "model = Model(\n",
    "    image_uri = image_uri,        \n",
    "    model_data = step_tuning.get_top_model_s3_uri(top_k = 0,s3_bucket = default_bucket,prefix = \"output\"),\n",
    "    name = model_name,\n",
    "    sagemaker_session = sagemaker_session,\n",
    "    role = role,\n",
    ")\n",
    "\n",
    "inputs = CreateModelInput(\n",
    "    instance_type = \"ml.m5.large\",\n",
    "    accelerator_type = \"ml.inf1.xlarge\",\n",
    ")\n",
    "\n",
    "step_create_model = CreateModelStep(\n",
    "    name = \"ChurnCreateModel\",\n",
    "    model = model,\n",
    "    inputs = inputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paso **ChurnModelConfigFile** se define en la variable llamada **step_config_file**. \n",
    "\n",
    "La configuración del paso incluye lo siguiente:\n",
    "- **Type** (Tipo) Processing (Procesamiento).\n",
    "- **Processor** (Procesador): ScriptProcessor.\n",
    "- **Code** (Código): **generate_config.py**, que reside en su bucket de S3 predeterminado.\n",
    "- **Job Arguments** (Argumentos del trabajo): los argumentos del trabajo incluyen al modelo que se generó con **ChurnCreateModel**, la ruta al informe de sesgos, el bucket predeterminado, el número de muestras y el número de instancias que se usan para el procesamiento.\n",
    "- **Depends On** (Depende de): observe que este trabajo no se puede ejecutar hasta que la creación del modelo no haya finalizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#configure-script-processing\n",
    "bias_report_output_path = f\"s3://{default_bucket}/clarify-output/bias\"\n",
    "clarify_instance_type = 'ml.m5.xlarge'\n",
    "analysis_config_path = f\"s3://{default_bucket}/clarify-output/bias/analysis_config.json\"\n",
    "clarify_image = sagemaker.image_uris.retrieve(framework = 'sklearn', version = sklearn_processor_version, region = region)\n",
    "\n",
    "#custom_image_uri = None\n",
    "script_processor = ScriptProcessor(\n",
    "    command = ['python3'],\n",
    "    image_uri = clarify_image,\n",
    "    role = role,\n",
    "    instance_count = 1,\n",
    "    instance_type = processing_instance_type,\n",
    "    sagemaker_session = sagemaker_session,\n",
    ")\n",
    "\n",
    "step_config_file = ProcessingStep(\n",
    "    name = \"ChurnModelConfigFile\",\n",
    "    processor = script_processor,\n",
    "    code = f\"s3://{default_bucket}/input/code/generate_config.py\",\n",
    "    job_arguments = [\"--modelname\", step_create_model.properties.ModelName, \"--bias-report-output-path\", bias_report_output_path, \"--clarify-instance-type\", clarify_instance_type,\\\n",
    "                  \"--default-bucket\", default_bucket, \"--num-baseline-samples\", \"50\", \"--instance-count\", \"1\"],\n",
    "    depends_on = [step_create_model.name]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paso **ChurnTransform** se define en la variable llamada **step_transform**. \n",
    "\n",
    "La configuración del paso incluye lo siguiente:\n",
    "- **Type** (Tipo) Transform (Transformación): los trabajos de transformación se definen con la clase TransformStep().\n",
    "- **Transformer** (Transformador): los detalles del transformador se configuran en la variable definida previamente llamada **transformer**. Observe que esta variable utiliza el modelo que se creó en ChurnCreateModel (**step_create_model**).\n",
    "- **Inputs** (Entradas): los datos que se transformarán, batch.csv, se definieron en el cuaderno anterior. La entrada incluye el tipo de archivo y cómo se debe dividir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-inference\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type = \"ml.m5.xlarge\",\n",
    "    instance_count = 1,\n",
    "    assemble_with = \"Line\",\n",
    "    accept = \"text/csv\",    \n",
    "    output_path = f\"s3://{default_bucket}/ChurnTransform\"\n",
    "    )\n",
    "\n",
    "step_transform = TransformStep(\n",
    "    name = \"ChurnTransform\",\n",
    "    transformer = transformer,\n",
    "    inputs = TransformInput(data = batch_data, content_type = \"text/csv\", join_source = \"Input\", split_type = \"Line\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paso **ClarifyProcessingStep** se define en la variable llamada **step_clarify**. \n",
    "\n",
    "La configuración del paso incluye lo siguiente:\n",
    "- **Type** (Tipo) Processing (Procesamiento).\n",
    "- **Processor** (Procesador): este trabajo utiliza SageMakerClarifyProcessor. Puede revisar la configuración del procesador en la variable llamada **clarify_processor**.\n",
    "- **Inputs** (Entradas): las entradas se definen en las variables **data_input** y **congif_input**.\n",
    "- **Outputs** (Salidas): la salida se escribe en una carpeta dentro del bucket predeterminado. \n",
    "- **Depends On** (Depende de): observe que este trabajo no se puede ejecutar hasta que **ChurnModelConfigFile** no haya creado la configuración del archivo que requiere Amazon SageMaker Clarify. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-clarify-processing\n",
    "data_config = sagemaker.clarify.DataConfig(\n",
    "s3_data_input_path = f's3://{default_bucket}/output/train/train.csv',\n",
    "s3_output_path = bias_report_output_path,\n",
    "    label = 0,\n",
    "    headers = ['target','esent','eopenrate','eclickrate','avgorder','ordfreq','paperless','refill','doorstep','first_last_days_diff','created_first_days_diff','favday_Friday','favday_Monday','favday_Saturday','favday_Sunday','favday_Thursday','favday_Tuesday','favday_Wednesday','city_BLR','city_BOM','city_DEL','city_MAA'],\n",
    "    dataset_type = \"text/csv\",\n",
    ")\n",
    "\n",
    "clarify_processor = sagemaker.clarify.SageMakerClarifyProcessor(\n",
    "    role = role,\n",
    "    instance_count = 1,\n",
    "    instance_type = clarify_instance_type,\n",
    "    sagemaker_session = sagemaker_session,\n",
    ")\n",
    "\n",
    "config_input = ProcessingInput(\n",
    "    input_name = \"analysis_config\",\n",
    "    source=analysis_config_path,\n",
    "    destination = \"/opt/ml/processing/input/analysis_config\",\n",
    "    s3_data_type = \"S3Prefix\",\n",
    "    s3_input_mode = \"File\",\n",
    "    s3_compression_type = \"None\",\n",
    "    )\n",
    "\n",
    "data_input = ProcessingInput(\n",
    "    input_name = \"dataset\",\n",
    "    source = data_config.s3_data_input_path,\n",
    "    destination = \"/opt/ml/processing/input/data\",\n",
    "    s3_data_type = \"S3Prefix\",\n",
    "    s3_input_mode = \"File\",\n",
    "    s3_data_distribution_type = data_config.s3_data_distribution_type,\n",
    "    s3_compression_type = data_config.s3_compression_type,\n",
    ")\n",
    "\n",
    "result_output = ProcessingOutput( \n",
    "    source = \"/opt/ml/processing/output\",\n",
    "    destination = data_config.s3_output_path,\n",
    "    output_name = \"analysis_result\",\n",
    "    s3_upload_mode = \"EndOfJob\",\n",
    ")\n",
    "\n",
    "step_clarify = ProcessingStep(\n",
    "    name = \"ClarifyProcessingStep\",\n",
    "    processor = clarify_processor,\n",
    "    inputs = [data_input, config_input],\n",
    "    outputs = [result_output],\n",
    "    depends_on = [step_config_file.name]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paso **RegisterChurnModel** se define en la variable llamada **step_register**. \n",
    "\n",
    "La configuración del paso incluye lo siguiente:\n",
    "- **Type** (Tipo) Register Model (Registro del modelo): los trabajos de registro se definen con la clase RegisterMode().\n",
    "- **Estimator** (estimador): el estimador se define antes en la celda en la variable **xgbtrain**.\n",
    "- **Model Data** (Datos del modelo): este es el URI del modelo que se genera en **ChurnHyperParameterTuning**.\n",
    "- **Content Types** (Tipos de contenido): text/csv\n",
    "- **Response Types** (Tipos de respuestas): text/csv\n",
    "- **Inference Instance** (Instancia de inferencia): es el tipo de instancia que se utilizará para el proceso de inferencia.\n",
    "- **Transform Instance** (Instancia de transformación): es el tipo de instancia que se utilizará para el proceso de transformaciones.\n",
    "- **Model Package Group Name** (Nombre del grupo de paquetes de modelos): este es el nombre del grupo que almacenará el grupo de versiones de modelos.\n",
    "- **Model Metrics** (Métricas del modelo): esto define la ubicación de las métricas del modelo. Los archivos que se incluyen son el informe de sesgos y el informe de explicabilidad de SageMaker Clarify y la evaluación del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure-model-registry\n",
    "model_statistics = MetricsSource(\n",
    "    s3_uri = \"s3://{}/output/evaluation/evaluation.json\".format(default_bucket),\n",
    "    content_type = \"application/json\"\n",
    "    )\n",
    "explainability = MetricsSource(\n",
    "    s3_uri = \"s3://{}/clarify-output/bias/analysis.json\".format(default_bucket),\n",
    "    content_type = \"application/json\"\n",
    "    )\n",
    "\n",
    "bias = MetricsSource(\n",
    "    s3_uri = \"s3://{}/clarify-output/bias/analysis.json\".format(default_bucket),\n",
    "    content_type = \"application/json\"\n",
    "    ) \n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics = model_statistics,\n",
    "    explainability = explainability,\n",
    "    bias = bias\n",
    ")\n",
    "\n",
    "step_register = RegisterModel(\n",
    "    name = \"RegisterChurnModel\",\n",
    "    estimator = xgb_train,\n",
    "    model_data = step_tuning.get_top_model_s3_uri(top_k = 0, s3_bucket = default_bucket, prefix = \"output\"),\n",
    "    content_types = [\"text/csv\"],\n",
    "    response_types = [\"text/csv\"],\n",
    "    inference_instances = [\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "    transform_instances = [\"ml.m5.large\"],\n",
    "    model_package_group_name = model_package_group_name,\n",
    "    model_metrics = model_metrics,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paso **CheckAUCScoreChurnEvaluation** se define en la variable llamada **step_cond**. \n",
    "\n",
    "La configuración del paso incluye lo siguiente:\n",
    "- **Type** (Tipo) Condition (Condición): los trabajos de condición se definen con la clase ConditionStep().\n",
    "- **Conditions** (Condiciones): esta condición se evalúa como True (Verdadera) si la salida de **ChurnEvalBestModel** es mayor a 0,75.\n",
    "- **If Steps** (Pasos si): esta es la lista de pasos que se ejecutan si la condición se evalúa como True (Verdadera).\n",
    "- **If Steps** (Pasos si no): esta es la lista de pasos que se ejecutan si la condición se evalúa como False (Falsa). Observe que esta lista está en blanco, lo que significa que la canalización detiene el procesamiento si la condición no se cumple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "cond_lte = ConditionGreaterThan(\n",
    "    left = JsonGet(\n",
    "        step = step_eval,\n",
    "        property_file = evaluation_report,\n",
    "        json_path = \"binary_classification_metrics.auc.value\"\n",
    "    ),\n",
    "    right = 0.75,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name = \"CheckAUCScoreChurnEvaluation\",\n",
    "    conditions = [cond_lte],\n",
    "    if_steps = [step_create_model, step_config_file, step_transform, step_clarify, step_register],\n",
    "    else_steps = [],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.2.3: definir la canalización\n",
    "\n",
    "Después de definir los pasos, configure la canalización en la variable llamada **pipeline**. Observe cómo los pasos que se definieron previamente pasan a la definición de la canalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #define pipeline function\n",
    "def get_pipeline(\n",
    "    region,\n",
    "    role = None,\n",
    "    default_bucket = None,\n",
    "    model_package_group_name = \"ChurnModelPackageGroup\",\n",
    "    pipeline_name = \"ChurnModelPipeline\",\n",
    "    base_prefix = None,\n",
    "    custom_image_uri = None,\n",
    "    sklearn_processor_version = None\n",
    "    ):\n",
    "\n",
    "    #configure pipeline instance\n",
    "    pipeline = Pipeline(\n",
    "        name = pipeline_name,\n",
    "        parameters = [\n",
    "            processing_instance_type,\n",
    "            processing_instance_count,\n",
    "            training_instance_type,\n",
    "            input_data,\n",
    "            batch_data,\n",
    "        ],\n",
    "        steps = [step_process, step_tuning, step_eval, step_cond],\n",
    "        sagemaker_session = sagemaker_session\n",
    "    )\n",
    "    return pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.2.4: crear la canalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #create pipeline using function\n",
    "pipeline = get_pipeline(\n",
    "  region = region,\n",
    "    role = role,\n",
    "    default_bucket = default_bucket,\n",
    "    model_package_group_name = model_package_group_name,\n",
    "    pipeline_name = pipeline_name,\n",
    "    custom_image_uri = clarify_image,\n",
    "    sklearn_processor_version = sklearn_processor_version\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.2.5: actualizar la canalización para utilizar el rol de IAM correcto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set-iam-role\n",
    "pipeline.upsert(role_arn = role)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** Si se encuentra con la siguiente advertencia después de ejecutar la celda, puede ignorarla sin problemas.\n",
    "\n",
    "“No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config”. (“No se ha encontrado ningún trabajo de entrenamiento finalizado asociado a este estimador. Por favor, asegúrese de que este estimador solo se utiliza para crear la configuración del flujo de trabajo”)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.2.6: iniciar la canalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start-pipeline\n",
    "RunPipeline = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.2.7: describir la canalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe-pipeline\n",
    "RunPipeline.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La canalización demora unos 35 minutos para ejecutarse.\n",
    "\n",
    "Mientras se ejecuta la canalización, continúe con la siguiente tarea para explorar la canalización en la consola de Amazon SageMaker Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 2.3: supervisar y aprobar la canalización\n",
    "\n",
    "En esta tarea, explore la canalización con la consola de Amazon SageMaker Studio.\n",
    "\n",
    "### Tarea 2.3.1: supervisar la canalización en SageMaker Studio\n",
    "\n",
    "La próxima tarea abre una nueva pestaña en SageMaker Studio. Para seguir esas instrucciones, utilice las siguientes opciones:\n",
    "- **Opción 1**: ver las pestañas una al lado de la otra. Para crear una vista de pantalla dividida de la ventana principal de SageMaker Studio, arrastre la pestaña **lab_10.ipynb** hacia el lado o seleccione (con el botón derecho del mouse) la pestaña **lab_10.ipynb** y elija **New View for Notebook** (Nueva vista para el cuaderno). Ahora, puede ver las instrucciones mientras explora los pasos de la canalización.\n",
    "- **Opción 2**: alternar entre las pestañas de SageMaker Studio para seguir estas instrucciones. Cuando haya terminado de explorar los pasos de la canalización, vuelva al cuaderno. Para ello, seleccione la pestaña **lab_10.ipynb**.\n",
    "\n",
    "1. En SageMaker Studio, seleccione el ícono de **SageMaker Home** (Inicio de SageMaker).\n",
    "1. Seleccione **Pipelines** (Canalizaciones).\n",
    "\n",
    "Se abre la pestaña **Pipelines** (Canalizaciones) en SageMaker Studio.\n",
    "\n",
    "1. Seleccione la canalización llamada **ChurnModelSMPipeline**. \n",
    "\n",
    "SageMaker Studio abre la pestaña **ChurnModelSMPipeline**.\n",
    "\n",
    "1. En la pestaña **ChurnModelSMPipeline**, en **Executions** (Ejecuciones), abra (haciendo clic con el botón derecho del mouse) el estado de la canalización y luego seleccione **Open execution details** (Abrir los detalles de la ejecución). \n",
    "\n",
    "SageMaker Studio abre la página **Directed Acyclic Graph** (DAG).\n",
    "\n",
    "Directed Acyclic Graph (DAG) muestra el flujo del trabajo y el proceso de la canalización. Los colores se utilizan para indicar el estado de un paso. Los colores indicadores son los siguientes:\n",
    "- **gris**: en espera de ejecución.\n",
    "- **azul**: en ejecución.\n",
    "- **verde**: se completó con éxito.\n",
    "- **rojo**: error.\n",
    "\n",
    "Cada paso que explora tiene las mismas cuatro pestañas en el panel de detalles del paso. Aunque los títulos de las pestañas son iguales, los contenidos de cada pestaña varían en función del tipo de trabajo y de su configuración:\n",
    "\n",
    "- **Input** (Entrada): esta pestaña contiene entadas que se han pasado al trabajo. Los ejemplos de entradas son los parámetros que especifican los tipos de instancias, los roles de AWS Identity and Access Management (IAM) o los argumentos necesarios para ejecutar el trabajo. Otros ejemplos de entradas incluyen archivos como código, conjuntos de datos e imágenes de Docker.\n",
    "- **Output** (Salida): esta pestaña muestra la salida que creó el trabajo. Algunos ejemplos de salidas son métricas, gráficos, archivos y resultados de evaluaciones.\n",
    "- **Logs** (Registros): esta pestaña proporciona una lista de registros a asociados con el trabajo. Si el usuario cuenta con suficientes privilegios para los Registros de Amazon CloudWatch, puede seleccionar el vínculo de los registros y ver los mensajes de registro detallados en CloudWatch. Algunos tipos de trabajo no generan registros.\n",
    "- **Information** (Información): esta pestaña proporciona información básica sobre un trabajo, como el tipo, el nombre y el momento en que se ejecutó.\n",
    "\n",
    "1. Seleccione el paso llamado **ChurnModelProcess**. Se abrirá un nuevo panel llamado **ChurnModelProcess**.\n",
    "1. En el panel **ChurnModelProcess**, revise las pestañas asociadas con este paso de la canalización: \n",
    "    - Seleccione la pestaña **Input** (Entrada). Esta pestaña contiene información útil sobre los parámetros y archivos que se utilizan en el paso de procesamiento. En la lista de parámetros, están los detalles, incluido el tipo de instancia y la imagen que utiliza el trabajo, la ubicación del conjunto de datos, la ubicación del código y los destinos para las diferentes salidas que se generan. Deslícese hasta la parte inferior del panel para hallar los archivos de entrada que se pasaron al trabajo.\n",
    "    - Seleccione la pestaña **Output** (Salida). En esta pestaña se muestran los diferentes archivos que se generan en el paso de la canalización y dónde están ubicados. Esta canalización ubica a todas las salidas en el bucket predeterminado de SageMaker Studio.\n",
    "    - Seleccione la pestaña **Logs** (Registros). Esta pestaña muestra los registros que se generan en el trabajo. Tener los registros disponibles dentro de SageMaker Studio acelera la investigación y la resolución de problemas cuando un paso de la canalización no se ejecuta en forma correcta.\n",
    "    - Seleccione la pestaña**Information** (Información). Esta pestaña proporciona información general de alto nivel sobre el paso de la canalización. Incluye información como el tipo y el nombre del paso y un vínculo al registro del trabajo. También proporciona detalles sobre cuándo se ejecutó el trabajo y cuánto tiempo duró.\n",
    "        - Observe que el **Step Type** (Tipo de paso) es **Processing** (Procesamiento).\n",
    "\n",
    "### Tarea 2.3.2: descubrir los detalles del paso de la canalización\n",
    "\n",
    "En los siguientes pasos, seleccione el nodo apropiado del gráfico acíclico direccionado (DAG) para hallar información sobre un paso de canalización determinado. Si necesita ayuda para hallar las respuestas, las respuestas correctas o sugerencias se incluyen al final de este cuaderno de Python.\n",
    "\n",
    "1. En el paso llamado **ChurnHyperParameterTuning**, ubique los siguientes detalles:\n",
    "    - ¿Cuál es el **Step Type** (Tipo de paso) de este paso?\n",
    "    - ¿Cuál fue el **Overall Best Training Job** (Mejor trabajo de entrenamiento en general) que se generó en este paso?\n",
    "1. En el paso llamado **ChurnEvalBestModel**, ubique los siguientes detalles:\n",
    "    - ¿Cuál es el **Step Type** (Tipo de paso) de este paso?\n",
    "    - ¿Cuál es el nombre del script de Python que se utiliza para evaluar el modelo superior que se identificó en el paso anterior?\n",
    "    - ¿Dónde se ubica el archivo?\n",
    "    - ¿Dónde se escriben los resultados de este paso?\n",
    "1. En el paso llamado **CheckAUCScoreChurnEvaluation**, ubique los siguientes detalles:\n",
    "    - ¿Cuál es el **Step Type** (Tipo de paso) de este paso?\n",
    "    - ¿Cuál fue el **Evaluation outcome** (Resultado de la evaluación)?\n",
    "1. En el paso llamado **ChurnCreateModel**, ubique los siguientes detalles:\n",
    "    - ¿Cuál es el **Step Type** (Tipo de paso) de este paso?\n",
    "    - ¿Este trabajo generó algún registro?\n",
    "1. En el paso llamado **RegisterChurnModel**, ubique los siguientes detalles:\n",
    "    - ¿Cuál es el **Step Type** (Tipo de paso) de este paso?\n",
    "    - ¿Cuál es el valor de la métrica del área bajo la curva (AUC)?\n",
    "1. En el paso llamado **ChurnTransform**, ubique los siguientes detalles:\n",
    "    - ¿Cuál es el **Step Type** (Tipo de paso) de este paso?\n",
    "    - ¿Este trabajo generó registros?\n",
    "    - ¿Qué archivos fueron las entradas para este trabajo?\n",
    "1. En el paso llamado **ChurnModelConfigFile**, ubique los siguientes detalles: \n",
    "    - ¿Qué ProcessingInstanceType (Tipo de instancia de procesamiento) se utilizó para ejecutar esta trabajo?\n",
    "    - ¿Cuál es el **Step Type** (Tipo de paso) de este paso?\n",
    "1. En el paso llamado **ClarifyProcessingStep**, ubique los siguientes detalles:\n",
    "    - ¿Cuál fue el archivo de salida de este paso?\n",
    "    - ¿Dónde se escribió la salida?\n",
    "\n",
    "## Tarea 2.3.3: aprobar el modelo en la canalización\n",
    "\n",
    "1. Una vez que la canalización haya finalizado la ejecución, revise el modelo que se creó en **Model registry** (Registro del modelo).\n",
    "    - En SageMaker Studio, seleccione el ícono de **SageMaker Home** (Inicio de SageMaker).\n",
    "    - Expanda la lista **Models** (Modelos).\n",
    "    - Seleccione **Model registry** (Registro del modelo).\n",
    "    - Abra el grupo del modelo llamado **ChurnModelPackageGroup**.\n",
    "    - En la pestaña **ChurnModelPackageGroup**, abra (haciendo clic con el botón derecho del mouse) la fila en la tabla **Versions** (Versiones) y seleccione **Open model version** (Abrir modelo de versión). Observe que el estado del modelo es **Pending** (Pendiente). Además, observe que el valor de **Execution** (Ejecución) es el nombre de la canalización que se acaba de completar.\n",
    "\n",
    "    Los detalles adicionales sobre la canalización se encuentran en cada una de las siguientes pestañas:\n",
    "    - **Activity** (Actividad): en esta pestaña se muestra la actividad del modelo. Contiene información del evento y cuánto tiempo ha transcurrido desde la última modificación del modelo.\n",
    "    - **Model quality** (Calidad del modelo): en esta pestaña se muestra las métricas de exactitud del modelo.\n",
    "    - **Explainability** (Explicabilidad): en esta pestaña se muestra la importancia de las funciones del modelo en términos de valores de Shapley (SHAP).\n",
    "    - **Bias report** (Informe de sesgos): en esta pestaña se muestran los posibles sesgos del modelo.\n",
    "    - **Inference recommender** (Recomendador de inferencias): en esta pestaña se proporcionan recomendaciones para mejorar el rendimiento de precios de un modelo. Esta pestaña no contiene datos porque esta función no es compatible con este modelo de paquete.\n",
    "    - **Load test** (Prueba de carga): desde esta pestaña puede iniciar pruebas para evaluar diferentes tipos de instancias y evaluarlas para las métricas de rendimiento y latencia requeridas para una implementación de producción.\n",
    "    - **Settings** (Configuración): en esta pestaña se muestra información como cuándo se creó el modelo, qué canalización lo generó, dónde se encuentra ubicado y el componente de prueba asociado a él.\n",
    "\n",
    "1. Apruebe el modelo. Este proceso está diseñado para una revisión manual antes de aprobar el modelo. Sin embargo, es posible automatizar la aprobación del modelo dentro de la canalización.\n",
    "    - Seleccione <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">**Update status**</span> (Actualizar estado).\n",
    "    - Abra la lista del menú desplegable y seleccione <span style=\"background-color:#1a1b22; font-size:90%; color:#57c4f8; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#57c4f8; border-width:thin; border-style:solid; border-radius:2px; margin-right:5px; white-space:nowrap\">**Approved**</span> (Aprobado).\n",
    "    - Seleccione <span style=\"background-color:#57c4f8; font-size:90%;  color:black; position:relative; top:-1px; padding-top:3px; padding-bottom:3px; padding-left:10px; padding-right:10px; border-color:#00a0d2; border-radius:2px; margin-right:5px; white-space:nowrap\">**Update status**</span> (Actualizar estado).\n",
    "1. Cierre la pestaña **ChurnModelPackageGroup**.\n",
    "\n",
    "### Tarea 2.3.4: ver los pasos de la canalización con el AWS SDK\n",
    "\n",
    "Además de utilizar la interfaz de usuario de SageMaker Studio para ver los detalles de la canalización, puede utilizar los comandos del AWS SDK. Por ejemplo, el siguiente comando devuelve una lista de los pasos de la canalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list-steps\n",
    "RunPipeline.list_steps()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 2.4: revisar los artefactos\n",
    "\n",
    "La próxima tarea abre una nueva pestaña en SageMaker Studio. Para seguir esas instrucciones, utilice las siguientes opciones:\n",
    "- **Opción 1**: ver las pestañas una al lado de la otra. Para crear una vista de pantalla dividida de la ventana principal de SageMaker Studio, arrastre la pestaña **lab_10.ipynb** hacia el lado o seleccione (con el botón derecho del mouse) la pestaña **lab_10.ipynb** y elija **New View for Notebook** (Nueva vista para el cuaderno). Ahora, puede ver las instrucciones mientras explora los artefactos.\n",
    "- **Opción 2**: alternar entre las pestañas de SageMaker Studio para seguir estas instrucciones. Cuando termine de explorar los artefactos, seleccione la pestaña **lab_10.ipynb** para volver al cuaderno.\n",
    "\n",
    "### Tarea 2.4.1: revisar los artefactos en SageMaker Studio\n",
    "\n",
    "Mientras se ejecuta la canalización, cada paso generó artefactos como archivos, parámetros de entrenamiento y modelos. Puede identificar los artefactos que creó la canalización en SageMaker Studio.\n",
    "1. Regrese a la pestaña llamada **ChurnModelSMPipeline**.\n",
    "1. Seleccione la pestaña **Executions** (Ejecuciones).\n",
    "1. Abra (haciendo clic con el botón derecho del mouse) la ejecución que figura en la lista y seleccione **View trial components generated by execution** (Ver componentes de la prueba generados en la ejecución). \n",
    "\n",
    "SageMaker Studio abre una nueva pestaña llamada **Trial Component List**. \n",
    "\n",
    "Se muestra una lista de todos los trabajos que ejecutó la canalización.\n",
    "\n",
    "Observe que cada componente de la prueba tiene un **Trial Component Type** (Tipo de componente de la prueba). La información disponible en las distintas pestañas de los detalles de la prueba asociada dependes del tipo de componente de la prueba. No todas las pestañas de los detalles de la prueba contienen datos para todos los tipos de componentes.\n",
    "\n",
    "1. Abra (haciendo clic con el botón derecho del mouse) la primera fila de la lista de trabajos y seleccione **Open in trial details** (Abrir en detalles de la prueba). \n",
    "\n",
    "SageMaker Studio abre una nueva pestaña llamada **Describe Trial Component** (Describir el componente de la prueba). \n",
    "\n",
    "En **Trial Components** (Componentes de la prueba), hay muchas pestañas disponibles. Dependiendo de lo que estaba haciendo el paso de la canalización, algunas pestañas podrían estar vacías. \n",
    "\n",
    "1. Seleccione la pestaña **Artifacts** (Artefactos). Los detalles de la entrada y la salida se utilizaron en el paso.\n",
    "1. Seleccione la pestaña **Explainability** (Explicabilidad). En esta pestaña se muestra el informe de explicabilidad que generó SageMaker Clarify.\n",
    "1. Seleccione la pestaña **Bias Report** (Informe de sesgos). En esta pestaña se muestra el informe de sesgos que generó SageMaker Clarify.\n",
    "\n",
    "### Tarea 2.4.2: localizar los artefactos en el bucket de S3 predeterminado\n",
    "**Nota:** use la Consola de administración de AWS para esta tarea. Una vez que haya explorado el bucket de S3, regrese a la pestaña del navegador donde está abierto SageMaker Studio y seleccione la pestaña **lab_10.ipynb**.\n",
    "\n",
    "1. En la pestaña del navegador donde se encuentra abierta la consola, navegue hasta Amazon S3.\n",
    "1. Seleccione el nombre del bucket que comience con **sagemaker-** y la región de AWS; por ejemplo, **sagemaker-us-west-2-123456789**.\n",
    "1. Explore las carpetas y archivos de este bucket. Este bucket contiene el conjunto de datos, las entradas y salidas del procesamiento, los resultados de SageMaker Clarify y otros archivos que contribuyen al modelo resultante.\n",
    "1. Regrese a la pestaña del navegador donde está abierto SageMaker Studio y seleccione la pestaña **lab_10.ipynb**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 2.5 (Opcional): crear y revisar el linaje de la canalización\n",
    "\n",
    "Aprendió cómo usar SageMaker Clarify para explicar cómo un modelo hace predicciones y comprender los posibles sesgos de un modelo. También puede usar SageMaker Clarify para descubrir los pasos que se usan para generar el modelo, que suelen ser necesarios para la auditoría del modelo. En esta tarea, se aprovecha del módulo MLLineageHelper para crear el linaje de la ejecución actual de la canalización. Consulte [MLLineageHelper](https://github.com/aws-samples/ml-lineage-helper) para obtener más información sobre ML Lineage Helper.\n",
    "\n",
    "El seguimiento del linaje de ML de Amazon SageMaker crea y almacena información sobre los pasos de un flujo de trabajo de ML, desde la preparación de los datos hasta la implementación del modelo. Con la información de seguimiento, puede reproducir los pasos del flujo de trabajo, hacer un seguimiento del linaje de modelo y del conjunto de datos y establecer normas de auditoría y gobernanza del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.5.1: configurar la sesión y las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set-variables\n",
    "fs_query = feature_group.athena_query()\n",
    "fs_table = fs_query.table_name\n",
    "query_string = 'SELECT * FROM \"'+fs_table+'\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.5.2: mostrar los valores que se utilizarán para construir el linaje del modelo\n",
    "\n",
    "Las configuraciones incluyen las siguientes características:\n",
    "- **query_string:** esta es la consulta de SageMaker Feature Store que se pasará al módulo MLLineageHelper.\n",
    "- **model_ref:** este es el nombre del modelo que se evalúa.\n",
    "- **processing_job:** este es el nombre del trabajo de procesamiento que generó el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print-values\n",
    "print ('query_string:',query_string)\n",
    "\n",
    "model_ref = sagemaker_client.list_models(SortBy = 'CreationTime', SortOrder = 'Descending')['Models'][0]['ModelName']\n",
    "print ('model_ref:',model_ref)\n",
    "\n",
    "processing_job = sagemaker_client.list_processing_jobs(SortBy = 'CreationTime', SortOrder = 'Descending', NameContains = 'ChurnModelProcess')['ProcessingJobSummaries'][0]['ProcessingJobName']\n",
    "print ('processing_job:',processing_job)\n",
    "\n",
    "processing_job_description = sagemaker_client.describe_processing_job(\n",
    "    ProcessingJobName = processing_job\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.5.3: describir el trabajo de procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe-processing-job\n",
    "processing_job_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.5.4: mostrar el nombre del trabajo de procesamiento que se usó para crear el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print-training-job\n",
    "training_job_name  =  sagemaker_client.list_training_jobs(SortBy = 'CreationTime', SortOrder = 'Descending')['TrainingJobSummaries'][0]['TrainingJobName']\n",
    "print (training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.5.5: crear el linaje para el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si recibe el siguiente error, ejecute la celda otra vez.\n",
    "- **ClientError: An error occurred (ThrottlingException) when calling the UpdateArtifact operation (reached max retries: 4): Rate exceeded** (ClientError: se ha producido un error [ThrottlingException] al llamar a la operación UpdateArtifact [reintentos máximos alcanzados: 4]: Tasa excedida**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build-lineage\n",
    "ml_lineage = MLLineageHelper()\n",
    "lineage = ml_lineage.create_ml_lineage(training_job_name, model_name = model_ref,\n",
    "                                       query = query_string, sagemaker_processing_job_description = processing_job_description,\n",
    "                                       feature_group_names = [feature_group_name])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.5.6: limitar el linaje para incluir solamente la prueba y el grupo de funciones actuales\n",
    "\n",
    "Una canalización se puede ejecutar múltiples veces. Para asegurarse de obtener los detalles de la ejecución del trabajo de entrenamiento más reciente, filtre la llamada de linaje con el nombre de la prueba y del grupo de funciones actuales que usa la prueba. \n",
    "\n",
    "Después de ejecutar la celda, los pasos que usó para crear al modelo, el orden en el que se ejecutaron los pasos y los trabajos que contribuyeron con otros trabajos en la canalización se muestran en forma de tabla. Esta misma información también se escribe en un archivo llamado **lineage_FS.csv**. Puede descargar este archivo para guardar la salida y compartirla con otros miembros del equipo, como los auditores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit-lineage\n",
    "trial_name = RunPipeline.describe()['PipelineExperimentConfig']['TrialName']\n",
    "pat = str(trial_name)+'|'+'fg-FG'\n",
    "df1 = lineage[lineage.apply(lambda x: any(x.str.contains(pat)),axis = 1)]\n",
    "pd.set_option('display.max_colwidth', 120)\n",
    "df1.to_csv('lineage_FS.csv') \n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.5.7: generar una visualización del linaje del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize-lineage\n",
    "plt.figure(3, figsize = (20, 14))\n",
    "graph = nx.DiGraph()\n",
    "graph.add_edges_from([(each[0], each[2]) for each in df1.values])\n",
    "fig, ax = plt.subplots()\n",
    "nx.draw_networkx(\n",
    "    graph,\n",
    "    node_size = 300,\n",
    "    node_color = \"orange\",\n",
    "    alpha = 0.65,\n",
    "    font_size = 8,\n",
    "    pos = nx.spring_layout(graph)\n",
    ")\n",
    "ax.set_facecolor('deepskyblue')\n",
    "ax.axis('off')\n",
    "fig.set_facecolor('deepskyblue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 2.6: eliminar la canalización\n",
    "\n",
    "Para borra la canalización, ejecute la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete-pipeline\n",
    "response = sagemaker_client.delete_pipeline(PipelineName = 'ChurnModelSMPipeline')\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión \n",
    "\n",
    "¡Felicitaciones! Usó SageMaker Pipelines para automatizar la creación y el registro de un modelo. Aprendió a profundizar en cada paso de la canalización para identificar los parámetros, archivos y registros asociados. Sabe cómo identificar los activos que la canalización utilizó para generar el modelo, cómo hallar el modelo en el registro de modelos y cómo hallar y ver los informes de explicabilidad y sesgos que puede generar la canalización.\n",
    "\n",
    "### Limpieza\n",
    "\n",
    "Ha completado este cuaderno. Para ir a la siguiente parte del laboratorio, complete estos pasos:\n",
    "\n",
    "- Cierre este archivo de cuaderno.\n",
    "- Regrese a la sesión de laboratorio y continúe con la **Conclusión**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sugerencias y respuestas para la tarea 2.3.1.1\n",
    "Sugerencia general: el **Step type** (Tipo de paso) se encuentra en la pestaña **Information** (Información).\n",
    "\n",
    "1. En el paso llamado **ChurnHyperParameterTuning**, ubique los siguientes detalles:\n",
    "    - ¿Cuál es el **Step Type** (Tipo de paso) de este paso?</br>\n",
    "    **Respuesta:** Tuning (Ajuste)</br>\n",
    "    - ¿Cuál fue el **Overall Best Training Job** (Mejor trabajo de entrenamiento en general) que se generó en este paso? </br>\n",
    "    **Sugerencia:** esta información se encuentra en la pestaña **Output** (Salida).</br>\n",
    "    **Respuesta:** se genera el nombre del modelo, el cual será diferente para cada estudiante. El nombre debería ser algo similar a este ejemplo: 056vhzs2vkxc-ChurnHy-TCAtUr16oV-001-17d5bd01\n",
    "1. En el paso **ChurnEvalBestModel**, ubique los siguientes detalles:\n",
    "    - ¿Cuál es el **Step Type** (Tipo de paso) de este paso?\n",
    "    **Respuesta:** Processing (Procesamiento)</br>\n",
    "    - ¿Cuál es el nombre del script de Python que se utiliza para evaluar el modelo superior que se identificó en el paso anterior?</br>\n",
    "    **Sugerencia:** esta información se encuentra en la pestaña **Input** (Entrada).</br>\n",
    "    **Respuesta:** evaluate.py</br>\n",
    "    - ¿Dónde se ubica el archivo?</br>\n",
    "    **Sugerencia:** esta información se encuentra en la pestaña **Input** (Entrada).</br>\n",
    "    **Respuesta:** el archivo se encuentra en el bucket de S3. La ruta es similar a este ejemplo: s3://sagemaker-us-west-2-1234567890/input/code/evaluate.py</br>\n",
    "    - ¿Dónde se escriben los resultados de este paso?</br>\n",
    "    **Sugerencia:** esta información se encuentra en la pestaña **Output** (Salida).</br>\n",
    "    **Respuesta:** los resultados de la evaluación se escribieron en un bucket de S3. La ruta del archivo debería ser similar al siguiente ejemplo: s3://sagemaker-us-west-2-1234567890/output/evaluation</br>\n",
    "1. En el paso **CheckAUCScoreChurnEvaluation**, ubique los siguientes detalles:\n",
    "    - ¿Cuál es el **Step Type** (Tipo de paso) de este paso?</br>\n",
    "    **Respuesta:** Condition (Condición)</br>\n",
    "    - ¿Cuál fue el **Evaluation outcome** (Resultado de la evaluación)?</br>\n",
    "    **Sugerencia:** esta información se encuentra en la pestaña **Output** (Salida).</br>\n",
    "    **Respuesta:** True (Verdadero)\n",
    "1. En el paso **ChurnCreateModel**, ubique los siguientes detalles:\n",
    "    - ¿Cuál es el **Step Type** (Tipo de paso) de este paso?</br>\n",
    "    **Respuesta:** Model (Modelo)</br>\n",
    "    - ¿Este trabajo generó algún registro?</br>\n",
    "    **Respuesta:** no\n",
    "1. En el paso **RegisterChurnModel**, ubique los siguientes detalles:\n",
    "    - ¿Cuál es el **Step Type** (Tipo de paso) de este paso?</br>\n",
    "    **Respuesta:** RegisterModel</br>\n",
    "    - ¿Cuál es el valor de la métrica AUC?</br>\n",
    "    **Sugerencia:** esta información se encuentra en la pestaña **Output** (Salida).</br>\n",
    "    **Respuesta:** el valor variará, pero debería estar cerca de 0,98.\n",
    "1. En el paso **ChurnTransform**, ubique los siguientes detalles:\n",
    "    - ¿Cuál es el **Step Type** (Tipo de paso) de este paso?</br>\n",
    "    **Respuesta:** Transform (Transformación)</br>\n",
    "    - ¿Este trabajo generó registros?</br>\n",
    "    **Respuesta:** sí</br>\n",
    "    - ¿Qué archivos fueron las entradas para este trabajo?</br>\n",
    "    **Sugerencia:** esta información se encuentra en la pestaña **Input** (Entrada). Es posible que deba deslizarse hasta la parte inferior del panel para hallar los nombres de los archivos.</br>\n",
    "    **Respuesta:** model.tar.gz, sagemaker-xgboost:1.5-1-cpu-py3, batch.csv\n",
    "1. En el paso **ChurnModelConfigFile**, ubique los siguientes detalles: \n",
    "    - ¿Qué ProcessingInstanceType (Tipo de instancia de procesamiento) se utilizó para ejecutar esta trabajo?</br>\n",
    "    **Sugerencia:** esta información se encuentra en la pestaña **Input** (Entrada).</br>\n",
    "    **Respuesta:** ml.m5.xlarge\n",
    "    - ¿Cuál es el **Step Type** (Tipo de paso) de este paso?</br>\n",
    "    **Respuesta:** Processing (Procesamiento)\n",
    "1. En el **ClarifyProcessingStep**, ubique los siguientes detalles:\n",
    "    - ¿Cuál fue el archivo de salida de este paso?\n",
    "    **Sugerencia:** esta información se encuentra en la pestaña **Output** (Salida).</br>\n",
    "    **Respuesta:** la salida eran datos sesgados.\n",
    "    - ¿Dónde se escribió la salida?\n",
    "    **Respuesta:** la salida se escribió en un bucket de S3. La ruta debería ser similar a este ejemplo: s3://sagemaker-us-west-2-1234567890/clarify-output/bias"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "741de909edea0d5644898c592544ed98bede62b404d20772e5c4abc3c2f12566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
