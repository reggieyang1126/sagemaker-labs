{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using an Amazon SageMaker Studio Notebook\n",
    "\n",
    "This notebook walks you through initializing and setting up the environment. It shows you how to upload and download the data to and from an Amazon Simple Storage Service (Amazon S3) bucket using the Amazon S3 helper methods from the SageMaker Python SDK.\n",
    "\n",
    "Start by initializing the environment. To do this, import the required libraries and get the default Amazon S3 bucket that SageMaker Studio uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "import pandas as pd\n",
    "import boto3\n",
    "\n",
    "\n",
    "# SageMaker dependencies\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role, session\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "\n",
    "region= boto3.Session().region_name\n",
    "\n",
    "# This object represents the AWS Identity and Access Management (IAM) role that you are assigned\n",
    "role = sagemaker.get_execution_role()\n",
    "print(\"Role: \", role)\n",
    "\n",
    "sm_session = session.Session(boto3.Session())\n",
    "sm = boto3.Session().client(\"sagemaker\")\n",
    "sm_runtime = boto3.Session().client(\"sagemaker-runtime\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset from the Amazon S3 bucket using the SageMaker Python SDK S3Downloader method. Refer to [SageMaker Python SDK S3Downloader method](https://sagemaker.readthedocs.io/en/stable/api/utility/s3.html#sagemaker.s3.S3Downloader) for more information about this downloader method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = ''\n",
    "s3 = boto3.resource('s3')\n",
    "for buckets in s3.buckets.all():\n",
    "    if 'labdatabucket' in buckets.name:\n",
    "        bucket = buckets.name\n",
    "print(bucket)\n",
    "prefix = 'scripts/data'\n",
    "\n",
    "S3Downloader.download(s3_uri=f\"s3://{bucket}/{prefix}/iris.csv\", local_path= 'data/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code verifies the dataset and displays it in a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "shape=pd.read_csv(\"data/iris.csv\", header=None)\n",
    "shape.sample(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition the dataset into train and test splits. Upload it to an Amazon S3 bucket using the SageMaker Python SDK S3Uploader method. Refer to [SageMaker Python SDK S3Uploader method](https://sagemaker.readthedocs.io/en/stable/api/utility/s3.html#sagemaker.s3.S3Uploader) for more information about this uploader method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = shape.sample(frac=0.8,random_state=200)\n",
    "test_data = shape.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'train_data.csv';\n",
    "train_data.to_csv(train_file, index=False, header=True)\n",
    "test_file = 'test_data.csv';\n",
    "test_data.to_csv(test_file, index=False, header=True)\n",
    "\n",
    "# Return the URLs of the uploaded file, so they can be reviewed or used elsewhere\n",
    "s3url = S3Uploader.upload(train_file, 's3://{}/{}'.format(bucket, prefix + \"/train\", \"train\"))\n",
    "print(s3url)\n",
    "s3url = S3Uploader.upload(test_file, 's3://{}/{}'.format(bucket, prefix + \"/test\", \"test\"))\n",
    "print(s3url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Congratulations! You have successfully initialized your environment and uploaded and downloaded files from an Amazon S3 bucket. \n",
    "\n",
    "### Cleanup\n",
    "\n",
    "You have completed this notebook. To move to the next part of the lab, do the following:\n",
    "\n",
    "- Close this notebook file\n",
    "- Return to the lab instructions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "741de909edea0d5644898c592544ed98bede62b404d20772e5c4abc3c2f12566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
